Lillian Diana Gish (October 14, 1893 – February 27, 1993) was an American actress, director and screenwriter.
Gish was a prominent film star from 1912 into the 1920s, being particularly associated with the films of director D. W. Griffith.
She also did considerable television work from the early 1950s into the 1980s, and closed her career playing opposite Bette Davis in the 1987 film The Whales of August.
The first several generations of Gishes were Dunkard ministers.
Their mother opened the Majestic Candy Kitchen, and the girls helped sell popcorn and candy to patrons of the old Majestic Theater, located next door.
The seventeen-year-old Lillian traveled to Shawnee, Oklahoma, where James's brother Alfred Grant Gish and his wife, Maude, lived.
Her father died in Norman, Oklahoma, in 1912, but she had returned to Ohio a few months before this.
When Lillian and Dorothy were old enough they joined the theatre, often traveling separately in different productions.
Gish continued to perform on the stage, and in 1913, during a run of A Good Little Devil, she collapsed from anemia.
Her performance in these frigid conditions gave her lasting nerve damage in several fingers.
He utilized her expressive talents to the fullest, developing her into a suffering yet strong heroine.
She directed her sister Dorothy in one film, Remodeling Her Husband (1920), when D. W. Griffith took his unit on location.
She turned down the money, requesting a more modest wage and a percentage so that the studio could use the funds to increase the quality of her films — hiring the best actors, screenwriters, etc.
Many of the silent era's leading ladies, such as Gish and Pickford, had been wholesome and innocent, but by the early 1930s (after the full adoption of sound and before the Motion Picture Production Code was enforced) these roles were perceived as outdated.
Louis Mayer wanted to stage a scandal ("knock her off her pedestal") to garner public sympathy for Gish, but Lillian didn't want to act both on screen and off, and returned to her first love, the theater.
Returning to movies, Gish was nominated for the Academy Award for Best Supporting Actress in 1946 for Duel in the Sun.
She was considered for various roles in Gone with the Wind ranging from Ellen O'Hara, Scarlett's mother (which went to Barbara O'Neil), to prostitute Belle Watling (which went to Ona Munson).
She appeared as Dowager Empress Maria Feodorovna in the short-lived 1965 Broadway musical Anya.
She was interviewed in the television documentary series Hollywood: A Celebration of the American Silent Film (1980).
She has a star on the Hollywood Walk of Fame at 1720 Vine Street.
At the Cannes festival, Gish won a 10-minute standing ovation from the audience.
The episode "Marry for Murder" was broadcast on September 9, 1943.
She was awarded an Academy Honorary Award in 1971, and in 1984 she received an AFI Life Achievement Award.
The University awarded Gish the honorary degree of Doctor of Performing Arts the next day.
Following Gish's 1993 death, the University raised funds to enlarge its gallery to display memorabilia received from Gish's estate.
The association between herself and D. W. Griffith was so close that some suspected a romantic connection, an issue never acknowledged by Gish, although several of their associates were certain they were at least briefly involved.
In the 1920s, Gish's association with Duell became something of a tabloid scandal when he sued her and made the details of their relationship public.
George Jean Nathan praised Gish's acting glowingly—comparing her to Eleonora Duse.
During the period of political turmoil in the US that lasted from the outbreak of World War II in Europe until the attack on Pearl Harbor, she maintained an outspoken non-interventionist stance.
Joseph Frank Keaton (October 4, 1895 – February 1, 1966), known professionally as Buster Keaton, was an American actor, comedian, film director, producer, screenwriter, and stunt performer.
His career declined when he signed with Metro-Goldwyn-Mayer and lost his artistic independence.
Many of Keaton's films from the 1920s remain highly regarded, such as Sherlock Jr. (1924), The General (1926), and The Cameraman (1928).
His father was Joseph Hallie "Joe" Keaton, who owned a traveling show with Harry Houdini called the Mohawk Indian Medicine Company, or the Keaton Houdini Medicine Show Company, which performed on stage and sold patent medicine on the side.
In Keaton's retelling, he was six months old when the incident occurred, and Harry Houdini gave him the nickname.
The act was mainly a comedy sketch.
A suitcase handle was sewn into Keaton's clothing to aid with the constant tossing.
However, Buster was always able to show the authorities that he had no bruises or broken bones.
Several times I'd have been killed if I hadn't been able to land like a cat.
Noticing that this caused the audience to laugh less, he adopted his famous deadpan expression when performing.
Despite tangles with the law and a disastrous tour of music halls in the United Kingdom, Keaton was a rising star in the theater.
In February 1917, he met Roscoe "Fatty" Arbuckle at the Talmadge Studios in New York City, where Arbuckle was under contract to Joseph M. Schenck.
Buster was such a natural in his first film, The Butcher Boy, he was hired on the spot.
Keaton later claimed that he was soon Arbuckle's second director and his entire gag department.
It was based on a successful play, The New Henrietta, which had already been filmed once, under the title The Lamb, with Douglas Fairbanks playing the lead.
He made a series of two-reel comedies, including One Week (1920), The Playhouse (1921), Cops (1922), and The Electric House (1922).
Comedy director Leo McCarey, recalling the freewheeling days of making slapstick comedies, said, "All of us tried to steal each other's gagmen.
During the railroad water-tank scene in Sherlock Jr., Keaton broke his neck when a torrent of water fell on him from a water tower, but he did not realize it until years afterward.
Keaton's character emerged unscathed, due to a single open window.
Aside from Steamboat Bill, Jr. (1928), Keaton's most enduring feature-length films include Our Hospitality (1923), The Navigator (1924), Sherlock Jr. (1924), Seven Chances (1925), The Cameraman (1928), and The General (1926).
Though it would come to be regarded as Keaton's greatest achievement, the film received mixed reviews at the time.
His distributor, United Artists, insisted on a production manager who monitored expenses and interfered with certain story elements.
The actors would phonetically memorize the foreign-language scripts a few lines at a time and shoot immediately after.
The director was usually Jules White, whose emphasis on slapstick and farce made most of these films resemble White's famous Three Stooges shorts.
However, director White's insistence on blunt, violent gags resulted in the Columbia shorts being the least inventive comedies he made.
He made his last starring feature El Moderno Barba Azul (1946) in Mexico; the film was a low-budget production, and it may not have been seen in the United States until its release on VHS in the 1980s, under the title Boom in the Moon.
In In the Good Old Summertime, Keaton personally directed the stars Judy Garland and Van Johnson in their first scene together, where they bump into each other on the street.
Reaction was strong enough for a local Los Angeles station to offer Keaton his own show, also broadcast live, in 1950.
Buster Keaton's wife Eleanor also was seen in the series (notably as Juliet to Buster's Romeo in a little-theater vignette).
Keaton's periodic television appearances during the 1950s and 1960s helped to revive interest in his silent films.
Well into his fifties, Keaton successfully recreated his old routines, including one stunt in which he propped one foot onto a table, then swung the second foot up next to it and held the awkward position in midair for a moment before crashing to the stage floor.
Keaton had prints of the features Three Ages, Sherlock Jr., Steamboat Bill, Jr., and College (missing one reel), and the shorts "The Boat" and "My Wife's Relations", which Keaton and Rohauer then transferred to Cellulose acetate film from deteriorating nitrate film stock.
In a series of silent television commercials for Simon Pure Beer made in 1962 by Jim Mohr in Buffalo, New York, Keaton revisited some of the gags from his silent film days.
In December 1958, Keaton was a guest star in the episode "A Very Merry Christmas" of The Donna Reed Show on ABC.
In 1960, he returned to MGM for the final time, playing a lion tamer in a 1960 adaptation of Mark Twain's The Adventures of Huckleberry Finn.
He worked with comedian Ernie Kovacs on a television pilot tentatively titled "Medicine Man," shooting scenes for it on January 12, 1962—the day before Kovacs died in a car crash. "
He traveled from one end of Canada to the other on a motorized handcar, wearing his traditional pork pie hat and performing gags similar to those in films that he made 50 years before.
Also in 1965, he traveled to Italy to play a role in Due Marines e un Generale, co-starring Franco Franchi and Ciccio Ingrassia.
One of his most biting parodies is The Frozen North (1922), a satirical take on William S. Hart's Western melodramas, like Hell's Hinges (1916) and The Narrow Trail (1917).
Audiences of the 1920s recognized the parody and thought the film hysterically funny.
The short also featured the impression of a performing monkey which was likely derived from a co-biller's act (called Peter the Great).
Note: Source misspells Keaton's frequent appellation as "Great Stoneface".
Keaton dated actress Dorothy Sebastian beginning in the 1920s and Kathleen Key in the early 1930s.
He escaped a straitjacket with tricks learned from Harry Houdini.
She filed for divorce in 1935 after finding Keaton with Leah Clampitt Sewell, the wife of millionaire Barton Sewell, in a hotel in Santa Barbara.
He stopped drinking for five years.
The marriage lasted until his death.
Confined to a hospital during his final days, Keaton was restless and paced the room endlessly, desiring to return home.
The screenplay, by Sidney Sheldon, who also directed the film, was loosely based on Keaton's life but contained many factual errors and merged his three wives into one character.
Dedicated to bringing greater public attention to Keaton's life and work, the membership includes many individuals from the television and film industry: actors, producers, authors, artists, graphic novelists, musicians, and designers, as well as those who simply admire the magic of Buster Keaton.
Hirschfeld said that modern film stars were more difficult to depict, that silent film comedians such as Laurel and Hardy and Keaton "looked like their caricatures".
Film critic Roger Ebert stated, "The greatest of the silent clowns is Buster Keaton, not only because of what he did, but because of how he did it.
Filmmaker Mel Brooks has credited Buster Keaton as a major influence, saying: "I owe (Buster) a lot on two levels: One for being such a great teacher for me as a filmmaker myself, and the other just as a human being watching this gifted person doing these amazing things.
Actor and stunt performer Johnny Knoxville cites Keaton as an inspiration when coming up with ideas for Jackass projects.
Lewis was particularly moved by the fact that Eleanor said his eyes looked like Keaton's.
In 1964, he told an interviewer that in making "this particular pork pie", he "started with a good Stetson and cut it down", stiffening the brim with sugar water.
His paternal great-grandparents were Welsh.
Lloyd began collaborating with Roach who had formed his own studio in 1913.
In 1919, she left Lloyd to pursue her dramatic aspirations.
Reportedly, the more Lloyd watched Davis the more he liked her.
Harold Lloyd would move away from tragicomic personas, and portray an everyman with unwavering confidence and optimism.
To create his new character Lloyd donned a pair of lensless horn-rimmed glasses but wore normal clothing; previously, he had worn a fake mustache and ill-fitting clothes as the Chaplinesque "Lonesome Luke". "
They were natural and the romance could be believable."
On Sunday, August 24, 1919, while posing for some promotional still photographs in the Los Angeles Witzel Photography Studio, he picked up what he thought was a prop bomb and lit it with a cigarette.
Lloyd was in the act of lighting a cigarette from the fuse of the bomb when it exploded, also badly burning his face and chest and injuring his eye.
Lloyd and Roach parted ways in 1924, and Lloyd became the independent producer of his own films.
All of these films were enormously successful and profitable, and Lloyd would eventually become the highest paid film performer of the 1920s.
However, his go-getting screen character was out of touch with Great Depression movie audiences of the 1930s.
On March 23, 1937, Lloyd sold the land of his studio, Harold Lloyd Motion Picture Company, to The Church of Jesus Christ of Latter-day Saints.
He returned for an additional starring appearance in The Sin of Harold Diddlebock, an ill-fated homage to Lloyd's career, directed by Preston Sturges and financed by Howard Hughes.
Lloyd and Sturges had different conceptions of the material and fought frequently during the shoot; Lloyd was particularly concerned that while Sturges had spent three to four months on the script of the first third of the film, "the last two-thirds of it he wrote in a week or less".
Some saw The Old Gold Comedy Theater as being a lighter version of Lux Radio Theater, and it featured some of the best-known film and radio personalities of the day, including Fred Allen, June Allyson, Lucille Ball, Ralph Bellamy, Linda Darnell, Susan Hayward, Herbert Marshall, Dick Powell, Edward G. Robinson, Jane Wyman, and Alan Young.
Many years later, acetate discs of 29 of the shows were discovered in Lloyd's home, and they now circulate among old-time radio collectors.
He was a Past Potentate of Al-Malaikah Shrine in Los Angeles, and was eventually selected as Imperial Potentate of the Shriners of North America for the year 1949–50.
Lloyd was invested with the Rank and Decoration of Knight Commander Court of Honour in 1955 and coroneted an Inspector General Honorary, 33°, in 1965.
It said, as first step, Lloyd will write the story of his life for Simon and Schuster.
He became known for his nude photographs of models, such as Bettie Page and stripper Dixie Evans, for a number of men's magazines.
We never intended them to be played with pianos."
They've come close to it, but they haven't come all the way up".
In the early 1960s, Lloyd produced two compilation films, featuring scenes from his old comedies, Harold Lloyd's World of Comedy and The Funny Side of Life.
Time-Life released several of the feature films more or less intact, also using some of Scharf's scores which had been commissioned by Lloyd.
The Brownlow and Gill documentary was shown as part of the PBS series American Masters, and created a renewed interest in Lloyd's work in the United States, but the films were largely unavailable.
They also adopted Gloria Freeman (1924–1986) in September 1930, whom they renamed Marjorie Elizabeth Lloyd but was known as "Peggy" for most of her life.
Davis died from a heart attack in 1969, two years before Lloyd's death.
In 1925, at the height of his movie career, Lloyd entered into Freemasonry at the Alexander Hamilton Lodge No.
In 1926, he became a 32° Scottish Rite Mason in the Valley of Los Angeles, California.
A portion of Lloyd's personal inventory of his silent films (then estimated to be worth $2 million) was destroyed in August 1943 when his film vault caught fire.
The fire spared the main house and outbuildings.
Lloyd was honored in 1960 for his contribution to motion pictures with a star on the Hollywood Walk of Fame located at 1503 Vine Street.
The second citation was a snub to Chaplin, who at that point had fallen foul of McCarthyism and had his entry visa to the United States revoked.
Gladys Marie Smith (April 8, 1892 – May 29, 1979), known professionally as Mary Pickford, was a Canadian-American film actress and producer with a career that spanned five decades.
Her father, John Charles Smith was the son of English Methodist immigrants, and worked a variety of odd jobs.
To please her husband's relatives, Pickford's mother baptized her children as Methodists, the religion of their father.
Gladys, her mother and two younger siblings toured the United States by rail, performing in third-rate companies and plays.
Gladys finally landed a supporting role in a 1907 Broadway play, The Warrens of Virginia.
After completing the Broadway run and touring the play, however, Pickford was again out of work.
She quickly grasped that movie acting was simpler than the stylized stage acting of the day.
As Pickford said of her success at Biograph:I played scrubwomen and secretaries and women of all nationalities ... I decided that if I could get into as many pictures as possible, I'd become known, and there would be a demand for my work.
In January 1910, Pickford traveled with a Biograph crew to Los Angeles.
Actors were not listed in the credits in Griffith's company.
Pickford left Biograph in December 1910.
She returned to Broadway in the David Belasco production of A Good Little Devil (1912).
In 1913, she decided to work exclusively in film.
Pickford left the stage to join Zukor's roster of stars.
Comedy-dramas, such as In the Bishop's Carriage (1913), Caprice (1913), and especially Hearts Adrift (1914), made her irresistible to moviegoers.
Tess of the Storm Country was released five weeks later.
Only Charlie Chaplin, who slightly surpassed Pickford's popularity in 1916, had a similarly spellbinding pull with critics and the audience.
She also became vice-president of Pickford Film Corporation.
Due to her lack of a normal childhood, she enjoyed making these pictures.
In August 1918, Pickford's contract expired and, when refusing Zukor's terms for a renewal, she was offered $250,000 to leave the motion picture business.
Through United Artists, Pickford continued to produce and perform in her own movies; she could also distribute them as she chose.
During this period, she also made Little Annie Rooney (1925), another film in which Pickford played a child, Sparrows (1926), which blended the Dickensian with newly minted German expressionist style, and My Best Girl (1927), a romantic comedy featuring her future husband Charles "Buddy" Rogers.
She played a reckless socialite in Coquette (1929), her first talkie, a role for which her famous ringlets were cut into a 1920s' bob.
The public failed to respond to her in the more sophisticated roles.
Established Hollywood actors were panicked by the impending arrival of the talkies.
She retired from film acting in 1933 following three costly failures with her last film appearance being Secrets.
During World War I she promoted the sale of Liberty Bonds, making an intensive series of fund-raising speeches, beginning in Washington, D.C., where she sold bonds alongside Charlie Chaplin, Douglas Fairbanks, Theda Bara, and Marie Dressler.
In a single speech in Chicago, she sold an estimated five million dollars' worth of bonds.
At the end of World War I, Pickford conceived of the Motion Picture Relief Fund, an organization to help financially needy actors.
As a result, in 1940, the Fund was able to purchase land and build the Motion Picture Country House and Hospital, in Woodland Hills, California.
She demanded (and received) these powers in 1916, when she was under contract to Zukor's Famous Players in Famous Plays (later Paramount).
The Mary Pickford Corporation was briefly Pickford's motion-picture production company.
Distributors (also part of the studios) arranged for company productions to be shown in the company's movie venues.
It was solely a distribution company, offering independent film producers access to its own screens as well as the rental of temporarily unbooked cinemas owned by other companies.
As a co-founder, as well as the producer and star of her own films, Pickford became the most powerful woman who has ever worked in Hollywood.
She and Chaplin remained partners in the company for decades.
It is rumored she became pregnant by Moore in the early 1910s and had a miscarriage or an abortion.
The couple lived together on-and-off for several years.
Around this time, Pickford also suffered from the flu during the 1918 flu pandemic.
They went to Europe for their honeymoon; fans in London and in Paris caused riots trying to get to the famous couple.
Pickford continued to epitomize the virtuous but fiery girl next door.
Foreign heads of state and dignitaries who visited the White House often asked if they could also visit Pickfair, the couple's mansion in Beverly Hills.
Other guests included George Bernard Shaw, Albert Einstein, Elinor Glyn, Helen Keller, H. G. Wells, Lord Mountbatten, Fritz Kreisler, Amelia Earhart, F. Scott Fitzgerald, Noël Coward, Max Reinhardt, Baron Nishi, Vladimir Nemirovich-Danchenko, Sir Arthur Conan Doyle, Austen Chamberlain, Sir Harry Lauder, and Meher Baba, among others.
They were also constantly on display as America's unofficial ambassadors to the world, leading parades, cutting ribbons, and making speeches.
They divorced January 10, 1936.
She criticized their physical imperfections, including Ronnie's small stature and Roxanne's crooked teeth.
Her siblings, Lottie and Jack, both died of alcohol-related causes in 1936 and 1933, respectively.
Pickford withdrew and gradually became a recluse, remaining almost entirely at Pickfair and allowing visits only from Lillian Gish, her stepson Douglas Fairbanks Jr., and few other people.
She appeared in court in 1959, in a matter pertaining to her co-ownership of North Carolina TV station WSJS-TV.
Charles "Buddy" Rogers often gave guests tours of Pickfair, including views of a genuine western bar Pickford had bought for Douglas Fairbanks, and a portrait of Pickford in the drawing room.
She also owned a house in Toronto, Ontario, Canada.
Her handprints and footprints are displayed at Grauman's Chinese Theatre in Hollywood, California.
The Mary Pickford Theater at the James Madison Memorial Building of the Library of Congress is named in her honor.
A first-run movie theatre in Cathedral City, California is called The Mary Pickford Theatre, which was established on May 25, 2001.
Among them are a rare and spectacular beaded gown she wore in the film Dorothy Vernon of Haddon Hall (1924) designed by Mitchell Leisen, her special Oscar, and a jewelry box.
The family home had been demolished in 1943, and many of the bricks delivered to Pickford in California.
In 1993, a Golden Palm Star on the Palm Springs Walk of Stars was dedicated to her.
From January 2011 until July 2011, the Toronto International Film Festival exhibited a collection of Mary Pickford memorabilia in the Canadian Film Gallery of the TIFF Bell LightBox building.
It was donated to Keene State College and is currently undergoing restoration by the Library of Congress for exhibition.
The Google Doodle of April 8, 2017 commemorated Mary Pickford's 125th birthday.
Gloria Josephine May Swanson (March 27, 1899 – April 4, 1983) was an American actress, producer, and businesswoman.
Her schoolgirl crush on Essanay Studios actor Francis X. Bushman led to her aunt taking her to tour the actor's Chicago studio.
Her sound film debut performance in the 1929 The Trespasser, earned her a second Academy Award nomination.
Her father was a Swedish American and her mother was of German, French, and Polish ancestry.
In either version, she was soon hired as an extra.
Her first role was a brief walk-on with actress Gerda Holmes, that paid an enormous (in those days) $3.25.
In 1915, she co-starred in Sweedie Goes to College with her future first husband Wallace Beery.
Vernon and Swanson projected a great screen chemistry that proved popular with audiences.
Badger was sufficiently impressed by Swanson to recommend her to the director Jack Conway for Her Decision and You Can't Believe Everything in 1918.
1920), Something to Think About (1920), and The Affairs of Anatol (1921) soon followed.
He had become a star in 1921 for his appearance in The Four Horsemen of the Apocalypse, but Swanson had known him since his days as an aspiring actor getting small parts, with no seeming hope for his professional future.
Filming was allowed for the first time at many of the historic sites relating to Napoleon.
At the time, Swanson was considered the most bankable star of her era.
The production was a disaster, with Parker being indecisive and the actors not experienced enough to deliver the performances she wanted.
The members took further steps by registering their discontent with Will H. Hays, Chairman of the Motion Picture Producers and Distributors of America.
Hays was enthusiastic about the basic story, but did have specific issues that were dealt with before the film's release.
He proposed to personally bankroll her next picture and conducted a thorough examination of her financial records.
Kennedy, however, advised her to hire Erich von Stroheim to direct another silent film, The Swamp, subsequently retitled Queen Kelly.
Stroheim worked for several months on writing the basic script.
Shooting was shut down in January, and Stroheim fired, after complaints by Swanson about him and about the general direction the film was taking.
The Trespasser in 1929 was a sound production, and garnered Swanson her second Oscar nomination.
The world premiere was held in London, the first American sound production to do so.
Perfect Understanding, a 1933 sound production comedy, was the only film produced by this company.
She began appearing in stage productions and starred in The Gloria Swanson Hour on WPIX-TV in 1948.
The storyline of the film follows a faded silent movie actress Norma Desmond (Swanson), in love with a failed screenwriter Joe Gillis (William Holden).
Norma plays a card game of bridge with a group of actors also known as "the Waxworks".
Norma dreams of a comeback are subverted, and when Gillis tries to break up with her, she threatens to kill herself, but instead kills him.
Although Swanson had objected to enduring a screen test for the film, she had been glad to be making much more money than she had been in television and on stage.
Swanson later hosted Crown Theatre with Gloria Swanson, a television anthology series in which she occasionally acted.
She was the "mystery guest" on What's My Line.
She made a notable appearance in a 1966 episode of The Beverly Hillbillies, in which she plays herself.
Actor and playwright Harold J. Kennedy, who had learned the ropes at Yale and with Orson Wells' Mercury Theatre, suggested Swanson do a road tour of "Reflected Glory", a comedy that had run on the Broadway stage with Tallulah Bankhead as its star.
After her success with Sunset Boulevard, she starred on Broadway in a revival of Twentieth Century with José Ferrer, and in Nina with David Niven.
As a Republican she supported the 1940 and 1944 campaigns for president of Wendell Willkie and the 1964 presidential campaign of Barry Goldwater.
Taking medication given to her by Beery, purported to be for morning sickness, she aborted the fetus and was taken unconscious to the hospital.
In 1923, she adopted 1-year-old Sonny Smith, whom she renamed Joseph Patrick Swanson after her father.
She had conceived a child with him before her divorce from Somborn was final, a situation that would have led to a public scandal and possible end of her film career.
Following a four-month recuperation from her abortion, they returned to the United States as European nobility.
He became a film executive representing Pathé (USA) in France.
Swanson described herself as a "mental vampire", someone with a searching curiosity about how things worked, and who pursued the possibilities of turning those ideas into reality.
They met by chance in Paris when Swanson was being fitted by Coco Chanel for her 1931 film Tonight or Never.
Her friends, some of whom openly disliked him, thought she was making a mistake.
Swanson had initially thought she was going to be able to retire from acting, but the marriage was troubled by Davey's alcoholism from the start.
He was the co-author (ghostwriter) of Billie Holiday's autobiography Lady Sings the Blues, the author of Sugar Blues, a 1975 best-selling health book still in print, and the author of the English version of Georges Ohsawa's You Are All Sanpaku.
Swanson and her husband first got to know John Lennon and Yoko Ono because they were fans of Dufty's work.
She was cremated and her ashes interred at the Episcopal Church of the Heavenly Rest on Fifth Avenue in New York City, attended by only a small circle of family.
In 1974, Swanson was one of the honorees of the first Telluride Film Festival.
Due to the erotic nature of her performances, Nielsen's films were censored in the United States, and her work remained relatively obscure to American audiences.
Nielsen's family moved several times during her childhood while her father sought employment.
Nielsen's father died when she was fourteen years old.
In 1901, 21-year-old Nielsen became pregnant and gave birth to a daughter, Jesta.
Nielsen graduated from the Theater school in 1902.
Nielsen's minimalist acting style was evidenced in her successful portrayal of a naive young woman lured into a tragic life.
Nielsen and Gad married, then made four more films together.
I realised that the age of short film was past.
It was international film sales that provided Union with eight Nielsen films per year.
I used every available means – and devised many new ones – in order to bring the Asta Nielsen films to the world."
In a Russian popularity poll of 1911, Nielsen was voted the world's top female movie star, behind Linder and ahead of her Danish compatriot Valdemar Psilander.
In 1921, Nielsen, through her own film distribution company of Asta Films, appeared in the Svend Gade and Heinz Schall directed Hamlet.
However, scholarly works such as the authoritative filmography published by Filmarchiv Austria in 2010 make no mention of such a film.
She worked in German films until the start of sound movies.
Thereafter, Nielsen acted only on stage.
Understanding the implications, Nielsen declined and left Germany in 1936.
They were divorced by 1919 when Nielsen married the Swedish shipbuilder Freddy Windgårdh.
They began a long-term common-law marriage that lasted from 1923 until the late 1930s.
Fred Astaire (born Frederick Austerlitz; May 10, 1899 – June 22, 1987) was an American dancer, actor, singer, choreographer, and television presenter.
He starred in more than 10 Broadway and West End musicals, made 31 musical films, four television specials, and numerous recordings.
Astaire's mother was born in the US to Lutheran German immigrants from East Prussia and Alsace.
Fritz was seeking work in the brewing trade and moved to Omaha, Nebraska, where he was employed by the Storz Brewing Company.
Johanna planned a "brother and sister act", common in vaudeville at the time, for her two children.
They began training at the Alviene Master School of the Theatre and Academy of Cultural Arts.
They were taught dance, speaking, and singing in preparation for developing an act.
In an interview, Astaire's daughter, Ava Astaire McKenzie, observed that they often put Fred in a top hat to make him look taller.
As a result of their father's salesmanship, Fred and Adele landed a major contract and played the Orpheum Circuit in the Midwest, Western and some Southern cities in the US.
In 1912, Fred became an Episcopalian.
From vaudeville dancer Aurelio Coccia, they learned the tango, waltz, and other ballroom dances popularized by Vernon and Irene Castle.
He first met George Gershwin, who was working as a song plugger for Jerome H. Remick's music publishing company, in 1916.
Of their work in The Passing Show of 1918, Heywood Broun wrote: "In an evening in which there was an abundance of good dancing, Fred Astaire stood out ... He and his partner, Adele Astaire, made the show pause early in the evening with a beautiful loose-limbed dance."
But by this time, Astaire's dancing skill was beginning to outshine his sister's.
Astaire's tap dancing was recognized by then as among the best.
After the close of Funny Face, the Astaires went to Hollywood for a screen test (now lost) at Paramount Pictures, but Paramount deemed them unsuitable for films.
The end of the partnership was traumatic for Astaire but stimulated him to expand his range.
They lent him for a few days to MGM in 1933 for his significant Hollywood debut in the successful musical film Dancing Lady.
He wrote his agent, "I don't mind making another picture with her, but as for this 'team' idea, it's 'out!'
The partnership, and the choreography of Astaire and Hermes Pan, helped make dancing an important element of the Hollywood film musical.
Six out of the nine Astaire–Rogers musicals became the biggest moneymakers for RKO; all of the films brought a certain prestige and artistry that all studios coveted at the time.
This gave the illusion of an almost stationary camera filming an entire dance in a single shot.
Astaire's style of dance sequences allowed the viewer to follow the dancers and choreography in their entirety.
Astaire's second innovation involved the context of the dance; he was adamant that all song and dance routines be integral to the plotlines of the film.
One would be a solo performance by Astaire, which he termed his "sock solo."
I think Ginger Rogers was.
She faked it an awful lot.
In 1976, British talk-show host Sir Michael Parkinson asked Astaire who his favorite dancing partner was on Parkinson.
Despite their success, Astaire was unwilling to have his career tied exclusively to any partnership.
Throughout this period, Astaire continued to value the input of choreographic collaborators.
They starred in Broadway Melody of 1940, in which they performed a celebrated extended dance routine to Cole Porter's "Begin the Beguine."
He played alongside Bing Crosby in Holiday Inn (1942) and later Blue Skies (1946).
The latter film featured "Puttin' On the Ritz", an innovative song-and-dance routine indelibly associated with him.
The first film, You'll Never Get Rich (1941), catapulted Hayworth to stardom.
It featured a duet to Kern's "I'm Old Fashioned," which became the centerpiece of Jerome Robbins's 1983 New York City Ballet tribute to Astaire.
Astaire choreographed this film alone and achieved modest box office success.
The fantasy Yolanda and the Thief (1945) featured an avant-garde surrealistic ballet.
Always insecure and believing his career was beginning to falter, Astaire surprised his audiences by announcing his retirement during the production of his next film Blue Skies (1946).
Both of these films revived Astaire's popularity and in 1950 he starred in two musicals.
While Three Little Words did quite well at the box office, Let's Dance was a financial disappointment.
But because of its high cost, it failed to make a profit on its first release.
Then, his wife Phyllis became ill and suddenly died of lung cancer.
Daddy Long Legs only did moderately well at the box office.
Similarly, Astaire's next project – his final musical at MGM, Silk Stockings (1957), in which he co-starred with Cyd Charisse, also lost money at the box office.
The first of these programs, 1958's An Evening with Fred Astaire, won nine Emmy Awards, including "Best Single Performance by an Actor" and "Most Outstanding Single Program of the Year."
The choice had a controversial backlash because many believed his dancing in the special was not the type of "acting" for which the award was designed.
They restored the original videotape, transferring its contents to a modern format and filling in gaps where the tape had deteriorated with kinescope footage.
Astaire appeared in non-dancing roles in three other films and several television series from 1957 to 1969.
Astaire's dance partner was Petula Clark, who played his character's skeptical daughter.
Astaire continued to act in the 1970s.
In the second compilation, aged seventy-six, he performed brief dance linking sequences with Kelly, his last dance performances in a musical film.
In 1978, he co-starred with Helen Hayes in a well received television film A Family Upside Down in which they played an elderly couple coping with failing health.
Astaire asked his agent to obtain a role for him on Galactica because of his grandchildren's interest in the series and the producers were delighted at the opportunity to create an entire episode to feature him.
Long after the photography for the solo dance number "I Want to Be a Dancin' Man" was completed for the 1952 feature The Belle of New York, it was decided that Astaire's humble costume and the threadbare stage set were inadequate and the entire sequence was reshot.
Frame for frame, the two performances are identical, down to the subtlest gesture.
His was a uniquely recognizable dance style that greatly influenced the American Smooth style of ballroom dance and set standards against which subsequent film dance musicals would be judged.
He notes Astaire's dance style was consistent in subsequent films made with or without the assistance of Pan.
However, this was almost always confined to the area of extended fantasy sequences, or "dream ballets".
Later in life, he admitted, "I had to do most of it myself."
Many dance routines were built around a "gimmick," like dancing on the walls in Royal Wedding or dancing with his shadows in Swing Time.
They would work with a rehearsal pianist (often the composer Hal Borne) who in turn would communicate modifications to the musical orchestrators.
With all the preparation completed, the actual shooting would go quickly, conserving costs.
He will not even go to see his rushes... He always thinks he is no good."
Michael Kidd, Astaire's co-choreographer on the 1953 film The Band Wagon, found that his own concern about the emotional motivation behind the dance was not shared by Astaire.
Let's add the looks later.' "
Irving Berlin considered Astaire the equal of any male interpreter of his songs—"as good as Jolson, Crosby or Sinatra, not necessarily because of his voice, but for his conception of projecting a song.
In his heyday, Astaire was referenced in lyrics of songwriters Cole Porter, Lorenz Hart and Eric Maschwitz and continues to inspire modern songwriters.
During 1952, Astaire recorded The Astaire Story, a four-volume album with a quintet led by Oscar Peterson.
Bogart began acting in Broadway shows, beginning his career in motion pictures with Up the River (1930) for Fox and appeared in supporting roles for the next decade, sometimes portraying gangsters.
Bogart's private detectives, Sam Spade (in The Maltese Falcon) and Phillip Marlowe (in 1946's The Big Sleep), became the models for detectives in other noir films.
Soon after the principal photography for The Big Sleep (1946, their second film together), he filed for divorce from his third wife and married Bacall.
He reprised those unsettled, unstable characters as a World War II naval-vessel commander in The Caine Mutiny (1954), which was a critical and commercial hit and earned him another Best Actor nomination.
The name "Bogart" derives from the Dutch surname, "Bogaert".
Maud was an Episcopalian of English heritage, and a descendant of Mayflower passenger John Howland.
Clifford McCarty wrote that Warner Bros. publicity department had altered it to January 23, 1900 "to foster the view that a man born on Christmas Day couldn't really be as villainous as he appeared to be on screen".
Lauren Bacall wrote in her autobiography that Bogart's birthday was always celebrated on Christmas Day, saying that he joked about being cheated out of a present every year.
Maud was a commercial illustrator who received her art training in New York and France, including study with James Abbott McNeill Whistler.
She earned over $50,000 a year at the peak of her career – a very large sum of money at the time, and considerably more than her husband's $20,000.
He had two younger sisters: Frances ("Pat") and Catherine Elizabeth ("Kay").
A kiss, in our family, was an event.
He inherited a tendency to needle, a fondness for fishing, a lifelong love of boating, and an attraction to strong-willed women from his father.
Bogart later attended Phillips Academy, a boarding school to which he was admitted based on family connections.
Several reasons have been given; according to one, he was expelled for throwing the headmaster (or a groundskeeper) into Rabbit Pond on campus.
He then volunteered for the Coast Guard Temporary Reserve in 1944, patrolling the California coastline in his yacht, the Santana.
In one, his lip was cut by shrapnel when his ship (the ) was shelled.
While changing trains in Boston, the handcuffed prisoner reportedly asked Bogart for a cigarette.
By the time Bogart was treated by a doctor, a scar had formed.
Instead of stitching it up, he screwed it up."
His character and values developed separately from his family during his navy days, and he began to rebel.
Bogart resumed his friendship with Bill Brady Jr. (whose father had show-business connections), and obtained an office job with William A. Brady's new World Films company.
He made his stage debut a few months later as a Japanese butler in Alice's 1921 play Drifting (nervously delivering one line of dialogue), and appeared in several of her subsequent plays.
A barroom brawl at this time was also a purported cause of Bogart's lip damage, dovetailing with Louise Brooks' account.
Bogart disliked his trivial, effeminate early-career parts, calling them "White Pants Willie" roles.
Menken said in her divorce filing that Bogart valued his career more than marriage, citing neglect and abuse.
There he met Spencer Tracy, a Broadway actor whom Bogart liked and admired, and they became close friends and drinking companions.
Tracy received top billing, but Bogart appeared on the film's posters.
A quarter of a century later, the two men planned to make The Desperate Hours together.
Bogart shuttled back and forth between Hollywood and the New York stage from 1930 to 1935, out of work for long periods.
Although Leslie Howard was the star, The New York Times critic Brooks Atkinson said that the play was "a peach ... a roaring Western melodrama ... Humphrey Bogart does the best work of his career as an actor."
Warner Bros. bought the screen rights to The Petrified Forest in 1935.
Howard, who held the production rights, made it clear that he wanted Bogart to star with him.
When Warner Bros. saw that Howard would not budge, they gave in and cast Bogart.
According to Variety, "Bogart's menace leaves nothing wanting".
There must be something in my tone of voice, or this arrogant face—something that antagonizes everybody.
In spite of his success, Warner Bros. had no interest in raising Bogart's profile.
Bogart used these years to begin developing his film persona: a wounded, stoical, cynical, charming, vulnerable, self-mocking loner with a code of honor.
His disputes with Warner Bros. over roles and money were similar to those waged by the studio with more established and less malleable stars such as Bette Davis and James Cagney.
His only leading role during this period was in Dead End (1937, on loan to Samuel Goldwyn), as a gangster modeled after Baby Face Nelson.
In Black Legion (1937), a movie Graham Greene described as "intelligent and exciting, if rather earnest", he played a good man who was caught up with (and destroyed by) a racist organization.
The trouble was they were drinking mine and I was making this stinking movie."
On August 21, 1938, Bogart entered a turbulent third marriage to actress Mayo Methot, a lively, friendly woman when sober but paranoid and aggressive when drunk.
She set their house afire, stabbed him with a knife, and slashed her wrists several times.
According to their friend, Julius Epstein, "The Bogart-Methot marriage was the sequel to the Civil War".
Methot's influence was increasingly destructive, however, and Bogart also continued to drink.
When he thought an actor, director or studio had done something shoddy, he spoke up publicly about it.
Paul Muni, George Raft, Cagney and Robinson turned down the lead role, giving Bogart the opportunity to play a character with some depth.
He worked well with Ida Lupino, sparking jealousy from Mayo Methot.
He could quote Plato, Pope, Ralph Waldo Emerson and over a thousand lines of Shakespeare, and subscribed to the Harvard Law Review.
Based on the Dashiell Hammett novel, it was first serialized in the pulp magazine Black Mask in 1929 and was the basis of two earlier film versions; the second was Satan Met a Lady (1936), starring Bette Davis.
Huston then eagerly accepted Bogart as his Sam Spade.
The film, directed by Michael Curtiz and produced by Hal Wallis, featured Ingrid Bergman, Claude Rains, Sydney Greenstreet, Paul Henreid, Conrad Veidt, Peter Lorre and Dooley Wilson.
Bogart is reported to have been responsible for the notion that Rick Blaine should be portrayed as a chess player, a metaphor for the relationships he maintained with friends, enemies, and allies.
Bogart was nominated for Best Actor in a Leading Role, but lost to Paul Lukas for his performance in Watch on the Rhine.
Bogart went on United Service Organizations and War Bond tours with Methot in 1943 and 1944, making arduous trips to Italy and North Africa (including Casablanca).
When they met, Bacall was 19 and Bogart 44; he nicknamed her "Baby."
We'll have a lot of fun together".
By Myself and Then Some, HarperCollins, New York, 2005.
He considered himself Bacall's protector and mentor, and Bogart was usurping that role.
Also, he has a sense of humor that contains that grating undertone of contempt."
The dialogue, especially in the added scenes supplied by Hawks, was full of sexual innuendo, and Bogart is convincing as private detective Philip Marlowe.
The marriage was a happy one, with tensions due to their differences.
According to Bogart's biographer, Stefan Kanfer, it was "a production line film noir with no particular distinction".
Lacking a love interest or a happy ending, it was considered a risky project.
James Agee wrote, "Bogart does a wonderful job with this character ... miles ahead of the very good work he has done before."
Bogart appeared in his final films for Warners, Chain Lightning (1950) and The Enforcer (1951).
Santana also made two films without him: And Baby Makes Three (1949) and The Family Secret (1951).
Several Bogart biographers, and actress-writer Louise Brooks, have felt that this role is closest to the real Bogart.
A parody of sorts of The Maltese Falcon, Beat the Devil was the final film for Bogart and John Huston.
Huston's love of adventure, his deep, longstanding friendship (and success) with Bogart, and the chance to work with Hepburn convinced the actor to leave Hollywood for a difficult shoot on location in the Belgian Congo.
Bacall came for the over-four-month duration, leaving their young son in Los Angeles.
She Luxed my undies in darkest Africa."
Hepburn (a teetotaler) fared worse in the difficult conditions, losing weight and at one point becoming very ill.
Despite the discomfort of jumping from the boat into swamps, rivers and marshes, The African Queen apparently rekindled Bogart's early love of boats; when he returned to California, he bought a classic mahogany Hacker-Craft runabout which he kept until his death.
When Bogart won, however, he said: "It's a long way from the Belgian Congo to the stage of this theatre.
As in tennis, you need a good opponent or partner to bring out the best in you.
Though he retained some of his old bitterness about having to do so, he delivered a strong performance in the lead; he received his final Oscar nomination and was the subject of a June 7, 1954 Time magazine cover story.
He is the type of director I don't like to work with ... the picture is a crock of crap.
Despite the acrimony, the film was successful; according to a review in The New York Times, Bogart was "incredibly adroit ... the skill with which this old rock-ribbed actor blends the gags and such duplicities with a manly manner of melting is one of the incalculable joys of the show".
He was uneasy with Ava Gardner in the female lead; she had just broken up with his Rat Pack buddy Frank Sinatra, and Bogart was annoyed by her inexperienced performance.
When Bacall found them together, she extracted an expensive shopping spree from her husband; the three traveled together after the shooting.
He also appeared on The Jack Benny Show, where a surviving kinescope of the live telecast captures him in his only TV sketch-comedy performance (October 25, 1953).
Stephen became an author and biographer and hosted a television special about his father on Turner Classic Movies.
In the wake of Santana, Bogart had formed a new company and had plans for a film (Melville Goodwin, U.S.A.) in which he would play a general and Bacall a press magnate.
He did not talk about his health and visited a doctor in January 1956 after considerable persuasion from Bacall.
He had additional surgery in November 1956, when the cancer had metastasized.
On it was inscribed, "If you want anything, just whistle."
Having studied with Stella Adler in the 1940s, he is credited with being one of the first actors to bring the Stanislavski system of acting and method acting, derived from the Stanislavski system, to mainstream audiences.
He directed and starred in the cult western One-Eyed Jacks, a critical and commercial flop, after which he delivered a series of notable box-office failures, beginning with Mutiny on the Bounty (1962).
He refused the award due to alleged mistreatment and misportrayal of Native Americans by Hollywood.
According to the Guinness Book of World Records, Brando was paid a record $3.7 million ($ million in inflation-adjusted dollars) and 11.75% of the gross profits for 13 days' work on Superman.
His ancestry was mostly German, Dutch, English, and Irish.
Brando was raised a Christian Scientist.
However, she was an alcoholic and often had to be brought home from bars in Chicago by her husband.
Brando harbored far more enmity for his father, stating, "I was his namesake, but nothing I did ever pleased or even interested him.
Around 1930, Brando's parents moved to Evanston, Illinois, when his father's work took him to Chicago, but separated in 1935 when Brando was 11 years old.
Brando, whose childhood nickname was "Bud", was a mimic from his youth.
In the 2007 TCM biopic Brando: The Documentary, childhood friend George Englund recalls Brando's earliest acting as imitating the cows and horses on the family farm as a way to distract his mother from drinking.
Brando's sister Frances left college in California to study art in New York.
Brando excelled at theater and did well in the school.
The faculty voted to expel him, though he was supported by the students, who thought expulsion was too harsh.
In a 1988 documentary, Marlon Brando: The Wild One, Brando's sister Jocelyn remembered, "He was in a school play and enjoyed it ... So he decided he would go to New York and study acting because that was the only thing he had enjoyed.
For a time he lived with Roy Somlyo, who later became a four time Emmy winning Broadway producer.
Brando's remarkable insight and sense of realism were evident early on.
According to Dustin Hoffman in his online Masterclass, Brando would often talk to camera men and fellow actors about their weekend even after the director would call action.
His behavior had him kicked out of the cast of the New School's production in Sayville, but he was soon afterwards discovered in a locally produced play there.
Cornell also cast him as the Messenger in her production of Jean Anouilh's Antigone that same year.
Bankhead had turned down the role of Blanche Dubois in A Streetcar Named Desire, which Williams had written for her, to tour the play for the 1946–1947 season.
Wilson was largely tolerant of Brando's behavior, but he reached his limit when Brando mumbled through a dress rehearsal shortly before the November 28, 1946, opening. "
It was marvelous," a cast member recalled. "
Critics were not as kind, however.
He received better reviews at subsequent tour stops, but what his colleagues recalled was only occasional indications of the talent he would later demonstrate. "
Brando displayed his apathy for the production by demonstrating some shocking onstage manners.
After several weeks on the road, they reached Boston, by which time Bankhead was ready to dismiss him.
Pierpont writes that John Garfield was first choice for the role, but "made impossible demands."
It humanizes the character of Stanley in that it becomes the brutality and callousness of youth rather than a vicious old man ... A new value came out of Brando's reading which was by far the best reading I have ever heard."
He said, "The curtain went up and on the stage is that son of a bitch from the gym, and he's playing me."
Brando's first screen role was a bitter paraplegic veteran in The Men (1950).
By Brando's own account, it may have been because of this film that his draft status was changed from 4-F to 1-A. He had had surgery on his trick knee, and it was no longer physically debilitating enough to incur exclusion from the draft.
Coincidentally, the psychiatrist knew a doctor friend of Brando.
The role is regarded as one of Brando's greatest.
The film was directed by Elia Kazan and co-starred Anthony Quinn.
During our scenes together, I sensed a bitterness toward me, and if I suggested a drink after work, he either turned me down or else was sullen and said little.
After achieving the desired effect, Kazan never told Quinn that he had misled him.
Gielgud was so impressed that he offered Brando a full season at the Hammersmith Theatre, an offer he declined.
It was like a furnace door opening—the heat came off the screen.
By all accounts, Brando was upset by his mentor's decision, but he worked with him again in On The Waterfront. "
Triumph's importers were ambivalent at the exposure, as the subject matter was rowdy motorcycle gangs taking over a small town.
When initially offered the role, Brando—still stung by Kazan's testimony to HUAC—demurred and the part of Terry Malloy nearly went to Frank Sinatra.
Brando won the Oscar for his role as Irish-American stevedore Terry Malloy in On the Waterfront.
In his July 29, 1954, review, The New York Times critic A. H. Weiler praised the film, calling it "an uncommonly powerful, exciting, and imaginative use of the screen by gifted professionals."
He portrayed Napoleon in the 1954 film Désirée.
Brando was especially contemptuous of director Henry Koster.
Relations between Brando and costar Frank Sinatra were also frosty, with Stefan Kanfer observing: "The two men were diametrical opposites: Marlon required multiple takes; Frank detested repeating himself."
Frank Sinatra called Brando "the world's most overrated actor", and referred to him as "mumbles".
Pauline Kael was not particularly impressed by the movie, but noted "Marlon Brando starved himself to play the pixie interpreter Sakini, and he looks as if he's enjoying the stunt—talking with a mad accent, grinning boyishly, bending forward, and doing tricky movements with his legs.
Newsweek found the film a "dull tale of the meeting of the twain", but it was nevertheless a box-office success.
The film went on to win four Academy Awards.
By all accounts, Brando was devastated by her death, with biographer Peter Manso telling A&E's Biography, "She was the one who could give him approval like no one else could and, after his mother died, it seems that Marlon stops caring."
The Young Lions also features Brando's only appearance in a film with friend and rival Montgomery Clift (although they shared no scenes together).
Brando portrays the lead character Rio, and Karl Malden plays his partner "Dad" Longworth.
Brando's inexperience as an editor also delayed postproduction and Paramount eventually took control of the film.
By then, I was bored with the whole project and walked away from it."
Brando's revulsion with the film industry reportedly boiled over on the set of his next film, Metro-Goldwyn-Mayer's remake of Mutiny on the Bounty, which was filmed in Tahiti.
Mutiny director Lewis Milestone claimed that the executives "deserve what they get when they give a ham actor, a petulant child, complete control over an expensive picture."
The Ugly American (1963) was the first of these films.
All of Brando's other Universal films during this period, including Bedtime Story (1964), The Appaloosa (1966), A Countess from Hong Kong (1967) and The Night of the Following Day (1969), were also critical and commercial flops.
Brando had also appeared in the spy thriller Morituri in 1965; that, too, failed to attract an audience.
Candy was especially appalling for many; a 1968 sex farce film directed by Christian Marquand and based on the 1958 novel by Terry Southern, the film satirizes pornographic stories through the adventures of its naive heroine, Candy, played by Ewa Aulin.
In the March 1966 issue of The Atlantic, Pauline Kael wrote that in his rebellious days, Brando "was antisocial because he knew society was crap; he was a hero to youth because he was strong enough not to take the crap", but now Brando and others like him had become "buffoons, shamelessly, pathetically mocking their public reputations."
I was very convincing in my pose of indifference, but I was very sensitive and it hurt a lot."
The film overall received mixed reviews.
Brando dedicated a full chapter to the film in his memoir, stating that the director, Gillo Pontecorvo, was the best director he had ever worked with next to Kazan and Bernardo Bertolucci.
In 1971, Michael Winner directed him in the British horror film The Nightcomers with Stephanie Beacham, Thora Hird, Harry Andrews and Anna Palk.
He bested Brando at the 1972 New York Film Critics Circle Awards.)
Brando also had One-Eyed Jacks working against him, a troubled production that lost money for Paramount when it was released in 1961.
Coppola convinced Brando to a videotaped "make-up" test, in which Brando did his own makeup (he used cotton balls to simulate the character's puffed cheeks).
Brando had doubts himself, stating in his autobiography, "I had never played an Italian before, and I didn't think I could do it successfully."
Brando was signed for a low fee of $50,000, but in his contract, he was given a percentage of the gross on a sliding scale: 1% of the gross for each $10 million over a $10 million threshold, up to 5% if the picture exceeded $60 million.
In a 1994 interview that can be found on the Academy of Achievement website, Coppola insisted, "The Godfather was a very unappreciated movie when we were making it.
They didn't like the way I was shooting it.
In a 2010 television interview with Larry King, Al Pacino also talked about how Brando's support helped him keep the role of Michael Corleone in the movie—despite the fact Coppola wanted to fire him.
He broke the ice by toasting the group with a glass of wine.
Caan adds, 'The first day we met Brando everybody was in awe.'"
Also, because he had so much power and unquestioned authority, I thought it would be an interesting contrast to play him as a gentle man, unlike Al Capone, who beat up people with baseball bats."
There was really no beginning.
He boycotted the award ceremony, instead sending indigenous American rights activist Sacheen Littlefeather, who appeared in full Apache attire, to state Brando's reasons, which were based on his objection to the depiction of indigenous Americans by Hollywood and television.
As with previous films, Brando refused to memorize his lines for many scenes; instead, he wrote his lines on cue cards and posted them around the set for easy reference, leaving Bertolucci with the problem of keeping them out of the picture frame.
His gross participation deal earned him $3 million.
Pauline Kael, in The New Yorker review, wrote "The movie breakthrough has finally come.
In 1973, Brando was devastated by the death of his childhood best friend Wally Cox.
Absent for the first hour of the movie, Clayton enters on horseback, dangling upside down, caparisoned in white buckskin, Littlefeather-style.
Penn, who believed in letting actors do their thing, indulged Marlon all the way."
In 1978, Brando narrated the English version of Raoni, a French-Belgian documentary film directed by Jean-Pierre Dutilleux and Luiz Carlos Saldanha that focused on the life of Raoni Metuktire and issues surrounding the survival of the indigenous Indian tribes of north central Brazil.
In 1979, he made a rare television appearance in the miniseries Roots: The Next Generations, portraying George Lincoln Rockwell; he won a Primetime Emmy Award for Outstanding Supporting Actor in a Miniseries or a Movie for his performance.
Brando was paid $1 million a week for 3 weeks work.
In the documentary, Coppola talks about how astonished he was when an overweight Brando turned up for his scenes and, feeling desperate, decided to portray Kurtz, who appears emaciated in the original story, as a man who had indulged every aspect of himself.
However, he returned in 1989 in A Dry White Season, based on André Brink's 1979 anti-apartheid novel.
Brando received praise for his performance, earning an Academy Award nomination for Best Supporting Actor and winning the Best Actor Award at the Tokyo Film Festival.
Variety also praised Brando's performance as Sabatini and noted, "Marlon Brando's sublime comedy performance elevates The Freshman from screwball comedy to a quirky niche in film history."
The Island of Dr. Moreau screenwriter Ron Hutchinson would later say in his memoir, Clinging to the Iceberg: Writing for a Living on the Stage and in Hollywood (2017), that Brando sabotaged the film's production by feuding and refusing to cooperate with his colleagues and the film crew.
This was his last role and his only role as a female character.
The actor's son, Miko, was Jackson's bodyguard and assistant for several years, and was a friend of the singer.
Dad had a hard time breathing in his final days, and he was on oxygen much of the time.
So Michael got Dad a golf cart with a portable oxygen tank so he could go around and enjoy Neverland.
He also suffered from diabetes and liver cancer.
His single recorded line was included within the final game as a tribute to the actor.
A distressed Brando told Malden he kept falling over.
Shortly before his death, he had apparently refused permission for tubes carrying oxygen to be inserted into his lungs, which, he was told, was the only way to prolong his life.
In 1976, he told a French journalist, "Homosexuality is so much in fashion, it no longer makes news.
He also claimed numerous other romances, although he did not discuss his marriages, his wives, or his children in his autobiography.
Brando met actress Rita Moreno in 1954, and they began a love affair.
Years after they broke up, Moreno played his love interest in the film The Night of the Following Day.
She is said to have been the daughter of a Welsh steel worker of Irish descent, William O'Callaghan, who had been superintendent on the Indian State railways.
Brando and Kashfi had a son, Christian Brando, on May 11, 1958; they divorced in 1959.
They had two children together: Miko Castaneda Brando (born 1961) and Rebecca Brando (born 1966).
Because Teriipaia was a native French speaker, Brando became fluent in the language and gave numerous interviews in French.
Brando and Teriipaia divorced in July 1972.
Brando had a long-term relationship with his housekeeper Maria Cristina Ruiz, with whom he had three children: Ninna Priscilla Brando (born May 13, 1989), Myles Jonathan Brando (born January 16, 1992), and Timothy Gahan Brando (born January 6, 1994).
His numerous grandchildren also include Prudence Brando and Shane Brando, children of Miko C. Brando; the children of Rebecca Brando; and the three children of Teihotu Brando among others.
His behavior during the filming of Mutiny on the Bounty (1962) seemed to bolster his reputation as a difficult star.
Galella had followed Brando, who was accompanied by talk show host Dick Cavett, after a taping of The Dick Cavett Show in New York City.
The filming of Mutiny on the Bounty affected Brando's life in a profound way, as he fell in love with Tahiti and its people.
The 1983 hurricane destroyed many of the structures including his resort.
He was listed in the Federal Communications Commission (FCC) records as Martin Brandeaux to preserve his privacy.
He attended some fundraisers for John F. Kennedy in the 1960 presidential election.
In autumn of 1967, Brando visited Helsinki, Finland at a charity party organized by UNICEF at the Helsinki City Theatre.
He spoke in favor of children’s rights and development aid in developing countries.
I felt I'd better go find out where it is; what it is to be black in this country; what this rage is all about," Brando said on the late-night ABC-TV talk show Joey Bishop Show.
It was one of the most incredible acts of courage I ever saw, and it meant a lot and did a lot."
In 1964 Brando was arrested at a "fish-in" held to protest a broken treaty that had promised Native Americans fishing rights in Puget Sound.
Brando ended his financial support for the group over his perception of its increasing radicalization, specifically a passage in a Panther pamphlet put out by Eldridge Cleaver advocating indiscriminate violence, "for the Revolution."
Sacheen Littlefeather represented him at the ceremony.
The event grabbed the attention of the US and the world media.
He was also an activist against apartheid.
He is listed by the American Film Institute as the fourth greatest male star whose screen debut occurred before or during 1950 (it occurred in 1950).
Retrieved August 19, 2009.Encyclopedia Britannica describes him as "the most celebrated of the method actors, and his slurred, mumbling delivery marked his rejection of classical dramatic training.
He was a development from the gangster leader and the outlaw.
His portrayal of the gang leader Johnny Strabler in The Wild One has become an iconic image, used both as a symbol of rebelliousness and a fashion accessory that includes a Perfecto style motorcycle jacket, a tilted cap, jeans and sunglasses.
The "I coulda been a contender" scene from On the Waterfront, according to the author of Brooklyn Boomer, Martin H. Levinson, is "one of the most famous scenes in motion picture history, and the line itself has become part of America's cultural lexicon."
You have to make 'em believe that you are dying ... Try to think of the most intimate moment you've ever had in your life."
In 1999 the American Film Institute ranked him eighth among its list of greatest male stars of the Golden Age of Hollywood.
He spent several years in vaudeville as a dancer and comedian, until he got his first major acting part in 1925.
After rave reviews, Warner Bros. signed him for an initial $400-a-week, three-week contract; when the executives at the studio saw the first dailies for the film, Cagney's contract was immediately extended.
He was nominated a third time in 1955 for Love Me or Leave Me with Doris Day.
Cagney walked out on Warner Bros. several times over the course of his career, each time returning on much improved personal and artistic terms.
He worked for an independent film company for a year while the suit was being settled, establishing his own production company, Cagney Productions, in 1942 before returning to Warner seven years later.
Cagney was the second of seven children, two of whom died within months of their births.
The family moved twice while he was still young, first to East 79th Street, and then to East 96th Street.
I feel sorry for the kid who has too cushy a time of it.
He was a good street fighter, defending his older brother Harry, a medical student, when necessary.
He became involved in amateur dramatics, starting as a scenery boy for a Chinese pantomime at Lenox Hill Neighborhood House (one of the first settlement houses in the nation) where his brother Harry performed and Florence James directed.
The show began Cagney's 10-year association with vaudeville and Broadway.
Eventually, they borrowed some money and headed back to New York via Chicago and Milwaukee, enduring failure along the way when they attempted to make money on the stage.
As with Pitter Patter, Cagney went to the audition with little confidence he would get the part.
This was a devastating turn of events for Cagney; apart from the logistical difficulties this presented—the couple's luggage was in the hold of the ship and they had given up their apartment.
He made up his mind that he would get a job doing something else."
Cagney also established a dance school for professionals, and then landed a part in the play Women Go On Forever, directed by John Cromwell, which ran for four months.
The show received rave reviews and was followed by Grand Street Follies of 1929.
Retitled Sinners' Holiday, the film was released in 1930.
However, the contract allowed Warners to drop him at the end of any 40-week period, effectively guaranteeing him only 40 weeks’ income at a time.
Due to the strong reviews he had received in his short film career, Cagney was cast as nice-guy Matt Doyle, opposite Edward Woods as Tom Powers.
Producer Darryl Zanuck claimed he thought of it in a script conference; Wellman said the idea came to him when he saw the grapefruit on the table during the shoot; and writers Glasmon and Bright claimed it was based on the real life of gangster Hymie Weiss, who threw an omelette into his girlfriend's face.
I never dreamed it would be shown in the movie.
He saw the film repeatedly just to see that scene, and was often shushed by angry patrons when his delighted laughter got too loud."
Warner Bros. was quick to team its two rising gangster stars—Edward G. Robinson and Cagney—for the 1931 film Smart Money.
As he completed filming, The Public Enemy was filling cinemas with all-night showings.
The studio heads also insisted that Cagney continue promoting their films, even ones he was not in, which he opposed.
The success of The Public Enemy and Blonde Crazy forced Warner Bros.' hand.
The film was swiftly followed by The Crowd Roars and Winner Take All.
Historians also debate the nature of history as an end in itself, as well as its usefulness to give perspective on the problems of the present.
However, ancient cultural influences have helped spawn variant interpretations of the nature of history which have evolved over the centuries and continue to change today.
Herodotus, a 5th-century BC Greek historian, is often considered the "father of history" in the Western tradition, although he has also been criticized as the "father of lies".
In Middle English, the meaning of history was "story" in general.
In modern German, French, and most Germanic and Romance languages, which are solidly synthetic and highly inflected, the same word is still used to mean both "history" and "story".
In the words of Benedetto Croce, "All history is contemporary history".
Therefore, the constitution of the historian's archive is a result of circumscribing a more general archive by invalidating the usage of certain texts and documents (by falsifying their claims to represent the "true past").
The study of history has sometimes been classified as part of the humanities and at other times as part of the social sciences.
In the 20th century, French historian Fernand Braudel revolutionized the study of history, by using such outside disciplines as economics, anthropology, and geography in the study of global history.
In general, the sources of historical knowledge can be separated into three categories: what is written, what is said, and what is physically preserved, and historians often consult all three.
Archaeological finds rarely stand alone, with narrative sources complementing its discoveries.
For example, Mark Leone, the excavator and interpreter of historical Annapolis, Maryland, USA, has sought to understand the contradiction between textual documents idealizing "liberty" and the material record, demonstrating the possession of slaves and the inequalities of wealth made apparent by the study of the total historical environment.
It is possible for historians to concern themselves with both the very specific and the very general, although the modern trend has been toward specialization.
Thirdly, it may refer to why history is produced: the philosophy of history.
By whom was it produced (authorship)?
What is the evidential value of its contents (credibility)?
The historical method comprises the techniques and guidelines by which historians use primary sources and other evidence to research and then to write history.
Thucydides, unlike Herodotus, regarded history as being the product of the choices and actions of human beings, and looked at cause and effect, rather than as the result of divine intervention (though Herodotus was not wholly committed to this idea himself).
There were historical traditions and sophisticated use of historical method in ancient and medieval China.
Chinese historians of subsequent dynastic periods in China used his Shiji as the official format for historical texts, as well as for biographical literature.
Around 1800, German philosopher and historian Georg Wilhelm Friedrich Hegel brought philosophy and a more secular approach in historical study.
The originality of Ibn Khaldun was to claim that the cultural difference of another age must govern the evaluation of relevant historical material, to distinguish the principles according to which it might be possible to attempt the evaluation, and lastly, to feel the need for experience, in addition to rational principles, in order to assess a culture of the past.
His historical method also laid the groundwork for the observation of the role of state, communication, propaganda and systematic bias in history,H. Mowlana (2001). "
Dr. S.W. Akhtar (1997). "
For Ranke, historical data should be collected carefully, examined objectively and put together with critical rigor.
In the 20th century, academic historians focused less on epic nationalistic narratives, which often tended to glorify the nation or great men, to more objective and complex analyses of social and intellectual forces.
Many of the advocates of history as a social science were or are noted for their multi-disciplinary approach.
So far only one theory of history came from the pen of a professional Historian.
Intellectual historians such as Herbert Butterfield, Ernst Nolte and George Mosse have argued for the significance of ideas in history.
Scholars such as Martin Broszat, Ian Kershaw and Detlev Peukert sought to examine what everyday life was like for ordinary people in 20th-century Germany, especially in the Nazi period.
Feminist historians such as Joan Wallach Scott, Claudia Koonz, Natalie Zemon Davis, Sheila Rowbotham, Gisela Bock, Gerda Lerner, Elizabeth Fox-Genovese, and Lynn Hunt have argued for the importance of studying the experience of women in the past.
Another defence of history from post-modernist criticism was the Australian historian Keith Windschuttle's 1994 book, The Killing of History.
Historical omissions can occur in many ways and can have a profound effect on historical records.
Ancient history: the study from the beginning of human history until the Early Middle Ages.
Comparative history: historical analysis of social and cultural entities not confined to national boundaries.
Cultural history: the study of culture in the past.
Intellectual history: the study of ideas in the context of the cultures that produced them and their development over time.
Modern history: the study of the Modern Times, the era after the Middle Ages.
Palaeography: study of ancient texts.
Psychohistory: study of the psychological motivations of historical events.
Women's history: the history of female human beings.
Centuries and decades are commonly used periods and the time they represent depends on the dating system used.
To do this, historians often turn to geography.
For example, to explain why the ancient Egyptians developed a successful civilization, studying the geography of Egypt is essential.
History of the Americas is the collective history of North and South America, including Central America and the Caribbean.
History of the Caribbean begins with the oldest evidence where 7,000-year-old remains have been found.
History of Eurasia is the collective history of several distinct peripheral coastal regions: the Middle East, South Asia, East Asia, Southeast Asia, and Europe, linked by the interior mass of the Eurasian steppe of Central Asia and Eastern Europe.
History of East Asia is the study of the past passed down from generation to generation in East Asia.
History of Southeast Asia has been characterized as interaction between regional players and foreign powers.
The "old" social history before the 1960s was a hodgepodge of topics without a central theme, and it often included political movements, like Populism, that were "social" in the sense of being outside the elite system.
It examines the records and narrative descriptions of past knowledge, customs, and arts of a group of people.
This type of political history is the study of the conduct of international relations between states or across state boundaries over time.
It gained popularity in the United States, Japan and other countries after the 1980s with the realization that students need a broader exposure to the world as globalization proceeds.
Despite being a relatively new field, gender history has had a significant effect on the general study of history.
At Oxford and Cambridge, scholarship was downplayed.
The tutors dominated the debate until after the Second World War.
In the United States after World War I, a strong movement emerged at the university level to teach courses in Western Civilization, so as to give students a common heritage with Europe.
Many view the field from both perspectives.
In the United States, textbooks published by the same company often differ in content from state to state.
Academic historians have often fought against the politicization of the textbooks, sometimes with success.
A civilization (or civilisation) is a complex society that is characterized by urban development, social stratification, a form of government, and symbolic systems of communication (such as writing).
In this broad sense, a civilization contrasts with non-centralized tribal societies, including the cultures of nomadic pastoralists, Neolithic societies or hunter-gatherers; however, sometimes it also contrasts with the cultures found within civilizations themselves.
The fundamental treatise is Norbert Elias's The Civilizing Process (1939), which traces social mores from medieval courtly society to the Early Modern period.
Related words like "civility" developed in the mid-16th century.
In the late 1700s and early 1800s, during the French Revolution, "civilization" was used in the singular, never in the plural, and meant the progress of humanity as a whole.
Only in this generalized sense does it become possible to speak of a "medieval civilization", which in Elias's sense would have been an oxymoron.
Here, civilization, being more rational and socially driven, is not fully in accord with human nature, and "human wholeness is achievable only through the recovery of or approximation to an original discursive or prerational natural unity" (see noble savage).
Civilizations have been distinguished by their means of subsistence, types of livelihood, settlement patterns, forms of government, social stratification, economic systems, literacy and other cultural traits.
All civilizations have depended on agriculture for subsistence, with the possible exception of some early civilizations in Peru which may have depended upon maritime resources.
Grain surpluses have been especially important because grain can be stored for a long time.
However, in some places hunter-gatherers have had access to food surpluses, such as among some of the indigenous peoples of the Pacific Northwest and perhaps during the Mesolithic Natufian culture.
The word "civilization" is sometimes simply defined as "'living in cities'".
State societies are more stratified than other societies; there is a greater difference among the social classes.
Civilizations, with complex social hierarchies and organized, institutional governments.
Some people also acquire landed property, or private ownership of the land.
By the early Iron Age, contemporary civilizations developed money as a medium of exchange for increasingly complex transactions.
These people may not be personally acquainted with one another and their needs may not occur all at the same time.
The transition from simpler to more complex economies does not necessarily mean an improvement in the living standards of the populace.
The average stature of a population is a good measurement of the adequacy of its access to necessities, especially food.
Like money, the writing was necessitated by the size of the population of a city and the complexity of its commerce among people who are not all personally acquainted with each other.
These include organized religion, development in the arts, and countless new advances in science and technology.
These cultures are called by some "primitive", a term that is regarded by others as pejorative. "
Anthropologists today use the term "non-literate" to describe these peoples.
But civilization is also spread by the technical, material and social dominance that civilization engenders.
Civilizations tend to develop intricate cultures, including a state-based decision making apparatus, a literature, professional art, architecture, organized religion and complex customs of education, coercion and control associated with maintaining the elite.
The civilization in which someone lives is that person's broadest cultural identity.
The aim is to preserve the cultural heritage of humanity and also the cultural identity, especially in the case of war and armed conflict.
Early twentieth-century philosopher Oswald Spengler,Spengler, Oswald, Decline of the West: Perspectives of World History (1919) uses the German word Kultur, "culture", for what many call a "civilization".
Spengler states civilization is the beginning of the decline of a culture as "the most external and artificial states of which a species of developed humanity is capable".
Civilizations generally declined and fell, according to Toynbee, because of the failure of a "creative minority", through moral or religious decline, to meet some important challenge, rather than mere economic or environmental causes.
For example, trade networks were, until the nineteenth century, much larger than either cultural spheres or political spheres.
During the Uruk period, Guillermo Algaze has argued that trade relations connected Egypt, Mesopotamia, Iran and Afghanistan.
Different civilizations and societies all over the globe are economically, politically, and even culturally interdependent in many ways.
Central Civilization later expanded to include the entire Middle East and Europe, and then expanded to a global scale with European colonization, integrating the Americas, Australia, China and Japan by the nineteenth century.
This encouraged a secondary products revolution in which people used domesticated animals not just for meat, but also for milk, wool, manure and pulling ploughs and carts – a development that spread through the Eurasian Oecumene.
This area has been identified as having "inspired some of the most important developments in human history including the invention of the wheel, the planting of the first cereal crops and the development of the cursive script".
This climate change shifted the cost-benefit ratio of endemic violence between communities, which saw the abandonment of unwalled village communities and the appearance of walled cities, associated with the first civilizations.
The civilized urban revolution in turn was dependent upon the development of sedentism, the domestication of grains and animals, the permanence of settlements and development of lifestyles that facilitated economies of scale and accumulation of surplus production by certain social sectors.
Some focus on historical examples, and others on general theory.
For Gibbon, "The decline of Rome was the natural and inevitable effect of immoderate greatness.
Theodor Mommsen in his History of Rome suggested Rome collapsed with the collapse of the Western Roman Empire in 476 CE and he also tended towards a biological analogy of "genesis", "growth", "senescence", "collapse" and "decay".
Arnold J. Toynbee in his A Study of History suggested that there had been a much larger number of civilizations, including a small number of arrested civilizations, and that all civilizations tended to go through the cycle identified by Mommsen.
During the intermediate phase, the increasing population growth leads to the decrease of per capita production and consumption levels, it becomes more and more difficult to collect taxes, and state revenues stop growing, whereas the state expenditures grow due to the growth of the population controlled by the state.
Secular Cycles and Millennial Trends.
The fact that Rome needed to generate ever greater revenues to equip and re-equip armies that were for the first time repeatedly defeated in the field, led to the dismemberment of the Empire.
He argues that the collapse of the Maya has lessons for civilization today.
The energy expended to energy yield ratio is central to limiting the survival of civilizations.
Koneczny claimed that civilizations cannot be mixed into hybrids, an inferior civilization when given equal rights within a highly developed civilization will overcome it.
Cultural Historian Morris Berman suggests in Dark Ages America: the End of Empire that in the corporate consumerist United States, the very factors that once propelled it to greatness―extreme individualism, territorial and economic expansion, and the pursuit of material wealth―have pushed the United States across a critical threshold where collapse is inevitable.
The corrosion of these pillars, Jacobs argues, is linked to societal ills such as environmental crisis, racism and the growing gulf between rich and poor.
This need for civilizations to import ever more resources, he argues, stems from their over-exploitation and diminution of their own local resources.
In the graphic, Ma means "million years ago".)
Much of the Earth was molten because of frequent collisions with other bodies which led to extreme volcanism.
Recognizable humans emerged at most 2 million years ago, a vanishingly small period on the geological scale.
It is estimated that 99 percent of all species that ever lived on Earth, over five billion, have gone extinct.
The Earth's crust has constantly changed since its formation, as has life since its first appearance.
The Moon is formed around this time probably due to a protoplanet's collision into Earth.
The atmosphere is composed of volcanic and greenhouse gases.
Bacteria begin producing oxygen, shaping the third and current of Earth's atmospheres.
The early continents of Columbia, Rodinia and Pannotia, in that order, may have existed in this eon.
Gradually, life expands to land and familiar forms of plants, animals and fungi begin appearing, including annelids, insects and reptiles, hence the eon's name, which means "visible life".
It was composed of hydrogen and helium created shortly after the Big Bang 13.8 Ga (billion years ago) and heavier elements ejected by supernovae.
As the cloud began to accelerate, its angular momentum, gravity, and inertia flattened it into a protoplanetary disk perpendicular to its axis of rotation.
After more contraction, a T Tauri star ignited and evolved into the Sun.
Earth formed in this manner about 4.54 billion years ago (with an uncertainty of 1%) and was largely completed within 10–20 million years.
The proto-Earth grew by accretion until its interior was hot enough to melt the heavy, siderophile metals.
From crater counts on other celestial bodies, it is inferred that a period of intense meteorite impacts, called the Late Heavy Bombardment, began about 4.1 Ga, and concluded around 3.8 Ga, at the end of the Hadean.
By the beginning of the Archean, the Earth had cooled significantly.
New evidence suggests the Moon formed even later, 4.48 ± 0.02 Ga, or 70–110 million years after the start of the Solar System.
The collision released about 100 million times more energy than the more recent Chicxulub impact that is believed to have caused the extinction of the non-avian dinosaurs.
The giant impact hypothesis predicts that the Moon was depleted of metallic material, explaining its abnormal composition.
The initial crust, formed when the Earth's surface first solidified, totally disappeared from a combination of this fast Hadean plate tectonics and the intense impacts of the Late Heavy Bombardment.
These pieces of late Hadean and early Archean crust form the cores around which today's continents grew.
Cratons consist primarily of two alternating types of terranes.
For this reason, greenstones are sometimes seen as evidence for subduction during the Archean.
Now it is considered likely that many of the volatiles were delivered during accretion by a process known as impact degassing in which incoming bodies vaporize on impact.
Planetesimals at a distance of 1 astronomical unit (AU), the distance of the Earth from the Sun, probably did not contribute any water to the Earth because the solar nebula was too hot for ice to form and the hydration of rocks by water vapor would have taken too long.
Recent evidence suggests the oceans may have begun forming as early as 4.4 Ga. By the start of the Archean eon, they already covered much of the Earth.
Thus, the Sun has become 30% brighter in the last 4.5 billion years.
There are many models, but little consensus, on how life emerged from non-living chemicals; chemical systems created in the laboratory fall well short of the minimum complexity for a living organism.
Although atmospheric composition was probably different from that used by Miller and Urey, later experiments with more realistic compositions also managed to synthesize organic molecules.
RNA would later have been replaced by DNA, which is more stable and therefore can build longer genomes, expanding the range of capabilities a single organism can have.
A difficulty with the metabolism-first scenario is finding a way for organisms to evolve.
Research in 2003 reported that montmorillonite could also accelerate the conversion of fatty acids into "bubbles", and that the bubbles could encapsulate RNA attached to the clay.
This LUA cell is the ancestor of all life on Earth today.
The change to an oxygen-rich atmosphere was a crucial development.
They used fermentation, the breakdown of more complex compounds into less complex compounds with less energy, and used the energy so liberated to grow and reproduce.
Most of the life that covers the surface of the Earth depends directly or indirectly on photosynthesis.
To supply the electrons in the circuit, hydrogen is stripped from water, leaving oxygen as a waste product.
The simpler anoxygenic form arose about 3.8 Ga, not long after the appearance of life.
At first, the released oxygen was bound up with limestone, iron, and other minerals.
Though each cell only produced a minute amount of oxygen, the combined metabolism of many cells over a vast time transformed Earth's atmosphere to its current state.
The ozone layer absorbed, and still absorbs, a significant amount of the ultraviolet radiation that once had passed through the atmosphere.
As a result, the Earth began to receive more heat from the Sun in the Proterozoic eon.
Glacial deposits found in South Africa date back to 2.2 Ga, at which time, based on paleomagnetic evidence, they must have been located near the equator.
The Huronian ice age might have been caused by the increased oxygen concentration in the atmosphere, which caused the decrease of methane (CH4) in the atmosphere.
However, the term Snowball Earth is more commonly used to describe later extreme ice ages during the Cryogenian period.
Carbon dioxide combines with rain to weather rocks to form carbonic acid, which is then washed out to sea, thus extracting the greenhouse gas from the atmosphere.
The Bacteria domain probably first split off from the other forms of life (sometimes called Neomura), but this supposition is controversial.
The earliest fossils possessing features typical of fungi date to the Paleoproterozoic era, some 2.4 ago; these multicellular benthic organisms had filamentous structures capable of anastomosis.
Perhaps the large cell attempted to digest the smaller one but failed (possibly due to the evolution of prey defenses).
Using oxygen, it metabolized the larger cell's waste products and derived more energy.
Soon, a stable symbiosis developed between the large cell and the smaller cells inside it.
A similar event occurred with photosynthetic cyanobacteria entering large heterotrophic cells and becoming chloroplasts.
Besides the well-established endosymbiotic theory of the cellular origin of mitochondria and chloroplasts, there are theories that cells led to peroxisomes, spirochetes led to cilia and flagella, and that perhaps a DNA virus led to the cell nucleus, though none of them are widely accepted.
Around 1.1 Ga, the supercontinent Rodinia was assembling.
Although the division between a colony with specialized cells and a multicellular organism is not always clear, around 1 billion years ago, the first multicellular plants emerged, probably green algae.
Paleomagnetic poles are supplemented by geologic evidence such as orogenic belts, which mark the edges of ancient plates, and past distributions of flora and fauna.
About 1000 to 830 Ma, most continental mass was united in the supercontinent Rodinia.
The hypothetical supercontinent is sometimes referred to as Pannotia or Vendia.
The intensity and mechanism of both glaciations are still under investigation and harder to explain than the early Proterozoic Snowball Earth.
Because CO2 is an important greenhouse gas, climates cooled globally.
Increased volcanic activity resulted from the break-up of Rodinia at about the same time.
The new forms of life, called Ediacara biota, were larger and more diverse than ever.
It consists of three eras: The Paleozoic, Mesozoic, and Cenozoic, and is the time when multi-cellular life greatly diversified into almost all the organisms known today.
This causes the sea level to rise.
Traces of glaciation from this period are only found on former Gondwana.
The continents Laurentia and Baltica collided between 450 and 400 Ma, during the Caledonian Orogeny, to form Laurussia (also known as Euramerica).
The collision of Siberia with Laurussia caused the Uralian Orogeny, the collision of Gondwana with Laurussia is called the Variscan or Hercynian Orogeny in Europe or the Alleghenian Orogeny in North America.
Whereas the Ediacaran life forms appear yet primitive and not easy to put in any modern group, at the end of the Cambrian most modern phyla were already present.
Some of these Cambrian groups appear complex but are seemingly quite different from modern life; examples are Anomalocaris and Haikouichthys.
A creature that could have been the ancestor of the fishes, or was probably closely related to it, was Pikaia.
Fish, the earliest vertebrates, evolved in the oceans around 530 Ma.
The oldest fossils of land fungi and plants date to 480–460 Ma, though molecular evidence suggests the fungi may have colonized the land as early as 1000 Ma and the plants 700 Ma.
Fins evolved to become limbs that the first tetrapods used to lift their heads out of the water to breathe air.
Eventually, some of them became so well adapted to terrestrial life that they spent their adult lives on land, although they hatched in the water and returned to lay their eggs.
Plants evolved seeds, which dramatically accelerated their spread on land, around this time (by approximately 360 Ma).
Another 30 million years (310 Ma) saw the divergence of the synapsids (including mammals) from the sauropsids (including birds and reptiles).
The Triassic–Jurassic extinction event at 200 Ma spared many of the dinosaurs, and they soon became dominant among the vertebrates.
60% of marine invertebrates became extinct and 25% of all families.
The third mass extinction was the Permian-Triassic, or the Great Dying, event was possibly caused by some combination of the Siberian Traps volcanic event, an asteroid impact, methane hydrate gasification, sea level fluctuations, and a major anoxic event.
This was by far the deadliest extinction ever, with about 57% of all families and 83% of all genera killed.
By the early Paleocene the earth recovered from the extinction, and mammalian diversity increased.
Grassless savanna began to predominate much of the landscape, and mammals such as Andrewsarchus rose up to become the largest known terrestrial predatory mammal ever, and early whales like Basilosaurus took control of the seas.
Giant ungulates like Paraceratherium and Deinotherium evolved to rule the grasslands.
The Tethys Sea was closed off by the collision of Africa and Europe.
The land bridge allowed the isolated creatures of South America to migrate over to North America, and vice versa.
The ice ages led to the evolution of modern man in Saharan Africa and expansion.
It is believed by many that a huge migration took place along Beringia which is why, today, there are camels (which evolved and became extinct in North America), horses (which evolved and became extinct in North America), and Native Americans.
Brain size increased rapidly, and by 2 Ma, the first animals classified in the genus Homo had appeared.
The ability to control fire probably began in Homo erectus (or Homo ergaster), probably at least 790,000 years ago but perhaps as early as 1.5 Ma.
It is more difficult to establish the origin of language; it is unclear whether Homo erectus could speak or if that capability had not begun until Homo sapiens.
Social skills became more complex, language became more sophisticated, and tools became more elaborate.
The first humans to show signs of spirituality are the Neanderthals (usually classified as a separate species with no surviving descendants); they buried their dead, often with no sign of food or tools.
As language became more complex, the ability to remember and communicate information resulted, according to a theory proposed by Richard Dawkins, in a new replicator: the meme.
Between 8500 and 7000 BC, humans in the Fertile Crescent in the Middle East began the systematic husbandry of plants and animals: agriculture.
However, among those civilizations that did adopt agriculture, the relative stability and increased productivity provided by farming allowed the population to expand.
This led to Earth's first civilization at Sumer in the Middle East, between 4000 and 3000 BC.
Humans no longer had to spend all their time working for survival, enabling the first specialized occupations (e.g. craftsmen, merchants, priests, etc.).
By around 500 BC, there were advanced civilizations in the Middle East, Iran, India, China, and Greece, at times expanding, at times entering into decline.
This civilization developed in warfare, arts, science, mathematics and in architect.
The Roman Empire was Christianized by Emperor Constantine in the early 4th century and declined by the end of the 5th.
The House of Wisdom was established in Abbasid-era Baghdad, Iraq.
In the 14th century, the Renaissance began in Italy with advances in religion, art, and science.
European civilization began to change beginning in 1500, leading to the scientific and industrial revolutions.
From 1914 to 1918 and 1939 to 1945, nations around the world were embroiled in world wars.
After the war, many new states were formed, declaring or being granted independence in a period of decolonization.
Technological developments include nuclear weapons, computers, genetic engineering, and nanotechnology.
Major concerns and problems such as disease, war, poverty, violent radicalism, and recently, human-caused climate change have risen as the world population increases.
Human history, or recorded history, is the narrative of humanity's past.
The Neolithic saw the Agricultural Revolution begin, between 10,000 and 5000 BCE, in the Near East's Fertile Crescent.
As farming developed, grain agriculture became more sophisticated and prompted a division of labour to store food between growing seasons.
Hinduism developed in the late Bronze Age on the Indian subcontinent.
Post-classical history (the "Middle Ages," c. 500–1500 CE,) witnessed the rise of Christianity, the Islamic Golden Age (c. 750 CE – c. 1258 CE), and the Timurid and Italian Renaissances (from around 1300 CE).
By the 18th century, the accumulation of knowledge and technology had reached a critical mass that brought about the Industrial Revolution and began the late modern period, which started around 1800 and has continued through the present.
Anatomically modern humans arose in Africa about 300,000 years ago, and achieved behavioral modernity about 50,000 years ago.
Perhaps as early as 1.8 million years ago, but certainly by 500,000 years ago, humans began to use fire for heat and cooking.
Paleolithic humans lived as hunter-gatherers, and were generally nomadic.
The rapid expansion of humankind to North America and Oceania took place at the climax of the most recent ice age.
The Yellow River valley in China cultivated millet and other cereal crops by about 7000 BCE; the Yangtze valley domesticated rice earlier, by at least 8000 BCE.
Metalworking, was first used in the creation of copper tools and ornaments around 6000 BCE.
Cities were centres of trade, manufacturing and political power.
The development of cities was synonymous with the rise of civilization.
These cultures variously invented the wheel, mathematics, bronze-working, sailing boats, the potter's wheel, woven cloth, construction of monumental buildings, and writing.
Typical of the Neolithic was a tendency to worship anthropomorphic deities.
These settlements were concentrated in fertile river valleys: the Tigris and Euphrates in Mesopotamia, the Nile in Egypt, the Indus in the Indian subcontinent, and the Yangtze and Yellow Rivers in China.
Cuneiform writing began as a system of pictographs, whose pictorial representations eventually became simplified and more abstract.
Transport was facilitated by waterways—by rivers and seas.
These developments led to the rise of territorial states and empires.
In Crete the Minoan civilization had entered the Bronze Age by 2700 BCE and is regarded as the first civilization in Europe.
Over the following millennia, civilizations developed across the world.
In India, this era was the Vedic period (1750-600 BCE), which laid the foundations of Hinduism and other cultural aspects of early Indian society, and ended in the 6th century BCE.
During the formative stage in Mesoamerica (about 1500 BCE to 500 CE), more complex and centralized civilizations began to develop, mostly in what is now Mexico, Central America, and Peru.
Karl Jaspers' Axial-Age theory also includes Persian Zoroastrianism, but other scholars dispute his timeline for Zoroastrianism.)
These were Taoism, Legalism, and Confucianism.
The great empires depended on military annexation of territory and on the formation of defended settlements to become agricultural centres.
There were a number of regional empires during this period.
The Median Empire gave way to successive Iranian empires, including the Achaemenid Empire (550–330 BCE), the Parthian Empire (247 BCE–224 CE), and the Sasanian Empire (224–651 CE).
Later, Alexander the Great (356–323 BCE), of Macedon, founded an empire of conquest, extending from present-day Greece to present-day India.
From the 3rd century CE, the Gupta dynasty oversaw the period referred to as ancient India's Golden Age.
The ensuing stability contributed to heralding in the golden age of Hindu culture in the 4th and 5th centuries.
By the time of Augustus (63 BCE – 14 CE), the first Roman Emperor, Rome had already established dominion over most of the Mediterranean.
The Western empire would fall, in 476 CE, to German influence under Odoacer.
The Han dynasty was comparable in power and influence to the Roman Empire that lay at the other end of the Silk Road.
As with other empires during the Classical Period, Han China advanced significantly in the areas of government, education, mathematics, astronomy, technology, and many others.
Successful regional empires were also established in the Americas, arising from cultures established as early as 2500 BCE.
The great Mayan city-states slowly rose in number and prominence, and Maya culture spread throughout the Yucatán and surrounding areas.
There were, however, in some regions, periods of rapid technological progress.
China's Han dynasty fell into civil war in 220 CE, beginning the Three Kingdoms period, while its Roman counterpart became increasingly decentralized and divided about the same time in what is known as the Crisis of the Third Century.
The development of the stirrup and the breeding of horses strong enough to carry a fully armed archer made the nomads a constant threat to the more settled civilizations.
The remaining part of the Roman Empire, in the eastern Mediterranean, continued as what came to be called the Byzantine Empire.
The era is commonly dated from the 5th-century fall of the Western Roman Empire, which fragmented into many separate kingdoms, some of which would later be confederated under the Holy Roman Empire.
South Asia saw a series of middle kingdoms of India, followed by the establishment of Islamic empires in India.
This allowed Africa to join the Southeast Asia trading system, bringing it contact with Asia; this, along with Muslim culture, resulted in the Swahili culture.
This was also a cultural battle, with the Byzantine Hellenistic and Christian culture competing against the Persian Iranian traditions and Zoroastrian religion.
From their centre on the Arabian Peninsula, Muslims began their expansion during the early Postclassical Era.
Much of this learning and development can be linked to geography.
The influence held by Muslim merchants over African-Arabian and Arabian-Asian trade routes was tremendous.
Motivated by religion and dreams of conquest, European leaders launched a number of Crusades to try to roll back Muslim power and retake the Holy Land.
Arab domination of the region ended in the mid-11th century with the arrival of the Seljuq Turks, migrating south from the Turkic homelands in Central Asia.
The region will later be called the Barbary Coast and will host pirates and privateers who will use several North African ports for their raids against the coastal towns of several European countries in search of slaves to be sold in North African markets as part of the Barbary slave trade.
In the 8th century, Islam began to penetrate the region and soon became the sole faith of most of the population, though Buddhism remained strong in the east.
After Genghis Khan died in 1227, most of Central Asia continued to be dominated by a successor state, Chagatai Khanate.
The region then became divided into a series of smaller khanates that were created by the Uzbeks.
The barbarian invaders formed their own new kingdoms in the remains of the Western Roman Empire.
Christianity expanded in western Europe, and monasteries were founded.
Manorialism, the organization of peasants into villages that owed rents and labour service to nobles, and feudalism, a political structure whereby knights and lower-status nobles owed military service to their overlords in return for the right to rents from lands and manors, were two of the ways of organizing medieval society that developed during the High Middle Ages.
Italian merchants imported slaves to work in households or in sugar processing.
Famine, plague, and war devastated the population of western Europe.
They eventually gave way to the Zagwe dynasty who are famed for their rock cut architecture at Lalibela.
They controlled the trans-Saharan trade in gold, ivory, salt and slaves.
Central Africa saw the birth of several states, including the Kingdom of Kongo.
They built large defensive stone structures without mortar such as Great Zimbabwe, capital of the Kingdom of Zimbabwe, Khami, capital of Kingdom of Butua, and Danangombe (Dhlo-Dhlo), capital of the Rozvi Empire.
The ninth century saw a Tripartite Struggle for control of northern India, among the Pratihara Empire, the Pala Empire, and the Rashtrakuta Empire.
The Tang dynasty eventually splintered, however, and after half a century of turmoil the Song dynasty reunified China, when it was, according to William McNeill, the "richest, most skilled, and most populous country on earth".
After about a century of Mongol Yuan dynasty rule, the ethnic Chinese reasserted control with the founding of the Ming dynasty (1368).
The Nara period of the 8th century marked the emergence of a strong Japanese state and is often portrayed as a golden age.
The feudal period of Japanese history, dominated by powerful regional lords (daimyos) and the military rule of warlords (shoguns) such as the Ashikaga shogunate and Tokugawa shogunate, stretched from 1185 to 1868.
Silla conquered Baekje in 660, and Goguryeo in 668, marking the beginning of the Northern and Southern States period (남북국시대), with Unified Silla in the south and Balhae, a successor state to Goguryeo, in the north.
Starting in the 9th century, the Bagan Kingdom rose to prominence in modern Myanmar.
The Ancestral Puebloans and their predecessors (9th – 13th centuries) built extensive permanent settlements, including stone structures that would remain the largest buildings in North America until the 19th century.
In South America, the 14th and 15th centuries saw the rise of the Inca.
The Scientific Revolution received impetus from Johannes Gutenberg's introduction to Europe of printing, using movable type, and from the invention of the telescope and microscope.
The late modern period continues either to the end of World War II, in 1945, or to the present.
The early Modern period was characterized by the rise of science, and by increasingly rapid technological progress, secularized civic politics, and the nation state.
During the early modern period, Europe was able to regain its dominance; historians still debate the causes.
It had developed an advanced monetary economy by 1000 CE.
It enjoyed a technological advantage and had a monopoly in cast iron production, piston bellows, suspension bridge construction, printing, and the compass.
One theory of Europe's rise holds that Europe's geography played an important role in its success.
This gave Europe some degree of protection from the peril of Central Asian invaders.
The Golden Age of Islam was ended by the Mongol sack of Baghdad in 1258.
Geography contributed to important geopolitical differences.
By contrast, Europe was almost always divided into a number of warring states.
Nearly all the agricultural civilizations have been heavily constrained by their environments.
Technological advance and the wealth generated by trade gradually brought about a widening of possibilities.
Europe's maritime expansion unsurprisingly—given the continent's geography—was largely the work of its Atlantic states: Portugal, Spain, England, France, and the Netherlands.
In North Africa, the Saadi Sultanate remained as an independent Berber state until 1659.
The Swahili coast declined after coming under the Portuguese Empire and later the Omani Empire.
The South African Kingdom of Zimbabwe gave way to smaller kingdoms such as Mutapa, Butua, and Rozvi.
Other civilizations in Africa advanced during this period.
Japan experienced its Azuchi–Momoyama period (1568–1603), followed by the Edo period (1603–1868).
The Johor Sultanate, centred on the southern tip of the Malay Peninsula, became the dominant trading power in the region.
Russia made incursions onto the northwest coast of North America, with a first colony in present-day Alaska in 1784, and the outpost of Fort Ross in present-day California in 1812.
The Industrial Revolution began in Great Britain and used new modes of production—the factory, mass production, and mechanization—to manufacture a wide array of goods faster and using less labour than previously required.
After Europeans had achieved influence and control over the Americas, imperial activities turned to the lands of Asia and Oceania.
The British also colonized Australia, New Zealand and South Africa with large numbers of British colonists emigrating to these colonies.
Within Europe, economic and military challenges created a system of nation states, and ethno-linguistic groupings began to identify themselves as distinctive nations with aspirations for cultural and political autonomy.
Meanwhile, industrial pollution and environmental damage, present since the discovery of fire and the beginning of civilization, accelerated drastically.
Much of the rest of the world was influenced by heavily Europeanized nations: the United States and Japan.
World War I led to the collapse of four empires – Austria-Hungary, the German Empire, the Ottoman Empire, and the Russian Empire – and weakened the United Kingdom and France.
Ongoing national rivalries, exacerbated by the economic turmoil of the Great Depression, helped precipitate World War II.
The Cold War ended peacefully in 1991 after the Pan-European Picnic, the subsequent fall of the Iron Curtain and the Berlin Wall, and the collapse of the Eastern Bloc and the Warsaw Pact.
In the early postwar decades, the colonies in Asia and Africa of the Belgian, British, Dutch, French, and other west European empires won their formal independence.
The European Union's effectiveness was handicapped by the immaturity of its common economic and political institutions, somewhat comparable to the inadequacy of United States institutions under the Articles of Confederation prior to the adoption of the Constitution of the United States that came into force in 1789.
In the decades after World War II, these advances led to jet travel, artificial satellites with innumerable applications including the Global Positioning System (GPS), and the Internet.
Worldwide competition for natural resources has risen due to growing populations and industrialization, especially in India, China, and Brazil.
An archive is an accumulation of historical records – in any media – or the physical facility in which they are located.
They have been metaphorically defined as "the secretions of an organism", and are distinguished from documents that have been consciously written or created to communicate a particular message to posterity.
This means that archives are quite distinct from libraries with regard to their functions and organization, although archival collections can often be found within library buildings.
Archaeologists have discovered archives of hundreds (and sometime thousands) of clay tablets going back to the third and second millennia BC in sites like Ebla, Mari, Amarna, Hattusas, Ugarit, and Pylos.
However, they have been lost, since documents written on materials like papyrus and paper deteriorated at a faster pace, unlike their stone tablet counterparts.
England after 1066 developed archives and archival research methods.
While there are many kinds of archives, the most recent census of archivists in the United States identifies five major types: academic, business (for profit), government, non-profit, and other.
Access to the collections in these archives is usually by prior appointment only; some have posted hours for making inquiries.
Examples of prominent business archives in the United States include Coca-Cola (which also owns the separate museum World of Coca-Cola), Procter and Gamble, Motorola Heritage Services and Archives, and Levi Strauss & Co. These corporate archives maintain historic documents and items related to the history and administration of their companies.
Workers in these types of archives may have any combination of training and degrees, from either a history or library background.
In the United States, National Archives and Records Administration (NARA) maintains central archival facilities in the District of Columbia and College Park, Maryland, with regional facilities distributed throughout the United States.
In the UK, the National Archives (formerly known as the Public Record Office) is the government archive for England and Wales.
Put together, the total volume of archives under the supervision of the French Archives Administration is the largest in the world.
Archdioceses, dioceses, and parishes also have archives in the Roman Catholic and Anglican Churches.
Often these institutions rely on grant funding from the government as well as the private funds.
Many museums keep archives in order to prove the provenance of their pieces.
This was a separate figure from the 1.3% that identified themselves as self-employed.
The archive's mission is to gather stories from women who want to express themselves, and want their stories heard.
The archives of an organization (such as a corporation or government) tend to contain other types of records, such as administrative files, business records, memos, official correspondence, and meeting minutes.
Many of these donations have yet to be cataloged, but are currently in the process of being digitally preserved and made available to the public online.
International partners for archives are UNESCO and Blue Shield International in accordance with the Hague Convention for the Protection of Cultural Property from 1954 and its 2nd Protocol from 1999.
Page, Morgan M. "One from the Vaults: Gossip, Access, and Trans History-Telling."
An example of this is Morgan M. Page’s description of disseminating transgender history directly to trans people through various social media and networking platforms like tumblr, Twitter, and Instagram, as well as via podcast.
With the options available through counter-archiving, there is the potential to "challenge traditional conceptions of history" as they are perceived within contemporary archives, which creates space for narratives that are often not present in many archival materials.
A biography, or simply bio, is a detailed description of a person's life.
Biographical works are usually non-fiction, but fiction can also be used to portray a person's life.
Another well-known collection of ancient biographies is De vita Caesarum ("On the Lives of the Caesars") by Suetonius, written about AD 121 in the time of the emperor Hadrian.
Hermits, monks, and priests used this historic period to write biographies.
One significant secular example of a biography from this period is the life of Charlemagne by his courtier Einhard.
They contained more social data for a large segment of the population than other works of that period.
By the late Middle Ages, biographies became less church-oriented in Europe as biographies of kings, knights, and tyrants began to appear.
Following Malory, the new emphasis on humanism during the Renaissance promoted a focus on secular subjects, such as artists and poets, and encouraged writing in the vernacular.
Two other developments are noteworthy: the development of the printing press in the 15th century and the gradual increase in literacy.
Influential in shaping popular conceptions of pirates, A General History of the Pyrates (1724), by Charles Johnson, is the prime source for the biographies of many well-known pirates.
Carlyle asserted that the lives of great human beings were essential to understanding society and its institutions.
Boswell's work was unique in its level of research, which involved archival study, eye-witness accounts and interviews, its robust and attractive narrative, and its honest depiction of all aspects of Johnson's life and character – a formula which serves as the basis of biographical literature to this day.
However, the number of biographies in print experienced a rapid growth, thanks to an expanding reading public.
Periodicals began publishing a sequence of biographical sketches.
Sociological" biographies conceived of their subjects' actions as the result of the environment, and tended to downplay individuality.
The conventional concept of heroes and narratives of success disappeared in the obsession with psychological explorations of personality.
Up until this point, as Strachey remarked in the preface, Victorian biographies had been "as familiar as the cortège of the undertaker", and wore the same air of "slow, funereal barbarism."
The book achieved worldwide fame due to its irreverent and witty style, its concise and factually accurate nature, and its artistic prose.
Robert Graves (I, Claudius, 1934) stood out among those following Strachey's model of "debunking biographies."
By World War I, cheap hard-cover reprints had become popular.
Along with documentary biographical films, Hollywood produced numerous commercial films based on the lives of famous people.
Unlike books and films, they often do not tell a chronological narrative: instead they are archives of many discrete media elements related to an individual person, including video clips, photographs, and text articles.
General "life writing" techniques are a subject of scholarly study.
The information can come from "oral history, personal narrative, biography and autobiography” or "diaries, letters, memoranda and other materials".
European-style castles originated in the 9th and 10th centuries, after the fall of the Carolingian Empire resulted in its territory being divided among individual lords and princes.
Urban castles were used to control the local populace and important travel routes, and rural castles were often situated near features that were integral to life in the community, such as mills, fertile land, or a water source.
In the late 12th and early 13th centuries, a scientific approach to castle defence emerged.
These changes in defence have been attributed to a mixture of castle technology from the Crusades, such as concentric fortification, and inspiration from earlier defences, such as Roman forts.
Although gunpowder was introduced to Europe in the 14th century, it did not significantly affect castle building until the 15th century, when artillery became powerful enough to break through stone walls.
Feudalism was the link between a lord and his vassal where, in return for military service and the expectation of loyalty, the lord would grant the vassal land.
Castles served a range of purposes, the most important of which were military, administrative, and domestic.
As William the Conqueror advanced through England, he fortified key positions to secure the land he had taken.
A castle could act as a stronghold and prison but was also a place where a knight or lord could entertain his peers.
In different areas of the world, analogous structures shared features of fortification and other defining characteristics associated with the concept of a castle, though they originated in different periods and circumstances and experienced differing evolutions and influences.
By the 16th century, when Japanese and European cultures met, fortification in Europe had moved beyond castles and relied on innovations such as the Italian trace italienne and star forts.
The excavation of earth to make the mound left a ditch around the motte, called a moat (which could be either wet or dry).
It was a common feature of castles, and most had at least one.
Water was supplied by a well or cistern.
Although often associated with the motte-and-bailey type of castle, baileys could also be found as independent defensive structures.
Keep" was not a term used in the medieval period – the term was applied from the 16th century onwards – instead "donjon" was used to refer to great towers, or turris in Latin.
Although often the strongest part of a castle and a last place of refuge if the outer defences fell, the keep was not left empty in case of attack but was used as a residence by the lord who owned the castle, or his guests or representatives.
Walkways along the tops of the curtain walls allowed defenders to rain missiles on enemies below, and battlements gave them further protection.
The front of the gateway was a blind spot and to overcome this, projecting towers were added on each side of the gate in a style similar to that developed by the Romans.
The passage through the gatehouse was lengthened to increase the amount of time an assailant had to spend under fire in a confined space and unable to retaliate.
They were most likely used to drop objects on attackers, or to allow water to be poured on fires to extinguish them.
A smaller horizontal opening could be added to give an archer a better view for aiming.
The earliest fortifications originated in the Fertile Crescent, the Indus Valley, Egypt, and China where settlements were protected by large walls.
Many earthworks survive today, along with evidence of palisades to accompany the ditches.
Although primitive, they were often effective, and were only overcome by the extensive use of siege engines and other siege warfare techniques, such as at the Battle of Alesia.
Discussions have typically attributed the rise of the castle to a reaction to attacks by Magyars, Muslims, and Vikings and a need for private defence.
Some high concentrations of castles occur in secure places, while some border regions had relatively few castles.
Building the hall in stone did not necessarily make it immune to fire as it still had windows and a wooden door.
Castles were not just defensive sites but also enhanced a lord's control over his lands.
In 864 the King of West Francia, Charles the Bald, prohibited the construction of castella without his permission and ordered them all to be destroyed.
Switzerland is an extreme case of there being no state control over who built castles, and as a result there were 4,000 in the country.
In 950 Provence was home to 12 castles, by 1000 this figure had risen to 30, and by 1030 it was over 100.
In the early 11th century, the motte and keep – an artificial mound with a palisade and tower on top – was the most common form of castle in Europe, everywhere except Scandinavia.
Although stone construction would later become common elsewhere, from the 11th century onwards it was the primary building material for Christian castles in Spain, while at the same time timber was still the dominant building material in north-west Europe.
Before the 12th century castles were as uncommon in Denmark as they had been in England before the Norman Conquest.
Their decoration emulated Romanesque architecture, and sometimes incorporated double windows similar to those found in church bell towers.
Although superseded by their stone successors, timber and earthwork castles were by no means useless.
Until the late 12th century castles generally had few towers; a gateway with few defensive features such as arrowslits or a portcullis; a great keep or donjon, usually square and without arrowslits; and the shape would have been dictated by the lay of the land (the result was often irregular or curvilinear structures).
The towers would have protruded from the walls and featured arrowslits on each level to allow archers to target anyone nearing or at the curtain wall.
Where keeps did exist, they were no longer square but polygonal or cylindrical.
Probably developed in the 12th century, the towers provided flanking fire.
It seemed that the Crusaders had learned much about fortification from their conflicts with the Saracens and exposure to Byzantine architecture.
Legends were discredited, and in the case of James of Saint George it was proven that he came from Saint-Georges-d'Espéranche, in France.
The castle builders of Western Europe were aware of and influenced by Roman design; late Roman coastal forts on the English "Saxon Shore" were reused and in Spain the wall around the city of Ávila imitated Roman architecture when it was built in 1091.
An example of this approach is Kerak.
The castles they founded to secure their acquisitions were designed mostly by Syrian master-masons.
While castles were used to hold a site and control movement of armies, in the Holy Land some key strategic positions were left unfortified.
Design varied not just between orders, but between individual castles, though it was common for those founded in this period to have concentric defences.
If assailants made it past the first line of defence they would be caught in the killing ground between the inner and outer walls and have to assault the second wall.
For instance, it was common in Crusader castles to have the main gate in the side of a tower and for there to be two turns in the passageway, lengthening the time it took for someone to reach the outer enclosure.
Although there were hundreds of wooden castles in Prussia and Livonia, the use of bricks and mortar was unknown in the region before the Crusaders.
Arrowslits did not compromise the wall's strength, but it was not until Edward I's programme of castle building that they were widely adopted in Europe.
Although machicolations performed the same purpose as the wooden galleries, they were probably an Eastern invention rather than an evolution of the wooden form.
Conflict and interaction between the two groups led to an exchange of architectural ideas, and Spanish Christians adopted the use of detached towers.
French historian François Gebelin wrote: "The great revival in military architecture was led, as one would naturally expect, by the powerful kings and princes of the time; by the sons of William the Conqueror and their descendants, the Plantagenets, when they became dukes of Normandy.
The new castles were generally of a lighter build than earlier structures and presented few innovations, although strong sites were still created such as that of Raglan in Wales.
These guns were too heavy for a man to carry and fire, but if he supported the butt end and rested the muzzle on the edge of the gun port he could fire the weapon.
This adaptation is found across Europe, and although the timber rarely survives, there is an intact example at Castle Doornenburg in the Netherlands.
Other types of port, though less common, were horizontal slits – allowing only lateral movement – and large square openings, which allowed greater movement.
Ham is an example of the trend for new castles to dispense with earlier features such as machicolations, tall towers, and crenellations.
In an effort to make them more effective, guns were made ever bigger, although this hampered their ability to reach remote castles.
While this sufficed for new castles, pre-existing structures had to find a way to cope with being battered by cannon.
A solution to this was to pull down the top of a tower and to fill the lower part with the rubble to provide a surface for the guns to fire from.
From this evolved star forts, also known as trace italienne.
The second choice proved to be more popular as it became apparent that there was little point in trying to make the site genuinely defensible in the face of cannon.
Some true castles were built in the Americas by the Spanish and French colonies.
Among other defensive structures (including forts and citadels), castles were also built in New France towards the end of the 17th century.
The manor house and stables were within a fortified bailey, with a tall round turret in each corner.
Although castle construction faded towards the end of the 16th century, castles did not necessarily all fall out of use.
In other cases they still had a role in defence.
In later conflicts, such as the English Civil War (1641–1651), many castles were refortified, although subsequently slighted to prevent them from being used again.
Revival or mock castles became popular as a manifestation of a Romantic interest in the Middle Ages and chivalry, and as part of the broader Gothic Revival in architecture.
This was because to be faithful to medieval design would have left the houses cold and dark by contemporary standards.
Follies were similar, although they differed from artificial ruins in that they were not part of a planned landscape, but rather seemed to have no reason for being built.
A castle with earthen ramparts, a motte, timber defences and buildings could have been constructed by an unskilled workforce.
The cost of building a castle varied according to factors such as their complexity and transport costs for material.
In the middle were castles such as Orford, which was built in the late 12th century for UK£1,400, and at the upper end were those such as Dover, which cost about UK£7,000 between 1181 and 1191.
The cost of a large castle built over this time (anywhere from UK£1,000 to UK£10,000) would take the income from several manors, severely impacting a lord's finances.
Medieval machines and inventions, such as the treadwheel crane, became indispensable during construction, and techniques of building wooden scaffolding were improved upon from Antiquity.
Many countries had both timber and stone castles, however Denmark had few quarries and as a result most of its castles are earth and timber affairs, or later on built from brick.
For example, when Tattershall Castle was built between 1430 and 1450, there was plenty of stone available nearby, but the owner, Lord Cromwell, chose to use brick.
He relied on the support of those below him, as without the support of his more powerful tenants a lord could expect his power to be undermined.
This especially applied to royalty, who sometimes owned land in different countries.
Royal households took essentially the same form as baronial households, although on a much larger scale and the positions were more prestigious.
As social centres castles were important places for display.
Castles have been compared with cathedrals as objects of architectural pride, and some castles incorporated gardens as ornamental features.
Courtly love was the eroticisation of love between the nobility.
The legend of Tristan and Iseult is one example of stories of courtly love told in the Middle Ages.
The purpose of marriage between the medieval elites was to secure land.
This derives from the image of the castle as a martial institution, but most castles in England, France, Ireland, and Scotland were never involved in conflicts or sieges, so the domestic life is a neglected facet.
For instance many castles are located near Roman roads, which remained important transport routes in the Middle Ages, or could lead to the alteration or creation of new road systems in the area.
Urban castles were particularly important in controlling centres of population and production, especially with an invading force, for instance in the aftermath of the Norman Conquest of England in the 11th century the majority of royal castles were built in or near towns.
Rural castles were often associated with mills and field systems due to their role in managing the lord's estate, which gave them greater influence over resources.
Not only were they practical in that they ensured a water supply and fresh fish, but they were a status symbol as they were expensive to build and maintain.
The benefits of castle building on settlements was not confined to Europe.
Settlements could also grow naturally around a castle, rather than being planned, due to the benefits of proximity to an economic centre in a rural landscape and the safety given by the defences.
They were usually located near any existing town defences, such as Roman walls, although this sometimes resulted in the demolition of structures occupying the desired site.
When the Normans invaded Ireland, Scotland, and Wales in the 11th and 12th centuries, settlement in those countries was predominantly non-urban, and the foundation of towns was often linked with the creation of a castle.
This signified a close relationship between feudal lords and the Church, one of the most important institutions of medieval society.
Another example is that of the 14th-century Bodiam Castle, also in England; although it appears to be a state of the art, advanced castle it is in a site of little strategic importance, and the moat was shallow and more likely intended to make the site appear impressive than as a defence against mining.
Garrisons were expensive and as a result often small unless the castle was important.
In 1403, a force of 37 archers successfully defended Caernarfon Castle against two assaults by Owain Glyndŵr's allies during a long siege, demonstrating that a small force could be effective.
Under him would have been knights who by benefit of their military training would have acted as a type of officer class.
It was more efficient to starve the garrison out than to assault it, particularly for the most heavily defended sites.
A long siege could slow down the army, allowing help to come or for the enemy to prepare a larger force for later.
If forced to assault a castle, there were many options available to the attackers.
The trebuchet, which probably evolved from the petraria in the 13th century, was the most effective siege weapon before the development of cannons.
Ballistas or springalds were siege engines that worked on the same principles as crossbows.
They were more commonly used against the garrison rather than the buildings of a castle.
A mine leading to the wall would be dug and once the target had been reached, the wooden supports preventing the tunnel from collapsing would be burned.
A counter-mine could be dug towards the besiegers' tunnel; assuming the two converged, this would result in underground hand-to-hand combat.
They were used to force open the castle gates, although they were sometimes used against walls with less effect.
A safer option for those assaulting a castle was to use a siege tower, sometimes called a belfry.
The estates of the realm, or three estates, were the broad orders of social hierarchy used in Christendom (Christian Europe) from the Middle Ages to early modern Europe.
The monarchy included the king and the queen, while the system was made up of clergy (the First Estate), nobles (Second Estate), peasants and bourgeoisie (Third Estate).
In England, a two-estate system evolved that combined nobility and clergy into one lordly estate with "commons" as the second estate.
In Scotland, the Three Estates were the Clergy (First Estate), Nobility (Second Estate), and Shire Commissioners, or "burghers" (Third Estate), representing the bourgeois, middle class, and lower class.
Since clergy could not marry, such mobility was theoretically limited to one generation.
Huizinga The Waning of the Middle Ages (1919, 1924:47).
Commoners were universally considered the lowest order.
In many regions and realms there also existed population groups born outside these specifically defined resident estates.
The economic and political transformation of the countryside in the period were filled by a large growth in population, agricultural production, technological innovations and urban centers; movements of reform and renewal attempted to sharpen the distinction between clerical and lay status, and power, recognized by the Church also had their effect.
The second order, those who fight, was the rank of the politically powerful, ambitious, and dangerous.
In addition, the First and Second Estates relied on the labour of the Third, which made the latter's inferior status all the more glaring.
Most were born within this group and also died as a part of it.
In May 1776, finance minister Turgot was dismissed, after failing to enact reforms.
When he could not persuade them to rubber-stamp his 'ideal program', Louis XVI sought to dissolve the Estates-General, but the Third Estate held out for their right to representation.
Because the Parliament of Scotland was unicameral, all members sat in the same chamber, as opposed to the separate English House of Lords and House of Commons.
As in England, the Parliament of Ireland evolved out of the Magnum Concilium "great council" summoned by the chief governor of Ireland, attended by the council (curia regis), magnates (feudal lords), and prelates (bishops and abbots).
In 1297, counties were first represented by elected knights of the shire (sheriffs had previously represented them).
Each were free men, and had specific rights and responsibilities, and the right to send representatives to the Riksdag of the Estates.
Prior to the 18th century, the King had the right to cast a deciding vote if the Estates were split evenly.
However, after the Diet of Porvoo, the Diet of Finland was reconvened only in 1863.
Around 1400, letters patent were introduced, in 1561 the ranks of Count and Baron were added, and in 1625 the House of Nobility was codified as the First Estate of the land.
Heads of the noble houses were hereditary members of the assembly of nobles.
This resulted in great political influence for the higher nobility.
In later centuries, the estate included teachers of universities and certain state schools.
Trade was allowed only in the cities when the mercantilistic ideology had got the upper hand, and the burghers had the exclusive right to conduct commerce within the framework of guilds.
In order for a settlement to become a city, a royal charter granting market right was required, and foreign trade required royally chartered staple port rights.
Since most of the population were independent farmer families until the 19th century, not serfs nor villeins, there is a remarkable difference in tradition compared to other European countries.
Their representatives to the Diet were elected indirectly: each municipality sent electors to elect the representative of an electoral district.
They had no political rights and could not vote.
In Sweden, the Riksdag of the Estates existed until it was replaced with a bicameral Riksdag in 1866, which gave political rights to anyone with a certain income or property.
In Finland, this legal division existed until 1906, still drawing on the Swedish constitution of 1772.
Furthermore, the industrial workers living in the city were not represented by the four-estate system.
Later in the 15th and 16th centuries Brussels became the place where the States General assembled.
As a consequence of the Union of Utrecht in 1579 and the events that followed afterwards, the States General declared that they no longer obeyed King Philip II of Spain, who was also overlord of the Netherlands.
It was the level of government where all things were dealt with that were of concern to all the seven provinces that became part of the Republic of the United Netherlands.
In the Southern Netherlands, the last meetings of the States General loyal to the Habsburgs took place in the Estates General of 1600 and the Estates General of 1632.
It no longer consisted of representatives of the States, let alone the Estates: all men were considered equal under the 1798 Constitution.
In 1815, when the Netherlands were united with Belgium and Luxemburg, the States General were divided into two chambers: the First Chamber and the Second Chamber.
From 1848 on, the Dutch Constitution provides that members of the Second Chamber be elected by the people (at first only by a limited portion of the male population; universal male and female suffrage exists since 1919), while the members of the First Chamber are chosen by the members of the States Provincial.
The clergy was represented by the independent prince-bishops, prince-archbishops and prince-abbots of the many monasteries.
Many peoples whose territories within the Holy Roman Empire had been independent for centuries had no representatives in the Imperial Diet, and this included the Imperial Knights and independent villages.
The four major estates were: nobility (dvoryanstvo), clergy, rural dwellers, and urban dwellers, with a more detailed stratification therein.
The bourgeoisie in its original sense is intimately linked to the existence of cities, recognized as such by their urban charters (e.g., municipal charters, town privileges, German town law), so there was no bourgeoisie apart from the citizenry of the cities.
Historically, the medieval French word bourgeois denoted the inhabitants of the bourgs (walled market-towns), the craftsmen, artisans, merchants, and others, who constituted "the bourgeoisie".
Guilds arose when individual businessmen (such as craftsmen, artisans and merchants) conflicted with their rent-seeking feudal landlords who demanded greater rents than previously agreed.
They tend to belong to a family that has been bourgeois for three or more generations.
The names of these families are generally known in the city where they reside, and their ancestors have often contributed to the region's history.
These people nevertheless live lavishly, enjoying the company of the great artists of the time.
In the French language, the term bourgeoisie almost designates a caste by itself, even though social mobility into this socio-economic group is possible.
Hitler distrusted capitalism for being unreliable due to its egotism, and he preferred a state-directed economy that is subordinated to the interests of the Volk.
Hitler also said that the business bourgeoisie "know nothing except their profit".
The utility of these things was inherent in their practical functions.
Belle de Jour (Beauty of the day, 1967) tells the story of a bourgeois wife who is bored with her marriage and decides to prostitute herself.
In Europe, the title of Emperor has been used since the Middle Ages, considered in those times equal or almost equal in dignity to that of Pope due to the latter's position as visible head of the Church and spiritual leader of the Catholic part of Western Europe.
In as much as there is a strict definition of emperor, it is that an emperor has no relations implying the superiority of any other ruler and typically rules over more than one nation.
Their status was officially recognised by the Holy Roman Emperor in 1514, although not officially used by the Russian monarchs until 1547.
Such pre-Roman titles as Great King or King of Kings, used by the Kings of Persia and others, are often considered as the equivalent.
Empire became identified instead with vast territorial holdings rather than the title of its ruler by the mid-18th century.
Ancient Romans abhorred the name Rex ("king"), and it was critical to the political order to maintain the forms and pretenses of republican rule.
Augustus, considered the first Roman emperor, established his hegemony by collecting on himself offices, titles, and honours of Republican Rome that had traditionally been distributed to different people, concentrating what had been distributed power in one man.
However, it was the informal descriptive of Imperator ("commander") that became the title increasingly favored by his successors.
This is one of the most enduring titles: Caesar and its transliterations appeared in every year from the time of Caesar Augustus to Tsar Simeon II of Bulgaria's removal from the throne in 1946.
Exceptions include the title of the Augustan History, a semi-historical collection of Emperors' biographies of the 2nd and 3rd century.
Few were however granted the title, and it was certainly not a rule that all wives of reigning Emperors would receive it.
In the late Republic, as in the early years of the new monarchy, Imperator was a title granted to Roman generals by their troops and the Roman Senate after a great victory, roughly comparable to field marshal (head or commander of the entire army).
The succeeding Nervan-Antonian Dynasty, ruling for most of the 2nd century, stabilised the Empire.
Three short lived secessionist attempts had their own emperors: the Gallic Empire, the Britannic Empire, and the Palmyrene Empire though the latter used rex more regularly.
At one point, there were as many as five sharers of the imperium (see: Tetrarchy).
The city is more commonly called Constantinople and is today named Istanbul).
These Later Roman "Byzantine" Emperors completed the transition from the idea of the Emperor as a semi-republican official to the Emperor as an absolute monarch.
Byzantine period emperors also used the Greek word "autokrator", meaning "one who rules himself", or "monarch", which was traditionally used by Greek writers to translate the Latin dictator.
In fact, none of these (and other) additional epithets and titles had ever been completely discarded.
Following the tragedy of the horrific sacking of the city, the conquerors declared a new "Empire of Romania", known to historians as the Latin Empire of Constantinople, installing Baldwin IX, Count of Flanders, as Emperor.
From the time of Otto the Great onward, much of the former Carolingian kingdom of Eastern Francia became the Holy Roman Empire.
This junior King then bore the title of Roman King (King of the Romans).
The Holy Roman Emperor was considered the first among those in power.
Geography is often defined in terms of two branches: human geography and physical geography.
Traditionally, geography has been associated with cartography and place names.
Because space and place affect a variety of topics, such as economics, health, climate, plants and animals, geography is highly interdisciplinary.
The former largely focuses on the built environment and how humans create, view, manage, and influence space.
It requires an understanding of the traditional aspects of physical and human geography, like the ways that human societies conceptualize the environment.
The study of systems larger than the Earth itself usually forms part of Astronomy or Cosmology.
Regional science: In the 1950s, the regional science movement led by Walter Isard arose to provide a more quantitative and analytical base to geographical questions, in contrast to the descriptive tendencies of traditional geography programs.
Cartography has grown from a collection of drafting techniques into an actual science.
In addition to all of the other subdisciplines of geography, GIS specialists must understand computer science and database systems.
Geostatistics is used extensively in a variety of fields, including hydrology, geology, petroleum exploration, weather analysis, urban planning, logistics, and epidemiology.
The map as reconstructed by Eckhard Unger shows Babylon on the Euphrates, surrounded by a circular landmass showing Assyria, Urartu, and several cities, in turn surrounded by a "bitter river" (Oceanus), with seven islands arranged around it so as to form a seven-pointed star.
In contrast to the Imago Mundi, an earlier Babylonian world map dating back to the 9th century BC depicted Babylon as being further north from the center of the world, though it is not certain what that center was supposed to represent.
Thales is also credited with the prediction of eclipses.
There is some debate about who was the first person to assert that the Earth is spherical in shape, with the credit going either to Parmenides or Pythagoras.
One of the first estimates of the radius of the Earth was made by Eratosthenes.
The meridians were sub-divided into 360°, with each degree further subdivided into 60 (minutes).
He extended the work of Hipparchus, using a grid system on his maps and adopting a length of 56.5 miles for a degree.
During the Middle Ages, the fall of the Roman empire led to a shift in the evolution of geography from Europe to the Islamic world.
Further, Islamic scholars translated and interpreted the earlier works of the Romans and the Greeks and established the House of Wisdom in Baghdad for this purpose.
Abu Rayhan Biruni (976–1048) first described a polar equi-azimuthal equidistant projection of the celestial sphere.
He also developed similar techniques when it came to measuring the heights of mountains, depths of the valleys, and expanse of the horizon.
The problem facing both explorers and geographers was finding the latitude and longitude of a geographic location.
The 18th and the 19th centuries were the times when geography became recognized as a discrete academic discipline, and became part of a typical university curriculum in Europe (especially Paris and Berlin).
Over the past two centuries, the advancements in technology with computers have led to the development of geomatics and new practices such as participant observation and geostatistics being incorporated into geography's portfolio of tools.
Arnold Henry Guyot (1807–1884) – noted the structure of glaciers and advanced understanding in glacier motion, especially in fast ice flow.
William Morris Davis (1850–1934) – father of American geography and developer of the cycle of erosion.
Ellen Churchill Semple (1863–1932) – first female president of the Association of American Geographers.
Walter Christaller (1893–1969) – human geographer and inventor of Central place theory.
David Harvey (born 1935) – Marxist geographer and author of theories on spatial and urban geography, winner of the Vautrin Lud Prize.
In some cases, a distinction is made between the official (constitutional) capital and the seat of government, which is in another place.
Examples are ancient Babylon, Abbasid Baghdad, ancient Athens, Rome, Bratislava, Budapest, Constantinople, Chang'an, ancient Cusco, Kyiv, Madrid, Paris, Podgorica, London, Beijing, Prague, Tallinn, Tokyo, Lisbon, Riga, Vilnius, and Warsaw.
In some countries, the capital has been changed for geopolitical reasons; Finland's first city, Turku, which had served as the country's capital since the Middle Ages under the Swedish rule, lost its right during the Grand Duchy of Finland in 1812, when Helsinki was made the current capital of Finland by the Russian Empire.
In Canada, there is a federal capital, while the ten provinces and three territories each have capital cities.
In Australia, the term "capital cities" is regularly used to refer to those six state capitals plus the federal capital Canberra, and Darwin, the capital of the Northern Territory.
Unlike in federations, there is usually not a separate national capital, but rather the capital city of one constituent nation will also be the capital of the state overall, such as London, which is the capital of England and of the United Kingdom.
The national capitals of Germany and Russia (the Stadtstaat of Berlin and the federal city of Moscow) are also constituent states of both countries in their own right.
Frankfort, Kentucky, midway between Louisville and Lexington.
Tallahassee, Florida, chosen as the midpoint between Pensacola and St. Augustine, Florida – then the two largest cities in Florida.
Changes in a nation's political regime sometimes result in the designation of a new capital.
When the Canary Islands became an autonomous community in 1982, Santa Cruz de Tenerife and Las Palmas de Gran Canaria were both given capital status.
Estonia: the Supreme Court and the Ministry of Education and Research are located in Tartu.
In case of emergency, the seat of the constitutional powers can be transferred to another town, in order for the Houses of Parliament to sit in the same location as the President and Cabinet.
The entire state machinery shifts from one city to another every six months.
Dharamshala, which is also the headquarters of the Central Tibetan Administration, is the second winter capital of the state.
The city itself is administered as a Union territory.
Uttarakhand: Dehradun is the administrative and legislative capital, while the high court is located in Nainital.
Its construction started in 1960 and was completed in 1966.
The presidential palace (Malacanang Palace) and the Supreme Court are located within the capital city but the two houses of Congress are located in separate suburbs.
Sri Lanka: Sri Jayawardenepura Kotte is designated the administrative capital and the location of the parliament, while the former capital, Colombo, is now designated as the "commercial capital".
South Africa: The administrative capital is Pretoria, the legislative capital is Cape Town, and the judicial capital is Bloemfontein.
Switzerland: Bern is the Federal City of Switzerland and functions as de facto capital.
Also similar to Illinois and New York State, most statewide elected officials and officers who are based in Southeast Pennsylvania (City of Philadelphia, Bucks County, Montgomery County, Delaware County, and Chester County) prefer working mostly in Philadelphia.
Israel and Palestine: Both the Government of Israel and the Palestinian Authority claim Jerusalem as their capital.
A symbolic relocation of a capital city to a geographically or demographically peripheral location may be for either economic or strategic reasons (sometimes known as a forward capital or spearhead capital).
The Ming emperors moved their capital to Beijing from the more central Nanjing to help supervise the border with the Mongols.
Delhi finally became the colonial capital after the Coronation Durbar of King-Emperor George V in 1911, continuing as independent India's capital from 1947.
Sometimes, the location of a new capital city was chosen to terminate actual or potential squabbling between various entities, such as in the cases of Canberra, Ottawa, Washington, Wellington and Managua.
In the Three Kingdoms period, both Shu and Wu fell when their respective capitals of Chengdu and Jianye fell.
After the Qing dynasty's collapse, decentralization of authority and improved transportation and communication technologies allowed both the Chinese Nationalists and Chinese Communists to rapidly relocate capitals and keep their leadership structures intact during the great crisis of Japanese invasion.
It can be defined as a permanent and densely settled place with administratively defined boundaries whose members work primarily on non-agricultural tasks.
Historically, city-dwellers have been a small proportion of humanity overall, but following two centuries of unprecedented and rapid urbanization, more than half of the world population now lives in cities, which has had profound consequences for global sustainability.
This increased influence means that cities also have significant influences on global issues, such as sustainable development, global warming and global health.
Therefore, compact cities are often referred to as a crucial element of fighting climate change.
For example, country capitals such as Beijing, London, Mexico City, Moscow, Nairobi, New Delhi, Paris, Rome, Athens, Seoul, Tokyo, and Washington, D.C. reflect the identity and apex of their respective nations.
The city may be looked on as a story, a pattern of relations between human groups, a production and distribution space, a field of physical force, a set of linked decisions, or an arena of conflict.
National censuses use a variety of definitions - invoking factors such as population, population density, number of dwellings, economic function, and infrastructure - to classify populations as urban.
The mutual interdependence of town and country has one consequence so obvious that it is easily overlooked: at the global scale, cities are generally confined to areas capable of supporting a permanent agricultural population.
As cities grew in complexity, the major civic institutions, from seats of government to religious buildings, would also come to dominate these points of convergence.
Physical environment generally constrains the form in which a city is built.
And it may be set up for optimal defense given the surrounding landscape.
This form could evolve from successive growth over a long time, with concentric traces of town walls and citadels marking older city boundaries.
In cities such as Moscow, this pattern is still clearly visible.
Excavations in these areas have found the ruins of cities geared variously towards trade, politics, or religion.
China's planned cities were constructed according to sacred principles to act as celestial microcosms.
These sites appear planned in a highly regimented and stratified fashion, with a minimalistic grid of rooms for the workers and increasingly more elaborate housing available for higher classes.
In the following centuries, independent city-states of Greece, especially Athens, developed the polis, an association of male landowning citizens who collectively constituted the city.
Under the authority of its empire, Rome transformed and founded many cities (coloniae), and with them brought its principles of urban architecture, design, and society.
The Norte Chico civilization included as many as 30 major population centers in what is now the Norte Chico region of north-central coastal Peru.
The locus of power in the West shifted to Constantinople and to the ascendant Islamic civilization with its major cities Baghdad, Cairo, and Córdoba.
By the thirteenth and fourteenth centuries, some cities become powerful states, taking surrounding areas under their control or establishing extensive maritime empires.
Western Europe's larger capitals (London and Paris) benefited from the growth of commerce following the emergence of an Atlantic trade.
England led the way as London became the capital of a world empire and cities across the country grew in locations strategic for manufacturing.
Entrepreneurial leadership became manifest through growth coalitions made up of builders, realtors, developers, the media, government actors such as mayors, and dominant corporations.
The results were efforts at downtown revitalization; inner-city gentrification; the transformation of the CBD to advanced service employment; entertainment, museums, and cultural venues; the construction of sports stadiums and sport complexes; and waterfront development."
Until the 18th century, an equilibrium existed between the rural agricultural population and towns featuring markets and small-scale manufacturing.
The cultural appeal of cities also plays a role in attracting residents.
Batam, Indonesia, Mogadishu, Somalia, Xiamen, China and Niamey, Niger, are considered among the world's fastest-growing cities, with annual growth rates of 5–8%.
The UN predicts an additional 2.5 billion citydwellers (and 300 million fewer countrydwellers) worldwide by 2050, with 90% of urban population expansion occurring in Asia and Africa.
A deep gulf divides rich and poor in these cities, with usually contain a super-wealthy elite living in gated communities and large masses of people living in substandard housing with inadequate infrastructure and otherwise poor conditions.
Yet municipalities routinely enact sweeping by-laws directed at open ended (and ill-defined) offences such as loitering and obstruction, requiring permits for protests or requiring residents and homeowners to remove snow from the city's sidewalks."
These are provided more or less routinely, in a more or less equal fashion.
These production oriented criteria often give rise to "service deliver rules", regularized procedures for the delivery of services, which are attempts to codify the productivity goals of urban service bureaucracies.
Robert L. Lineberry, "Mandating Urban Equality: The Distribution of Municipal Public Services"; in Hahn & Levine (1980).
However, financing municipal services, as well as urban renewal and other development projects, is a perennial problem, which cities address through appeals to higher governments, arrangements with the private sector, and techniques such as privatization (selling services into the private sector), corporatization (formation of quasi-private municipally-owned corporations), and financialization (packaging city assets into tradable financial instruments and derivatives).
The impact of globalization and the role of multinational corporations in local governments worldwide, has led to a shift in perspective on urban governance, away from the "urban regime theory" in which a coalition of local interests functionally govern, toward a theory of outside economic control, widely associated in academics with the philosophy of neoliberalism.
Planning tools, beyond the original design of the city itself, include public capital investment in infrastructure and land-use controls such as zoning.
Also available to cities in their implementation of planning objectives are municipal powers of zoning, subdivision control and the regulation of building, housing and sanitation principles."
People living relatively close together may live, work, and play, in separate areas, and associate with different people, forming ethnic or lifestyle enclaves or, in areas of concentrated poverty, ghettoes.
Suburbs in the west, and, increasingly, gated communities and other forms of "privatopia" around the world, allow local elites to self-segregate into secure and exclusive neighborhoods.
This outcast proletariat—perhaps 1.5 billion people today, 2.5 billion by 2030—is the fastest-growing and most novel social class on the planet.
It is ontologically both similar and dissimilar to the historical agency described in the Communist Manifesto.
As hubs of trade cities have long been home to retail commerce and consumption through the interface of shopping.
A thicker labor market allows for better skill matching between firms and individuals.
Cultural elites tend to live in cities, bound together by shared cultural capital, and themselves playing some role in governance.
Greg Kerr & Jessica Oliver, "Rethinking Place Identities", in Kavaratzis, Warnaby, & Ashworth (2015).
Patriotic tourists visit Agra to see the Taj Mahal, or New York City to visit the World Trade Center.
Why do anonymous people—the poor, the underprivileged, the unconnected—frequently prefer life under miserable conditions in tenements to the healthy order and tranquility of small towns or the sanitary subdivisions of semirural developments?
Those who came to live in them did so in order to participate and compete on any attainable level.
Sports also play a major role in city branding and local identity formation.
More importantly, there is also huge long term potential for both tourism and investment (Kasimati, 2003).
War brought concentration of social leadership and political power in the hands of a weapons-bearing minority, abetted by a priesthood exercising sacred powers and possessing secret but valuable scientific and magical knowledge."
During World War II, national governments on occasion declared certain cities open, effectively surrendering them to an advancing enemy in order to avoid damage and bloodshed.
Such warfare, known as counterinsurgency, involves techniques of surveillance and psychological warfare as well as close combat, functionally extends modern urban crime prevention, which already uses concepts such as defensible space.
Because of the higher barriers to entry, these networks have been classified as natural monopolies, meaning that economic logic favors control of each network by a single organization, public or private.
Kath Wellman & Frederik Pretorius, "Urban Infrastructure: Productivity, Project Evaluation, and Finance"; in Wellman & Spiller (2012).
Sanitation, necessary for good health in crowded conditions, requires water supply and waste management as well as individual hygiene.
Modern urban life relies heavily on the energy transmitted through electricity for the operation of electric machines (from household appliances to industrial machines to now-ubiquitous electronic systems used in communications, business, and government) and for traffic lights, streetlights and indoor lighting.
Tom Hart, "Transport and the City"; in Paddison (2001).
Many big American cities still operate conventional public transit by rail, as exemplified by the ever-popular New York City Subway system.
Anthropogenic buildings and waste, as well as cultivation in gardens, create physical and chemical environments which have no equivalents in wilderness, in some cases enabling exceptional biodiversity.
From one perspective, cities are not ecologically sustainable due to their resource needs.
Modern cities are known for creating their own microclimates, due to concrete, asphalt, and other artificial surfaces, which heat up in sunlight and channel rainwater into underground ducts.
Aerial particulates increase rainfall by 5–10%.
For example, within the urban microclimate, less-vegetated poor neighborhoods bear more of the heat (but have fewer means of coping with it).
Generally they are called Urban open space (although this word does not always mean green space), Green space, Urban greening.
The study used data from almost 20,000 people in the UK.
People who did not get at least two hours — even if they surpassed an hour per week — did not get the benefits.
The study didn't count time spent in a person's own yard or garden as time in nature, but the majority of nature visits in the study took place within two miles from home. "
Saskia Sassen used the term "global city" in her 1991 work, The Global City: New York, London, Tokyo to refer to a city's power, status, and cosmopolitanism, rather than to its size.
3 (1982): 319 Global cities form the capstone of the global hierarchy, exerting command and control through their economic and political influence.
Critics of the notion point to the different realms of power and interchange.
Multinational corporations and banks make their headquarters in global cities and conduct much of their business within this context.
Nancy Duxbury & Sharon Jeannotte, "Global Cultural Governance Policy"; Chapter 21 in The Ashgate Research Companion to Planning and Culture; London: Ashgate, 2013.
The Habitat I conference in 1976 adopted the "Vancouver Declaration on Human Settlements" which identifies urban management as a fundamental aspect of development and establishes various principles for maintaining urban habitats.
In January 2002 the UN Commission on Human Settlements became an umbrella agency called the United Nations Human Settlements Programme or UN-Habitat, a member of the United Nations Development Group.
The Bank's policies have tended to focus on bolstering real estate markets through credit and technical assistance.
Cities figure prominently in traditional Western culture, appearing in the Bible in both evil and holy forms, symbolized by Babylon and Jerusalem.
Cities can be perceived in terms of extremes or opposites: at once liberating and oppressive, wealthy and poor, organized and chaotic.
This and other political ideologies strongly influence narratives and themes in discourse about cities.
Classical and medieval literature includes a genre of descriptiones which treat of city features and history.
Other early cinematic representations of cities in the twentieth century generally depicted them as technologically efficient spaces with smoothly functioning systems of automobile transport.
A country is a distinct territorial body or political entity (i.e. a nation).
It is not inherently sovereign.
The largest country in the world by geographical area is Russia, while the most populous is China, followed by India, the United States, Indonesia, Pakistan and Brazil.
In many European countries the words are used for sub-divisions of the national territory, as in the German Bundesländer, as well as a less formal term for a sovereign state.
There is no universal agreement on the number of "countries" in the world since a number of states have disputed sovereignty status.
The degree of autonomy of non-sovereign countries varies widely.
The report classifies country development based on per capita gross national income (GNI).
The 2019 report recognizes only developed countries in North America, Europe, and Asia and the Pacific.
The World Bank defines its regions as East Asia and Pacific, Europe and Central Asia, Latin America and the Caribbean, Middle East and North Africa, North America, South Asia, and Sub-Saharan Africa.
Exploration is the act of searching for the purpose of discovery of information or resources, especially in the context of geography or space, rather than research and development that is usually not centred on earth sciences or astronomy.
Only the one done by emperor Nero seemed to be a preparative for the conquest of Ethiopia or Nubia: in 62 AD two legionaries explored the sources of the Nile river.
The Romans also organized several explorations into Northern Europe, and explored as far as China in Asia.
100 AD-166 AD Romano-Chinese relations begin.
The key invention to their exploration was the outrigger canoe, which provided a swift and stable platform for carrying goods and people.
2011 studies at Wairau Bar in New Zealand show a high probability that one origin was Ruahine Island in the Society Islands.
There are cultural and language similarities between Cook Islanders and New Zealand Maori.
During 1328–1333, he sailed along the South China Sea and visited many places in Southeast Asia and reached as far as South Asia, landing in Sri Lanka and India, and he even went to Australia.
Portugal and Spain dominated the first stages of exploration, while other European nations followed, such as England, Netherlands, and France.
The extreme conditions in the deep sea require elaborate methods and technologies to endure them.
An administrative subdivision, instead, is understood to be a division of a state proper.
The dependent territories that currently remain in the world today generally maintain a very high degree of political autonomy.
Cook Islands' status is considered to be equivalent to independence for international law purposes, and the country exercises full sovereignty over its internal and external affairs.
Under the terms of the free association agreement, however, New Zealand retains some responsibility for the foreign relations and defence of Niue.
This list is generally limited to entities that are either subject to an international treaty on their status, uninhabited, or have a unique level of autonomy and are largely self-governing in matters other than international affairs.
They are independently administrated jurisdictions, although the British Government is solely responsible for defense and international representation and has ultimate responsibility for ensuring good government.
No crown dependency has representation in the U.K. Parliament.
New Zealand and its dependencies share the same governor-general and constitute one monarchic realm.
The mutually negotiated Covenant to Establish a Commonwealth of the Northern Mariana Islands (CNMI) in Political Union with the United States was approved in 1976.
This is a constant source of ambiguity and confusion when trying to define, understand, and explain Puerto Rico's political relationship with the United States.
However, the status of its "constituent countries" in the Caribbean (Aruba, Curaçao, and Sint Maarten) can be considered akin to dependencies or "associated non-independent states."
Borders are geographic boundaries, imposed either by geographic features such as oceans, or by arbitrary groupings of political entities such as governments, sovereign states, federated states, and other subnational entities.
Most external borders are partially or fully controlled, and may be crossed legally only at designated border checkpoints and border zones may be controlled.
Most countries have some form of border control to regulate or limit the movement of people, animals, and goods into and out of the country.
To stay or work within a country's borders aliens (foreign persons) may need special immigration documents or permits; but possession of such documents does not guarantee that the person should be allowed to cross the border.
Most countries prohibit carrying illegal drugs or endangered animals across their borders.
In places where smuggling, migration, and infiltration are a problem, many countries fortify borders with fences and barriers, and institute formal border control procedures.
This is common in countries within the European Schengen Area and on rural sections of the Canada–United States border.
Rivers: some political borders have been formalized along natural borders formed by rivers.
In the Hebrew Bible, Moses defined the middle of the river Arnon as the border between Moab and the Israelite tribes settling east of the Jordan.
Examples are Lake Tanganyika, with the Democratic Republic of the Congo and Zambia on its west shore and Tanzania and Burundi on the east; and the Great Lakes which form a substantial part of the border between Canada and the United States.
Mountain ranges: Many nations have their political borders defined along mountain ranges, often along a drainage divide.
One example is the defensive forest created by China's Song Dynasty in the eleventh century.
For instance, the boundary between East and West Germany is no longer an international boundary, but it can still be seen because of historical markers on the landscape, and it is still a cultural and economic division in Germany.
Maritime borders exist in the context of territorial waters, contiguous zones, and exclusive economic zones; however, the terminology does not encompass lake or river boundaries, which are considered within the context of land boundaries.
Airspace extends 12 nautical miles from the coast of a country and it holds responsibility for protecting its own airspace unless under NATO peacetime protection.
However, there is a general agreement of vertical airspace ending at the point of the Kármán line.
Overall border regulations are placed by national and local governments and can vary depending on nation and current political or economic conditions.
Working across borders – Harnessing the potential of cross-border activities to improve livelihood security in the Horn of Africa drylands .
Human economic traffic across borders (apart from kidnapping) may involve mass commuting between workplaces and residential settlements.
It can enable and stop movement, across as well as along borders.
Many cross-border regions are also active in encouraging intercultural communication and dialogue as well as cross-border economic development strategies.
Since its conception in the mid-80's, this artistic practice has assisted in the development of questions surrounding homeland, borders, surveillance, identity, race, ethnicity, and national origin(s).
Borders can include but are not limited to language, culture, social and economic class, religion, and national identity.
These artists are often "border crossers" themselves.
In general, a rural area or a countryside is a geographic area that is located outside towns and cities.
Typical rural areas have a low population density and small settlements.
Predominantly urban regions have less than 15 percent of their population living in a rural community.
Rural northern regions are predominantly rural census divisions that are found either entirely or mostly above the following lines of parallel in each province: Newfoundland and Labrador, 50th; Quebec 54th; Ontario, 54th; Manitoba, 53rd; Saskatchewan, Alberta and British Columbia, 54th.
The U.S. Census Bureau, the USDA's Economic Research Service, and the Office of Management and Budget (OMB) have come together to help define rural areas.
The 2002 farm bill (P.L. 107–171, Sec.
According to the handbook, Definitions of Rural: A Handbook for Health Policy Makers and Researchers, "Residents of metropolitan counties are generally thought to have easy access to the relatively concentrated health services of the county's central areas.
This became the Goldsmith Modification definition of rural. "
President Emmanuel Macron government launched an action plan in 2019 in favour for rural areas named "Agenda Rural".
In Scotland a different definition of rural is used.
RBI defines rural areas as those areas with a population of less than 49,000 (tier -3 to tier-6 cities).
Rural areas in Pakistan that are near cities are considered as suburban areas or suburbs.
Suburbs might have their own political or legal jurisdiction, especially in the United States, but this is not always the case, especially in the United Kingdom where most suburbs are located within the administrative boundaries of cities.
In others, such as Morocco, France, and much of the United States, many suburbs remain separate municipalities or are governed locally as part of a larger metropolitan area such as a county, district or borough.
The terms inner suburb and outer suburb are used to differentiate between the higher-density areas in proximity to the city centre (which would not be referred to as 'suburbs' in most other countries), and the lower-density suburbs on the outskirts of the urban area.
In New Zealand, most suburbs are not legally defined, which can lead to confusion as to where they may begin and end.
The word suburbani was first employed by the Roman statesman Cicero in reference to the large villas and estates built by the wealthy patricians of Rome on the city's outskirts.
By the mid-19th century, the first major suburban areas were springing up around London as the city (then the largest in the world) became more overcrowded and unsanitary.
The line reached Harrow in 1880.
The Met's marketing department coined the term "Metro-land" in 1915 when the Guide to the Extension Line became the Metro-land guide, priced at 1d.
In part, this was a response to the shocking lack of fitness amongst many recruits during World War One, attributed to poor living conditions; a belief summed up in a housing poster of the period "you cannot expect to get an A1 population out of C3 homes" – referring to military fitness classifications of the period.
The Report also legislated on the required, minimum standards necessary for further suburban construction; this included regulation on the maximum housing density and their arrangement and it even made recommendations on the ideal number of bedrooms and other rooms per house.
Within just a decade suburbs dramatically increased in size.
Levittown developed as a major prototype of mass-produced housing.
Shopping for different goods and services in one central location without having to travel to multiple locations, helped to keep shopping centers a component of these newly designed suburbs which were booming in population.
The Highway Act of 1956 helped to fund the building of 64,000 kilometers across the nation by having $26 thousand-million to use, which helped to link many more to these shopping centers with ease.
Some suburbs had developed around large cities where there was rail transportation to the jobs downtown.
The product was a great housing boom.
With 16 million eligible veterans, the opportunity to buy a house was suddenly at hand.
Developers purchased empty land just outside the city, installed tract houses based on a handful of designs, and provided streets and utilities, or local public officials race to build schools.
Veterans could get one with a much lower down payment.
The growth of the suburbs was facilitated by the development of zoning laws, redlining and numerous innovations in transport.
African-Americans and other people of color largely remained concentrated within decaying cores of urban poverty.
After World War II, availability of FHA loans stimulated a housing boom in American suburbs.
Economic growth in the United States encouraged the suburbanization of American cities that required massive investments for the new infrastructure and homes.
An alternative strategy is the deliberate design of "new towns" and the protection of green belts around cities.
Federal subsidies for suburban development accelerated this process as did the practice of redlining by banks and other lending institutions.
Virginia Beach is now the largest city in all of Virginia, having long since exceeded the population of its neighboring primary city, Norfolk.
A greater percentage of whites (both non-Hispanic and, in some areas, Hispanic) and lesser percentage of citizens of other ethnic groups than in urban areas.
Compared to rural areas, suburbs usually have greater population density, higher standards of living, more complex road systems, more franchised stores and restaurants, and less farmland and wildlife.
However, of this metropolitan population, in 2001 nearly half lived in low-density neighborhoods, with only one in five living in a typical "urban" neighborhood.
Throughout Canada, there are comprehensive plans in place to curb sprawl.
The majority of recent population growth in Canada's three largest metropolitan areas (Greater Toronto, Greater Montréal, and Greater Vancouver) has occurred in non-core municipalities.
This is due to annexation and large geographic footprint within the city borders.
In the 2016 census, the City of Calgary had a population of 1,239,220, whereas the Calgary Metropolitan Area had a population of 1,392,609, indicating the vast majority of people in the Calgary CMA lived within the city limits.
In the UK, the government is seeking to impose minimum densities on newly approved housing schemes in parts of South East England.
Suburbs can be found in Guadalajara, Mexico City, Monterrey, and most major cities.
As the growth of middle-class and upper-class suburbs increased, low-class squatter areas have increased, most notably "lost cities" in Mexico, campamentos in Chile, barriadas in Peru, villa miserias in Argentina, asentamientos in Guatemala and favelas of Brazil.
In an illustrative case of South Africa, RDP housing has been built.
In certain areas such as Klang, Subang Jaya and Petaling Jaya, suburbs form the core of these places.
In the suburban system, most trips from one component to another component requires that cars enter a collector road, no matter how short or long the distance is.
If a traffic crash occurs on a collector road, or if road construction inhibits the flow, then the entire road system may be rendered useless until the blockage is cleared.
This encourages car trips even for distances as low as several hundreds of yards or meters (which may have become up to several miles or kilometers due to the road network).
Taken together, these two groups of taxpayers represent a largely untapped source of potential revenue that cities may begin to target more aggressively, particularly if they're struggling.
French songs like La Zone by Fréhel (1933), Aux quatre coins de la banlieue by Damia (1936), Ma banlieue by Reda Caire (1937), or Banlieue by Robert Lamoureux (1953), evoke the suburbs of Paris explicitly since the 1930s.
French cinema was although soon interested in urban changes in the suburbs, with such movies as Mon oncle by Jacques Tati (1958), L'Amour existe by Maurice Pialat (1961) or Two or Three Things I Know About Her by Jean-Luc Godard (1967).
The 1962 song "Little Boxes" by Malvina Reynolds lampoons the development of suburbia and its perceived bourgeois and conformist values, while the 1982 song Subdivisions by the Canadian band Rush also discusses suburbia, as does Rockin' the Suburbs by Ben Folds.
Over the Hedge is a syndicated comic strip written and drawn by Michael Fry and T. Lewis.
British television series such as The Good Life, Butterflies and The Fall and Rise of Reginald Perrin have depicted suburbia as well-manicured but relentlessly boring, and its residents as either overly conforming or prone to going stir crazy.
A village is a clustered human settlement or community, larger than a hamlet but smaller than a town (although the word is often used to describe both hamlets and smaller towns), with a population typically ranging from a few hundred to a few thousand.
This also enabled specialization of labor and crafts, and development of many trades.
The size of these villages varies considerably.
Desa are generally located in rural areas while kelurahan are generally urban subdivisions.
A desa or kelurahan is the subdivision of a kecamatan (subdistrict), in turn the subdivision of a kabupaten (district) or kota (city).
In Malaysia, a kampung is determined as a locality with 10,000 or fewer people.
All Muslims in the Malay or Indonesian village want to be prayed for, and to receive Allah's blessings in the afterlife.
Mainland Singapore used to have many kampung villages but modern developments and rapid urbanisation works have seen them bulldozed away; Kampong Lorong Buangkok is the last surviving village on the country's mainland.
Vietnam's village is the typical symbol of Asian agricultural production.
In Slovenia, the word selo is used for very small villages (fewer than 100 people) and in dialects; the Slovene word vas is used all over Slovenia.
It could be relative to a Sanskrit like Afgan word deh and Indonesian word desa.
Approximately 46% of all migrated people have changed their residence from one city to another.
The lowest administrative unit of the Russian Empire, a volost, or its Soviet or modern Russian successor, a selsoviet, was typically headquartered in a selo and embraced a few neighboring villages.
While peasants of central Russia lived in a village around the lord's manor, a Cossack family often lived on its own farm, called khutor.
There is, however, another smaller type of settlement which is designated in Ukrainian as a selysche (селище).
They represent a type of a small rural locality that might have once been a khutir, a fisherman's settlement, or a dacha.
However, ambiguity is often avoided in connection with urbanized settlements by referring to them using the three-letter abbreviation smt instead.
They became really popular during the Stolypin reform in the early 20th century.
Larger villages can also be referred to as a Flecken or Markt depending on the region.
For example, in areas such as the Lincolnshire Wolds, the villages are often found along the spring line halfway down the hillsides, and originate as spring line settlements, with the original open field systems around the village.
Some villages have disappeared (for example, deserted medieval villages), sometimes leaving behind a church or manor house and sometimes nothing but bumps in the fields.
Other villages have grown and merged and often form hubs within the general mass of suburbia—such as Hampstead, London and Didsbury in Manchester.
Seen as being far from the bustle of modern life, it is represented as quiet and harmonious, if a little inward-looking.
These (such as Murton, County Durham) grew from hamlets when the sinking of a colliery in the early 20th century resulted in a rapid growth in their population and the colliery owners built new housing, shops, pubs and churches.
Maltby was constructed under the auspices of the Sheepbridge Coal and Iron Company and included ample open spaces and provision for gardens.
The typical village had a pub or inn, shops, and a blacksmith.
However, some civil parishes have no functioning parish, town, or city council nor a functioning parish meeting.
In Scotland, the equivalent is also a community council, however, despite being statutory bodies they have no executive powers.
The district of Danniyeh consists of thirty-six small villages, which includes Almrah, Kfirchlan, Kfirhbab, Hakel al Azimah, Siir, Bakhoun, Miryata, Assoun, Sfiiri, Kharnoub, Katteen, Kfirhabou, Zghartegrein, Ein Qibil.
Dinniyeh has an excellent ecological environment filled with woodlands, orchards and groves.
Villages in the south of Syria (Hauran, Jabal al-Druze), the north-east (the Syrian island) and the Orontes River basin depend mostly on agriculture, mainly grain, vegetables, and fruits.
Mediterranean cities in Syria, such as Tartus and Latakia have similar types of villages.
Every urbanization is a "pueblo" unless is elevated by decree to the next category.
However, this is a generality; in many states, there are villages that are an order of magnitude larger than the smallest cities in the state.
In some cases, the village may be coterminous with the town or township, in which case the two may have a consolidated government.
Hempstead, the largest village, has 55,000 residents; making it more populous than some of the state's cities.
The village of Arlington Heights, Illinois had 75,101 residents as of the 2010 census.
Villages can incorporate land in multiple townships and even multiple counties.
The largest village is Menomonee Falls, which has over 32,000 residents.
In Maryland, a locality designated "Village of ..." may be either an incorporated town or a special tax district.
At that time Traditional rulers used to have absolute power in their administrative regions.
Every Hausa village was reigned by Magaji (Village head) who was answerable to his Hakimi (mayor) at the town level.
They have mud houses with thatched roofing though, like in most of the villages in the North, zinc roofing is becoming a common sight.
Others are lucky to have wells within a walking distance.
An atlas is a collection of maps; it is typically a bundle of maps of Earth or a region of Earth.
This title provides Mercator's definition of the word as a description of the creation and form of the whole universe, not simply as a collection of maps.
A desk atlas is made similar to a reference book.
In cartography, a contour line (often just called a "contour") joins points of equal elevation (height) above a given level, such as mean sea level.
The gradient of the function is always perpendicular to the contour lines.
Contour lines are curved, straight or a mixture of both lines on a map describing the intersection of a real or hypothetical surface with one or more horizontal planes.
In 1701, Edmond Halley used such lines (isogons) on a chart of magnetic variation.
In 1791, a map of France by J. L. Dupain-Triel used contour lines at 20-metre intervals, hachures, spot-heights and a vertical section.
Isobaths were not routinely used on nautical charts until those of Russia from 1834, and those of Britain from 1838.
As late as 1944, John K. Wright still preferred isogram, but it never attained wide usage.
Despite attempts to select a single standard, all of these alternatives have survived to the present.
Weather stations are seldom exactly positioned at a contour line (when they are, this indicates a measurement precisely equal to the value of the contour).
In meteorology, the barometric pressures shown are reduced to sea level, not the surface pressures at the map locations.
Isallobars are lines joining points of equal pressure change during a specific time interval.
Isallobaric gradients are important components of the wind as they increase or decrease the geostrophic wind.
An isotherm at 0 °C is called the freezing level.
From these contours, a sense of the general terrain can be determined.
In cartography, the contour interval is the elevation difference between adjacent contour lines.
Two or more contour lines merging indicates a cliff.
Usually contour intervals are consistent throughout a map, but there are exceptions.
Whether crossing an equipotential line represents ascending or descending the potential is inferred from the labels on the charges.
Acid precipitation is indicated on maps with isoplats.
Contour lines are also used to display non-geographic information in economics.
Such isolines are useful for representing more than two dimensions (or quantities) on two-dimensional graphs.
In interpreting radar images, an isodop is a line of equal Doppler velocity, and an isoecho is a line of equal radar reflectivity.
Line color is the choice of any number of pigments that suit the display.
Line type refers to whether the basic contour line is solid, dashed, dotted or broken in some other pattern to create the desired effect.
Numerical marking is the manner of denoting the arithmetical values of contour lines.
If the contour lines are not numerically labeled and adjacent lines have the same style (with the same weight, color and type), then the direction of the gradient cannot be determined from the contour lines alone.
A properly labeled contour map helps the reader to quickly interpret the shape of the terrain.
Then the coordinates of other places are measured from the nearest control point through surveying.
This phenomenon is called datum shift.
More ambitious undertakings such as the Struve Geodetic Arc across Eastern Europe (1816-1855) and the Great Trigonometrical Survey of India (1802-1871) took much longer, but resulted in more accurate estimations of the shape of the Earth ellipsoid.
An approximate definition of sea level is the datum WGS 84, an ellipsoid, whereas a more accurate definition is Earth Gravitational Model 2008 (EGM2008), using at least 2,159 spherical harmonics.
When used without qualification, the term latitude refers to geodetic latitude.
The datum shift between two particular datums can vary from one place to another within one country or region, and can be anything from zero to hundreds of meters (or several kilometers for some remote islands).
For example, in Sydney there is a 200 metres (700 feet) difference between GPS coordinates configured in GDA (based on global standard WGS 84) and AGD (used for most local maps), which is an unacceptably large error for some applications, such as surveying or site location for scuba diving.
Since reference datums can have different radii and different center points, a specific point on Earth can have substantially different coordinates depending on the datum used to make the measurement.
The most common reference Datums in use in North America are NAD27, NAD83, and WGS 84.
This datum, designated as NAD 83 ...is based on the adjustment of 250,000 points including 600 satellite Doppler stations which constrain the system to a geocentric origin."
It is the reference frame used by the U.S. Department of Defense (DoD) and is defined by the National Geospatial-Intelligence Agency (NGA) (formerly the Defense Mapping Agency, then the National Imagery and Mapping Agency).
It was used as the reference frame for broadcast GPS Ephemerides (orbits) beginning January 23, 1987.
It became the reference frame for broadcast orbits on June 28, 1994.
WGS 84 (G873) was adopted as the reference frame for broadcast orbits on January 29, 1997.
WGS 84 is the default standard datum for coordinates stored in recreational and commercial GPS units.
For example, the longitudinal difference between a point on the equator in Uganda, on the African Plate, and a point on the equator in Ecuador, on the South American Plate, increases by about 0.0014 arcseconds per year.
Most mapping, such as within a single country, does not span plates.
Ptolemy credited him with the full adoption of longitude and latitude, rather than measuring latitude in terms of the length of the midsummer day.
Mathematical cartography resumed in Europe following Maximus Planudes' recovery of Ptolemy's text a little before 1300; the text was translated into Latin at Florence by Jacobus Angelus around 1407.
They then choose the most appropriate mapping of the spherical coordinate system onto that ellipsoid, called a terrestrial reference system or geodetic datum.
φ, or phi) of a point on Earth's surface is the angle between the equatorial plane and the straight line that passes through that point and through (or close to) the center of the Earth.
All meridians are halves of great ellipses (often called great circles), which converge at the North and South Poles.
The antipodal meridian of Greenwich is both 180°W and 180°E. This is not to be conflated with the International Date Line, which diverges from it in several places for political and convenience reasons, including between far eastern Russia and the far western Aleutian Islands.
Coordinates on a map are usually in terms northing N and easting E offsets relative to a specified origin.
In geography, latitude is a geographic coordinate that specifies the north–south position of a point on the Earth's surface.
Latitude is used together with longitude to specify the precise location of features on the surface of the Earth.
The second step is to approximate the geoid by a mathematically simpler reference surface.
Lines of constant latitude and longitude together constitute a graticule on the reference surface.
Since there are many different reference ellipsoids, the precise latitude of a feature on the surface is not unique: this is stressed in the ISO standard which states that "without the full specification of the coordinate reference system, coordinates (that is latitude and longitude) are ambiguous at best and meaningless at worst".
The plane through the centre of the Earth and perpendicular to the rotation axis intersects the surface at a great circle called the Equator.
The time variation is discussed more fully in the article on axial tilt.
The situation is reversed at the June solstice, when the Sun is overhead at the Tropic of Cancer.
Since latitude is defined with respect to an ellipsoid, the position of a given point is different on each ellipsoid: one cannot exactly specify the latitude and longitude of a geographical feature without specifying the ellipsoid used.
Geographic latitude must be used with care.
The evaluation of the meridian distance integral is central to many studies in geodesy and map projection.
There are two methods of proceeding.
When converting from isometric or conformal to geodetic, two iterations of Newton-Raphson gives double precision accuracy.
The differences shown on the plot are in arc minutes.
The transformation between geodetic and Cartesian coordinates may be found in Geographic coordinate conversion.
In general the true vertical at a point on the surface does not exactly coincide with either the normal to the reference ellipsoid or the normal to the geoid.
Longitude is a geographic coordinate that specifies the east–west position of a point on the Earth's surface, or the surface of a celestial body.
The prime meridian, which passes near the Royal Observatory, Greenwich, England, is defined as 0° longitude by convention.
Local time (for example from the position of the sun) varies with longitude, a difference of 15° longitude corresponding to a one-hour difference in local time.
The principle is straightforward, but in practice finding a reliable method of determining longitude took centuries and required the effort of some of the greatest scientific minds.
His prime meridian passed through Alexandria.
In 1910, the Journal published an article by Ulysses G. Weatherly (1865-1940) that called for white supremacy and segregation of the races to protect racial purity.
In his work, he contended that social class, colonialism, and capitalism shaped ideas about race and racial categories.
By 1978, William Julius Wilson (1935–) argued that race and racial classification systems were declining in significance, and that instead, social class more accurately described what sociologists had earlier understood as race.
Eduardo Bonilla-Silva, Sociology professor at Duke University, remarks, "I contend that racism is, more than anything else, a matter of group power; it is about a dominant racial group (whites) striving to maintain its systemic advantages and minorities fighting to subvert the racial status quo.
In clinical settings, race has sometimes been considered in the diagnosis and treatment of medical conditions.
There is an active debate among biomedical researchers about the meaning and importance of race in their research.
Members of the latter camp often base their arguments around the potential to create genome-based personalized medicine.
They argue that overemphasizing genetic contributions to health disparities carries various risks such as reinforcing stereotypes, promoting racism or ignoring the contribution of non-genetic factors to health disparities.
IC" stands for "Identification Code;" these items are also referred to as Phoenix classifications.
In many countries, such as France, the state is legally banned from maintaining data based on race, which often makes the police issue wanted notices to the public that include labels like "dark skin complexion", etc.
Many consider de facto racial profiling an example of institutional racism in law enforcement.
Mass incarceration is also, "the larger web of laws, rules, policies, and customs that control those labeled criminals both in and out of prison."
Many research findings appear to agree that the impact of victim race in the IPV arrest decision might possibly include a racial bias in favor of white victims.
Some studies have reported that races can be identified with a high degree of accuracy using certain methods, such as that developed by Giles and Elliot.
The study concluded that "The apportionment of genetic diversity in skin color is atypical, and cannot be used for purposes of classification."
Cultural anthropology is a branch of anthropology focused on the study of cultural variation among humans.
In addressing this question, ethnologists in the 19th century divided into two schools of thought.
Some of those who advocated "independent invention", like Lewis Henry Morgan, additionally supposed that similarities meant that different groups had passed through the same stages of cultural evolution (See also classical social evolutionism).
Morgan, like other 19th century social evolutionists, believed there was a more or less orderly progression from the primitive to the civilized.
Although 19th-century ethnologists saw "diffusion" and "independent invention" as mutually exclusive and competing theories, most ethnographers quickly reached a consensus that both processes occur, and that both can plausibly account for cross-cultural similarities.
Boas first articulated the idea in 1887: "...civilization is not something absolute, but ... is relative, and ... our ideas and conceptions are true only so far as our civilization goes."
Cultural relativism involves specific epistemological and methodological claims.
Cultural relativism was in part a response to Western ethnocentrism.
This understanding of culture confronts anthropologists with two problems: first, how to escape the unconscious bonds of one's own culture, which inevitably bias our perceptions of and reactions to the world, and second, how to make sense of an unfamiliar culture.
One such method is that of ethnography: basically, they advocated living with people of another culture for an extended period of time, so that they could learn the local language and be enculturated, at least partially, into that culture.
His approach was empirical, skeptical of overgeneralizations, and eschewed attempts to establish universal laws.
He believed that each culture has to be studied in its particularity, and argued that cross-cultural generalizations, like those made in the natural sciences, were not possible.
His first generation of students included Alfred Kroeber, Robert Lowie, Edward Sapir, and Ruth Benedict, who each produced richly detailed studies of indigenous North American cultures.
The publication of Alfred Kroeber's textbook Anthropology (1923) marked a turning point in American anthropology.
Influenced by psychoanalytic psychologists including Sigmund Freud and Carl Jung, these authors sought to understand the way that individual personalities were shaped by the wider cultural and social forces in which they grew up.
Economic anthropology as influenced by Karl Polanyi and practiced by Marshall Sahlins and George Dalton challenged standard neoclassical economics to take account of cultural and social factors, and employed Marxian analysis into anthropological study.
In keeping with the times, much of anthropology became politicized through the Algerian War of Independence and opposition to the Vietnam War; Marxism became an increasingly popular theoretical approach in the discipline.
In the 1980s books like Anthropology and the Colonial Encounter pondered anthropology's ties to colonial inequality, while the immense popularity of theorists such as Antonio Gramsci and Michel Foucault moved issues of power and hegemony into the spotlight.
These interpretations must then be reflected back to its originators, and its adequacy as a translation fine-tuned in a repeated way, a process called the hermeneutic circle.
David Schnieder's cultural analysis of American kinship has proven equally influential.
The method originated in the field research of social anthropologists, especially Bronislaw Malinowski in Britain, the students of Franz Boas in the United States, and in the later urban research of the Chicago School of Sociology.
Walnut Creek, CA: AltaMira Press.
To establish connections that will eventually lead to a better understanding of the cultural context of a situation, an anthropologist must be open to becoming part of the group, and willing to develop meaningful relationships with its members.
Before participant observation can begin, an anthropologist must choose both a location and a focus of study.
This allows the anthropologist to become better established in the community.
The majority of participant observation is based on conversation.
In some cases, ethnographers also turn to structured observation, in which an anthropologist's observations are directed by a specific set of questions he or she is trying to answer.
This helps to standardize the method of study when ethnographic data is being compared across several groups or is needed to fulfill a specific purpose, such as research for a governmental policy decision.
Who the ethnographer is has a lot to do with what he or she will eventually write about a culture, because each researcher is influenced by his or her own perspective.
However, these approaches have not generally been successful, and modern ethnographers often choose to include their personal experiences and possible biases in their writing instead.
An ethnography is a piece of writing about a people, at a particular place and time.
A typical ethnography will also include information about physical geography, climate and habitat.
Boas' students such as Alfred L. Kroeber, Ruth Benedict and Margaret Mead drew on his conception of culture and cultural relativism to develop cultural anthropology in the United States.
Today socio-cultural anthropologists attend to all these elements.
American "cultural anthropologists" focused on the ways people expressed their view of themselves and their world, especially in symbolic forms, such as art and myths.
Monogamy, for example, is frequently touted as a universal human trait, yet comparative study shows that it is not.
Through this methodology, greater insight can be gained when examining the impact of world-systems on local and global communities.
For example, a multi-sited ethnography may follow a "thing," such as a particular commodity, as it is transported through the networks of global capitalism.
An example of multi-sited ethnography is Nancy Scheper-Hughes' work on the international black market for the trade of human organs.
Research in kinship studies often crosses over into different anthropological subfields including medical, feminist, and public anthropology.
That is the matrix into which human children are born in the great majority of cases, and their first words are often kinship terms.
There are stark differences between communities in terms of marital practice and value, leaving much room for anthropological fieldwork.
The marital practice found in most cultures, however, is monogamy, where one woman is married to one man.
There are similar foundational differences where the act of procreation is concerned.
The shift can be traced back to the 1960s, with the reassessment of kinship's basic principles offered by Edmund Leach, Rodney Neeham, David Schneider, and others.
This shift was progressed further by the emergence of second-wave feminism in the early 1970s, which introduced ideas of marital oppression, sexual autonomy, and domestic subordination.
At this time, there was the arrival of "Third World feminism", a movement that argued kinship studies could not examine the gender relations of developing countries in isolation, and must pay respect to racial and economic nuance as well.
In Jamaica, marriage as an institution is often substituted for a series of partners, as poor women cannot rely on regular financial contributions in a climate of economic instability.
With this technology, questions of kinship have emerged over the difference between biological and genetic relatedness, as gestational surrogates can provide a biological environment for the embryo while the genetic ties remain with a third party.
There have also been issues of reproductive tourism and bodily commodification, as individuals seek economic security through hormonal stimulation and egg harvesting, which are potentially harmful procedures.
One critique is that, as its inception, the framework of kinship studies was far too structured and formulaic, relying on dense language and stringent rules.
Much of this development can be attributed to the rise in anthropologists working outside of academia and the increasing importance of globalization in both institutions and the field of anthropology.
The two types of institutions defined in the field of anthropology are total institutions and social institutions.
Anthropology of institutions may analyze labor unions, businesses ranging from small enterprises to corporations, government, medical organizations, education, prisons, and financial institutions.
Institutional anthropologists may study the relationship between organizations or between an organization and other parts of society.
More specifically, anthropologists may analyze specific events within an institution, perform semiotic investigations, or analyze the mechanisms by which knowledge and culture are organized and dispersed.
This new era would involve many new technological developments, such as mechanical recording.
Current Anthropology 43(Supplement):S5-17.Schieffelin, Bambi B. 2006.
Woolard, in her overview of "code switching", or the systematic practice of alternating linguistic varieties within a conversation or even a single utterance, finds the underlying question anthropologists ask of the practice—Why do they do that?—reflects a dominant linguistic ideology.
Other linguists have carried out research in the areas of language contact, language endangerment, and 'English as a global language'.
The work of Joel Kuipers develops this theme vis-a-vis the island of Sumba, Indonesia.
He feels, in fact, that the exemplary center idea is one of linguistic anthropology's three most important findings.
Therefore, after a couple generations these languages may no longer be spoken.
To follow best practices of documentation, these records should be clearly annotated and kept safe within an archive of some kind.
Language revitalization is the practice of bringing a language back into common use.
The course aims to educate indigenous and non-indigenous students about the Lenape language and culture.
Encouraging those who already know the language to use it, increasing the domains of usage, and increasing the overall prestige of the language are all components of reclamation.
Social anthropology is the study of patterns of behaviour in human societies and cultures.
British and American anthropologists including Gillian Tett and Karen Ho who studied Wall Street provided an alternative explanation for the financial crisis of 2007–2010 to the technical explanations rooted in economic and political theory.
This development was bolstered by Franz Boas's introduction of cultural relativism arguing that cultures are based on different ideas about the world and can therefore only be properly understood in terms of their own standards and values.
In 1906, Congolese pygmy Ota Benga was put by American anthropologist Madison Grant in a cage in the Bronx Zoo, labelled "the missing link" between an orangutan and the "white race" — Grant, a renowned eugenicist, was also the author of The Passing of the Great Race (1916).
Anthropology grew increasingly distinct from natural history and by the end of the 19th century the discipline began to crystallize into its modern form - by 1935, for example, it was possible for T.K. Penniman to write a history of the discipline entitled A Hundred Years of Anthropology.
Non-European societies were thus seen as evolutionary "living fossils" that could be studied in order to understand the European past.
However, as Stocking notes, Tylor mainly concerned himself with describing and mapping the distribution of particular elements of culture, rather than with the larger function, and he generally seemed to assume a Victorian idea of progress rather than the idea of non-directional, multilineal cultural change proposed by later anthropologists.
His comparative studies, most influentially in the numerous editions of The Golden Bough, analyzed similarities in religious belief and symbolism globally.
The findings of the expedition set new standards for ethnographic description.
Other intellectual founders include W. H. R. Rivers and A. C. Haddon, whose orientation reflected the contemporary Parapsychologies of Wilhelm Wundt and Adolf Bastian, and Sir E. B. Tylor, who defined anthropology as a positivist science following Auguste Comte.
A. R. Radcliffe-Brown also published a seminal work in 1922.
This was particularly the case with Radcliffe-Brown, who spread his agenda for "Social Anthropology" by teaching at universities across the British Empire and Commonwealth.
He believed that indigenous terms used in ethnographic data should be translated into Anglo-American legal terms for the benefit of the reader.
Departments of Social Anthropology at different Universities have tended to focus on disparate aspects of the field.
A people is any plurality of persons considered as a whole.
Four states — Massachusetts, Virginia, Pennsylvania, and Kentucky — refer to themselves as the Commonwealth in case captions and legal process.
In some parts of the world, ethnology has developed along independent paths of investigation and pedagogical doctrine, with cultural anthropology becoming dominant especially in the United States, and social anthropology in Great Britain.
The 15th-century exploration of America by European explorers had an important role in formulating new notions of the Occident (the Western world), such as the notion of the "Other".
The progress of ethnology, for example with Claude Lévi-Strauss's structural anthropology, led to the criticism of conceptions of a linear progress, or the pseudo-opposition between "societies with histories" and "societies without histories", judged too dependent on a limited view of history as constituted by accumulative growth.
However, the claims of such cultural universalism have been criticized by various 19th- and 20th-century social thinkers, including Marx, Nietzsche, Foucault, Derrida, Althusser, and Deleuze.
An ethnic group or ethnicity is a grouping of people who identify with each other on the basis of shared attributes that distinguish them from other groups such as a common set of traditions, ancestry, language, history, society, culture, nation, religion, or social treatment within their residing area.
Membership of an ethnic group tends to be defined by a shared cultural heritage, ancestry, origin myth, history, homeland, language, or dialect, symbolic systems such as religion, mythology and ritual, cuisine, dressing style, art, or physical appearance.
By way of language shift, acculturation, adoption and religious conversion, individuals or groups may over time shift from one ethnic group to another.
Whether through division or amalgamation, the formation of a separate ethnic identity is referred to as ethnogenesis.
In Early Modern English and until the mid-19th century, ethnic was used to mean heathen or pagan (in the sense of disparate "nations" which did not yet participate in the Christian oikumene), as the Septuagint used ta ethne ("the nations") to translate the Hebrew goyim "the nations, non-Hebrews, non-Jews".
In the 19th century, the term came to be used in the sense of "peculiar to a race, people or nation", in a return to the original Greek meaning.
ethnic, a. and n.") Depending on context, the term nationality may be used either synonymously with ethnicity or synonymously with citizenship (in a sovereign state).
Whether ethnicity qualifies as a cultural universal is to some extent dependent on the exact definition used.
According to Thomas Hylland Eriksen, the study of ethnicity was dominated by two distinct debates until recently.
The instrumentalist approach, on the other hand, treats ethnicity primarily as an ad hoc element of a political strategy, used as a resource for interest groups for achieving secondary goals such as, for instance, an increase in wealth, power, or status.
Constructivists view national and ethnic identities as the product of historical forces, often recent, even when the identities are presented as old.
This is in the context of debates over multiculturalism in countries, such as the United States and Canada, which have large immigrant populations from many different cultures, and post-colonialism in the Caribbean and South Asia.
Third, group formation resulted from the drive to monopolize power and status.
Barth went further than Weber in stressing the constructed nature of ethnicity.
He wanted to part with anthropological notions of cultures as bounded entities, and ethnicity as primordialist bonds, replacing it with a focus on the interface between groups.
He agrees with Joan Vincent's observation that (in Cohen's paraphrase) "Ethnicity... can be narrowed or broadened in boundary terms in relation to the specific needs of political mobilization.
Ethnic groups came to be defined as social rather than biological entities.
Examples of various approaches are primordialism, essentialism, perennialism, constructivism, modernism, and instrumentalism.
"Essentialist primordialism" further holds that ethnicity is an a priori fact of human existence, that ethnicity precedes any human social interaction and that it is unchanged by it.
"Kinship primordialism" holds that ethnic communities are extensions of kinship units, basically being derived by kinship or clan ties where the choices of cultural signs (language, religion, traditions) are made exactly to show this biological affinity.
"Geertz's primordialism", notably espoused by anthropologist Clifford Geertz, argues that humans in general attribute an overwhelming power to primordial human "givens" such as blood ties, language, territory, and cultural differences.
Smith (1999) distinguishes two variants: "continuous perennialism", which claims that particular nations have existed for very long periods, and "recurrent perennialism", which focuses on the emergence, dissolution and reappearance of nations as a recurring aspect of human history.
This view holds that the concept of ethnicity is a tool used by political groups to manipulate resources such as wealth, power, territory or status in their particular groups' interests.
"Instrumentalist perennialism", while seeing ethnicity primarily as a versatile tool that identified different ethnics groups and limits through time, explains ethnicity as a mechanism of social stratification, meaning that ethnicity is the basis for a hierarchical arrangement of individuals.
According to Donald Noel, ethnic stratification will emerge only when specific ethnic groups are brought into contact with one another, and only when those groups are characterized by a high degree of ethnocentrism, competition, and differential power.
Continuing with Noel's theory, some degree of differential power must be present for the emergence of ethnic stratification.
The different ethnic groups must be competing for some common goal, such as power or influence, or a material interest, such as wealth or territory.
It holds that ethnic groups are only products of human social interaction, maintained only in so far as they are maintained as valid social constructs in societies.
They hold that prior to this ethnic homogeneity was not considered an ideal or necessary factor in the forging of large-scale societies.
Members of an ethnic group, on the whole, claim cultural continuities over time, although historians and cultural anthropologists have documented that many of the values, practices, and norms that imply continuity with the past are of relatively recent invention.
It is based on the notion of "culture".
This view arose as a way to justify enslavement of African Americans and genocide of Native Americans in a society that was officially founded on freedom for all.
Many of the foremost scientists of the time took up the idea of racial difference and found that white Europeans were superior.
Instead of attributing the marginalized status of people of color in the United States to their inherent biological inferiority, he attributed it to their failure to assimilate into American culture.
They argue in Racial Formation in the United States that the ethnicity theory was exclusively based on the immigration patterns of the white population and did take into account the unique experiences of non-whites in the United States.
Assimilation shedding the particular qualities of a native culture for the purpose of blending in with a host culture did not work for some groups as a response to racism and discrimination, though it did for others.
They culminated in the rise of "nation-states" in which the presumptive boundaries of the nation coincided (or ideally coincided) with state boundaries.
Nation-states, however, invariably include populations who have been excluded from national life for one reason or another.
Multi-ethnic states can be the result of two opposite events, either the recent creation of state borders at variance with traditional tribal territories, or the recent immigration of ethnic minorities into a former nation-state.
States such as the United Kingdom, France and Switzerland comprised distinct ethnic groups from their formation and have likewise experienced substantial immigration, resulting in what has been termed "multicultural" societies, especially in large cities.
Though these categories are usually discussed as belonging to the public, political sphere, they are upheld within the private, family sphere to a great extent.
Before Weber (1864–1920), race and ethnicity were primarily seen as two aspects of the same thing.
According to this view, the state should not acknowledge ethnic, national or racial identity but rather instead enforce political and legal equality of all individuals.
The 19th century saw the development of the political ideology of ethnic nationalism, when the concept of race was tied to nationalism, first by German theorists including Johann Gottfried von Herder.
Each promoted the pan-ethnic idea that these governments were acquiring only lands that had always been inhabited by ethnic Germans.
The colonization of Asia was largely ended in the 20th century, with national drives for independence and self-determination across the continent.
A number of European countries, including France and Switzerland, do not collect information on the ethnicity of their resident population.
During European colonization, Europeans arrived in North America.
Digital ethnography allows for a lot more opportunities to look at different cultures and societies.
Relational Ethnography articulates studying fields rather than places or processes rather than processed people.
The goal is to collect data in such a way that the researcher imposes a minimal amount of personal bias in the data.
Interviews are often taped and later transcribed, allowing the interview to proceed unimpaired of note-taking, but with all information available later for full analysis.
Despite these attempts of reflexivity, no researcher can be totally unbiased.
These informants are typically asked to identify other informants who represent the community, often using snowball or chain sampling.
2010) examine the ontological and epistemological presuppositions underlying ethnography.
Critical theory researchers address "issues of power within the researcher-researched relationships and the links between knowledge and power."
An image can be contained within the physical world through a particular individual's perspective, primarily based on that individual's past experiences.
The idea of an image relies on the imagination and has been seen to be utilized by children in a very spontaneous and natural manner.
Cultural and social anthropologists today place a high value on doing ethnographic research.
Ethnographies are also sometimes called "case studies."
The fieldwork usually involves spending a year or more in another society, living with the local people and learning about their ways of life.
Benedict's experiences with the Southwest Zuni pueblo is to be considered the basis of her formative fieldwork.
A typical ethnography attempts to be holistic and typically follows an outline to include a brief history of the culture in question, an analysis of the physical geography or terrain inhabited by the people under study, including climate, and often including what biological anthropologists call habitat.
Kinship and social structure (including age grading, peer groups, gender, voluntary associations, clans, moieties, and so forth, if they exist) are typically included.
Rites, rituals, and other evidence of religion have long been an interest and are sometimes central to ethnographies, especially when conducted in public where visiting anthropologists can see them.
For example, if within a group of people, winking was a communicative gesture, he sought to first determine what kinds of things a wink might mean (it might mean several things).
Geertz, while still following something of a traditional ethnographic outline, moved outside that outline to talk about "webs" instead of "outlines" of culture.
Writing Culture helped bring changes to both anthropology and ethnography often described in terms of being 'postmodern,' 'reflexive,' 'literary,' 'deconstructive,' or 'poststructural' in nature, in that the text helped to highlight the various epistemic and political predicaments that many practitioners saw as plaguing ethnographic representations and practices.
In regards to this last point, Writing Culture became a focal point for looking at how ethnographers could describe different cultures and societies without denying the subjectivity of those individuals and groups being studied while simultaneously doing so without laying claim to absolute knowledge and objective authority.
As the purpose of ethnography is to describe and interpret the shared and learned patterns of values, behaviors, beliefs, and language of a culture-sharing group, Harris, (1968), also Agar (1980) note that ethnography is both a process and an outcome of the research.
Sociologist Sam Ladner argues in her book, that understanding consumers and their desires requires a shift in "standpoint," one that only ethnography provides.
By assessing user experience in a "natural" setting, ethnology yields insights into the practical applications of a product or service.
The Ethnographic Praxis in Industry (EPIC) conference is evidence of this.
Jaber F. Gubrium and James A. Holstein's (1997) monograph, The New Language of Qualitative Method, discusses forms of ethnography in terms of their "methods talk."
Essentially, Fine maintains that researchers are typically not as ethical as they claim or assume to be — and that "each job includes ways of doing things that would be inappropriate for others to know".
He maintains that "illusions" are essential to maintain an occupational reputation and avoid potentially more caustic consequences.
The code of ethics notes that anthropologists are part of a wider scholarly and political network, as well as human and natural environment, which needs to be reported on respectfully.
Researchers take near-fictions and turn them into claims of fact.
In reality, an ethnographer will always miss some aspect because of lacking omniscience.
Indigenous peoples, also referred to as first people, aboriginal people, native people, or autochthonous people, are culturally distinct ethnic groups who are native to a place which has been colonised and settled by another ethnic group.
Peoples are usually described as "indigenous" when they maintain traditions or other aspects of an early culture that is associated with a given region.
Indigenous peoples continue to face threats to their sovereignty, economic well-being, languages, ways of knowing, and access to the resources on which their cultures depend.
Estimates of the total global population of Indigenous peoples usually range from 250 million to 600 million.
As a reference to a group of people, the term Indigenous first came into use by Europeans who used it to differentiate the Indigenous peoples of the Americas from enslaved Africans.
In the 1970s, the term was used as a way of linking the experiences, issues, and struggles of groups of colonized people across international borders.
This situation can persist even in the case where the Indigenous population outnumbers that of the other inhabitants of the region or state; the defining notion here is one of separation from decision and regulatory processes that have some, at least titular, influence over aspects of their community and land rights.
A 2009 United Nations report published by the Secretariat of the Permanent Forum on Indigenous Issues stated: For centuries, since the time of their colonization, conquest or occupation, Indigenous peoples have documented histories of resistance, interface or cooperation with states, thus demonstrating their conviction and determination to survive with their distinct sovereign identities.
These people were seen by ancient writers either as the ancestors of the Greeks, or as an earlier group of people who inhabited Greece before the Greeks.
The Crusades (1096-1271) were based on this ambition of a holy war against who the church saw as infidels.
However, the council upheld that conquests could 'legally' occur if non-Christians refused to comply with Christianization and European natural law.
In the 14th and 15th centuries, the Indigenous peoples of what are now referred to as the Canary Islands, known as Guanches (who had lived on the islands since the BCE era) became the subject of colonizers' attention.
In 1402, the Spanish began efforts to invade and colonize the islands.
The invaders brought destruction and diseases to the Guanche people, whose identity and culture disappeared as a result.
As stated by Robert J. Miller, Jacinta Ruru, Larissa Behrendt, and Tracey Lindberg, the doctrine developed over time "to justify the domination of non-Christian, non-European peoples and the confiscations of their lands and rights."
Spanish King Ferdinand and Queen Isabella hired Christopher Columbus, who was dispatched in 1492, to colonize and bring new lands under the Spanish crown.
Alexander granted Spain any lands that it discovered as long as they had not been "previously possessed by any Christian owner."
Many conquistadors apparently feared that, if given the option, Indigenous peoples would actually accept Christianity, which would legally not permit invasion of their lands and the theft of their belongings.
Being Catholic countries in 1493, England as well as France worked to 're-interpret' the Doctrine of Discovery to serve their own colonial interests.
Land claims were made through symbolic "rituals of discovery" that were performed to illustrate the colonizing nation's legal claim to the land.
In 1774, Captain James Cook attempted to invalidate Spanish land claims to Tahiti by removing their marks of possession and then proceeding to set up English marks of possession.
This concept formalized the idea that lands which were not being used in a manner that European legal systems approved of were open for European colonization.
As the 'rules' of colonization became established into legal doctrine agreed upon by between European colonial powers, methods of laying claims to Indigenous lands continued to expand rapidly.
Precise estimates for the total population of the world's Indigenous peoples are very difficult to compile, given the difficulties in identification and the variances and inadequacies of available census data.
This includes at least 5,000 distinct peoples in over 72 countries.
Some have also been assimilated by other populations or have undergone many other changes.
The highly diverse and numerous ethnic groups that comprise most modern, independent African states contain within them various peoples whose situation, cultures and pastoralist or hunter-gatherer lifestyles are generally marginalized and set apart from the dominant political and economic structures of the nation.
The impacts of historical and ongoing European colonization of the Americas on Indigenous communities have been in general quite severe, with many authorities estimating ranges of significant population decline primarily due to disease, land theft and violence.
In the southern states of Oaxaca (65.73%) and Yucatán (65.40%), the majority of the population is Indigenous, as reported in 2015.
The descriptors "Indian" and "Eskimo" have fallen into disuse in Canada.
Most notable was the change of Aboriginal Affairs and Northern Development Canada (AANDC) to Indigenous and Northern Affairs Canada (INAC) in 2015, which then split into Indigenous Services Canada and Crown-Indigenous Relations and Northern Development Canada in 2017.
First Nations peoples signed 11 numbered treaties across much of what is now known as Canada between 1871 and 1921, except in parts of British Columbia.
The autonomous territory of Greenland within the Kingdom of Denmark is also home to a recognised Indigenous and majority population of Inuit (about 85%) who settled the area in the 13th century, displacing the Indigenous Dorset people and Greenlandic Norse.
In Spanish or Portuguese speaking countries, one finds the use of terms such as índios, pueblos indígenas, amerindios, povos nativos, povos indígenas, and, in Peru, Comunidades Nativas (Native Communities), particularly among Amazonian societies like the Urarina and Matsés.
Indigenous peoples are found in the entire territory of Brazil, although the majority of them live in Indian reservations in the North and Center-Western part of the country.
There are currently more Armenians living outside their ancestral homeland because of the Armenian genocide of 1915.
The argument entered the Israeli–Palestinian conflict in the 1990s, with Palestinians claiming Indigenous status as a pre-existing population displaced by Jewish settlement, and currently constituting a minority in the State of Israel.
In Russia, definition of "indigenous peoples" is contested largely referring to a number of population (less than 50 000 people), and neglecting self-identification, origin from indigenous populations who inhabited the country or region upon invasion, colonization or establishment of state frontiers, distinctive social, economic and cultural institutions.
The Tibetans are indigenous to Tibet.
In Hong Kong, the indigenous inhabitants of the New Territories are defined in the Sino-British Joint Declaration as people descended through the male line from a person who was in 1898, before Convention for the Extension of Hong Kong Territory.
The Cham are the indigenous people of the former state of Champa which was conquered by Vietnam in the Cham–Vietnamese wars during Nam tiến.
The Khmer Krom are the indigenous people of the Mekong Delta and Saigon which were acquired by Vietnam from Cambodian King Chey Chettha II in exchange for a Vietnamese princess.
This problem is shared by many other countries in the ASEAN region.
The indigenous peoples of Mindanao are the Lumad peoples and the Moro (Tausug, Maguindanao Maranao and others) who also live in the Sulu archipelago.
These groups are often together spoken of as Indigenous Australians.
During the 20th century, several of these former colonies gained independence and nation-states formed under local control.
The remains of at least 25 miniature humans, who lived between 1,000 and 3,000 years ago, were recently found on the islands of Palau in Micronesia.
According to the 2013 census, New Zealand Māori make up 14.9% of the population of New Zealand, with less than half (46.5%) of all Māori residents identifying solely as Māori.
Many Māori national leaders signed a treaty with the British, the Treaty of Waitangi (1840), seen in some circles as forming the modern geo-political entity that is New Zealand.
These issues include cultural and linguistic preservation, land rights, ownership and exploitation of natural resources, political determination and autonomy, environmental degradation and incursion, poverty, health, and discrimination.
The situation can be further confused when there is a complicated or contested history of migration and population of a given region, which can give rise to disputes about primacy and ownership of the land and resources.
Despite the diversity of indigenous peoples, it may be noted that they share common problems and issues in dealing with the prevailing, or invading, society.
Notable exceptions are the Sakha and Komi peoples (two northern indigenous peoples of Russia), who now control their own autonomous republics within the Russian state, and the Canadian Inuit, who form a majority of the territory of Nunavut (created in 1999).
This rejection ended up recognizing that there was a pre-existing system of law practised by the Meriam people.
Retrieved on 11 October 2011.
Hindus and Chams have both experienced religious and ethnic persecution and restrictions on their faith under the current Vietnamese government, with the Vietnamese state confiscating Cham property and forbidding Cham from observing their religious beliefs.
In 2012, Vietnamese police in Chau Giang village stormed into a Cham Mosque, stole the electric generator, and also raped Cham girls.
In 2012, Indonesia stated that ‘The Government of Indonesia supports the promotion and protection of indigenous people worldwide ... Indonesia, however, does not recognize the application of the indigenous peoples concept ... in the country’.
The Vietnamese were originally centered around the Red River Delta but engaged in conquest and seized new lands such as Champa, the Mekong Delta (from Cambodia) and the Central Highlands during Nam Tien.
The tremendous scale of Vietnamese Kinh colonists flooding into the Central Highlands has significantly altered the demographics of the region.
And no elimination of one culture by another.”
Indigenous peoples have been denoted primitives, savages or uncivilized.
Some philosophers, such as Thomas Hobbes (1588-1679), considered indigenous people to be merely "savages".
Retrieved from Internet Archive 13 December 2013.
The UN Declaration on the Rights of Indigenous Peoples, adopted by the General Assembly in 2007, established indigenous peoples' right to self-determination, implying several rights regarding natural resource management.
Oil drilling could destroy thousands of years of culture for the Gwich'in.
Development projects such as dam construction, pipelines and resource extraction have displaced large numbers of indigenous peoples, often without providing compensation.
These women also become economically dependent on men when they lose their livelihoods.
For example the Munduruku people in the Amazon rainforest are opposing the building of Tapajós dam with the help of Greenpeace.
Two main scenarios are proposed, an early expansion to Central Africa, and a single origin of the dispersal radiating from there, or an early separation into an eastward and a southward wave of dispersal, with one wave moving across the Congo basin towards East Africa, and another moving south along the African coast and the Congo River system towards Angola.
Cattle terminology in use amongst the relatively few modern Bantu pastoralist groups suggests that the acquisition of cattle may have been from Central Sudanic, Kuliak and Cushitic-speaking neighbors.
Not far from the Mutirikiwi river, the Monomatapa kings built the Great Zimbabwe complex, a civilisation ancestral to the Kalanga people.
The Swahili culture that emerged from these exchanges evinces many Arab and Islamic influences not seen in traditional Bantu culture, as do the many Afro-Arab members of the Bantu Swahili people.
After World War II, the National Party governments adopted that usage officially, while the growing African nationalist movement and its liberal allies turned to the term "African" instead, so that "Bantu" became identified with the policies of apartheid.
Again association with apartheid discredited the term, and the South African government shifted to the politically appealing but historically deceptive term "ethnic homelands".
In Swati the stem is -ntfu and the noun is buntfu.
Not all Basques are Basque-speakers.
modern Basque esan) and the suffix -(k)ara ("way (of doing something)").
He records the name of the Basque language as enusquera.
Although they are genetically distinctive in some ways due to isolation, the Basques are still very typically European in terms of their Y-DNA and mtDNA sequences, and in terms of some other genetic loci.
However, studies of the Y-DNA haplogroups found that on their direct male lineages, the vast majority of modern Basques have a common ancestry with other Western Europeans, namely a marked predominance of Indo-European Haplogroup R1b-DF27 (70%).
In spite of its high frequency in Basques, Y-STR internal diversity of R1b-DF27 is lower there, and results in more recent age estimates", implying it was brought to the region from elsewhere.
The collection of mtDNA and Y-DNA haplogroups sampled there differed significantly compared to their modern frequencies.
Rather, some 4500 years ago almost all Y-DNA heritage from Iberian admixture of Mesolithic hunter-gatherers and Neolithic farmers was replaced by the R1b lineage of Indo-European herders from the steppe, and the Basque genetic distinctiveness is a result of centuries of low population size, genetic drift, and endogamy.
Mattias Jakobsson from Uppsala University in Sweden analysed genetic material from eight Stone Age human skeletons found in El Portalón Cavern in Atapuerca, northern Spain.
The findings were published in Proceedings of the National Academy of Sciences of the United States.
This admixed group was also found to be ancestral to other modern-day Iberian peoples, but while the Basques remained relatively isolated for millennia after this time, later migrations into Iberia led to distinct and additional admixture in all other Iberian groups.
There is enough evidence to support the hypothesis that at that time and later they spoke old varieties of the Basque language (see: Aquitanian language).
The Kingdom of Pamplona, a central Basque realm, later known as Navarre, underwent a process of feudalization and was subject to the influence of its much larger Aragonese, Castilian and French neighbours.
Weakened by the Navarrese civil war, the bulk of the realm eventually fell before the onslaught of the Spanish armies (1512–1524).
Nevertheless, the Basques enjoyed a great deal of self-government until the French Revolution (1790) and the Carlist Wars (1839, 1876), when the Basques supported heir apparent Carlos V and his descendants.
The autonomous community (a concept established in the Spanish Constitution of 1978) known as Euskal Autonomia Erkidegoa or EAE in Basque and as Comunidad Autónoma Vasca or CAV in Spanish (in English: Basque Autonomous Community or BAC), is made up of the three Spanish provinces of Álava, Biscay and Gipuzkoa.
It is sometimes referred to simply as "the Basque Country" (or Euskadi) by writers and public agencies only considering those three western provinces, but also on occasions merely as a convenient abbreviation when this does not lead to confusion in the context.
In particular in common usage the French term Pays Basque ("Basque Country"), in the absence of further qualification, refers either to the whole Basque Country ("Euskal Herria" in Basque), or not infrequently to the northern (or "French") Basque Country specifically.
Note that in historical contexts Navarre may refer to a wider area, and that the present-day northern Basque province of Lower Navarre may also be referred to as (part of) Nafarroa, while the term "High Navarre" (Nafarroa Garaia in Basque, Alta Navarra in Spanish) is also encountered as a way of referring to the territory of the present-day autonomous community.
Knowledge of Spanish is compulsory under the Spanish constitution (article no.
Knowledge of Basque, after declining for many years during Franco's dictatorship owing to official persecution, is again on the rise due to favorable official language policies and popular support.
Only Spanish is an official language of Navarre, and the Basque language is only co-official in the province's northern region, where most Basque-speaking Navarrese are concentrated.
Much of this population lives in or near the Bayonne-Anglet-Biarritz (BAB) urban belt on the coast (in Basque these are Baiona, Angelu and Miarritze).
Millions of Basque descendants (see Basque American and Basque Canadian) live in North America (the United States; Canada, mainly in the provinces of Newfoundland and Quebec), Latin America (in all 23 countries), South Africa, and Australia.
Estimates range between 2.5 - 5 million Basque descendants live in Chile; the Basque have been a major if not the strongest influence in the country's cultural and economic development.
It consisted mostly of the area which is today the states of Chihuahua and Durango.
In Guatemala, most Basques have been concentrated in Sacatepequez Department, Antigua Guatemala, Jalapa for six generations now, while some have migrated to Guatemala City.
Bambuco, a Colombian folk music, has Basque roots.
Elko, Nevada, sponsors an annual Basque festival that celebrates the dance, cuisine and cultures of the Basque peoples of Spanish, French and Mexican nationalities who have arrived in Nevada since the late 19th century.
Some of North America's largest ranches, which were founded under these colonial land grants, can be found in this region.
There is a history of Basque culture in Chino, California.
They are mostly descendants of settlers from Spain and Mexico.
This sense of Basque identity tied to the local language does not only exist in isolation.
As with many European states, a regional identity, be it linguistically derived or otherwise, is not mutually exclusive with the broader national one.
I have friends who are involved in the political side of things but that is not for me.
There are extremely few Basque monolingual speakers: essentially all Basque speakers are bilingual on both sides of the border.
The Basque language is thought to be a genetic language isolate in contrast with other European languages, almost all of which belong to the broad Indo-European language family.
Home in this context is synonymous with family roots.
As in other cultures, the fate of other family members depended on the assets of a family: wealthy Basque families tended to provide for all children in some way, while less-affluent families may have had only one asset to provide to one child.
Mostly after the advent of industrialisation, this system resulted in the emigration of many rural Basques to Spain, France or the Americas.
Some scholars and commentators have attempted to reconcile these points by assuming that patrilineal kinship represents an innovation.
They emerged from the Franco regime with a revitalized language and culture.
The region has been a source of missionaries like Francis Xavier and Michel Garicoïts.
Lasuén was the successor to Franciscan Padre Junípero Serra and founded 9 of the 21 extant California Missions along the coast.
By the time Henry III of Navarre converted to Catholicism in order to become king of France, Protestantism virtually disappeared from the Basque community.
Nowadays, according to one single opinion poll, only slightly more than 50% of Basques profess some kind of belief in God, while the rest are either agnostic or atheist.
According to one, Christianity arrived in the Basque Country during the 4th and 5th centuries but according to the other, it did not take place until the 12th and 13th centuries.
In this sense, Christianity arrived "early".
According to one tradition, she travelled every seven years between a cave on Mount Anboto and one on another mountain (the stories vary); the weather would be wet when she was in Anboto, dry when she was in Aloña, or Supelegor, or Gorbea.
It's said that when they gathered in the high caves of the sacred peaks, they engendered the storms.
Legends also speak of many and abundant genies, like jentilak (equivalent to giants), lamiak (equivalent to nymphs), mairuak (builders of the cromlechs or stone circles, literally Moors), iratxoak (imps), sorginak (witches, priestess of Mari), and so on.
There is a trickster named San Martin Txiki ("St Martin the Lesser").
The jentilak ('Giants'), on the other hand, are a legendary people which explains the disappearance of a people of Stone Age culture that used to live in the high lands and with no knowledge of iron.
For more than a century, scholars have widely discussed the high status of Basque women in law codes, as well as their positions as judges, inheritors, and arbitrators through ante-Roman, medieval, and modern times.
Navarre has a separate statute of autonomy, a contentious arrangement designed during Spanish transition to democracy (the Amejoramiento, an 'upgrade' of its previous status during dictatorship).
Questions of political, linguistic and cultural allegiance and identity are highly complex in Navarre.
The majority of schools under the jurisdiction of the Basque education system use Basque as the primary medium of teaching.
In contrast, the desire for greater autonomy or independence is particularly common among leftist Basque nationalists.
They regard themselves as culturally and especially linguistically distinct from their surrounding neighbours.
Miguel de Unamuno was a noted novelist and philosopher of the late 19th and the 20th century.
He also founded the Chilean Trade Union Association to promote a union movement based on the social teachings of the Catholic Church.
The historical presence of the San in Botswana is particularly evident in northern Botswana's Tsodilo Hills region.
From the 1950s through to the 1990s, San communities switched to farming because of government-mandated modernisation programs.
Certain San groups are one of 14 known extant "ancestral population clusters"; that is, "groups of populations with common genetic ancestry, who share ethnicity and similarities in both their culture and the properties of their languages".
Representatives of San peoples in 2003 stated their preference of the use of such individual group names where possible over the use of the collective term San.
I continued to use Bushman, and I was publicly corrected several times by the righteous.
Instead, the San Council's representative was adamant that no hurt or harm was caused to them or the San community with the manner in which (Die Burger) published the word 'boesman'."
San kinship is comparable to Eskimo kinship, with the same set of terms as in European cultures, but also uses a name rule and an age rule.
Children have no social duties besides playing, and leisure is very important to San of all ages.
They make important family and group decisions and claim ownership of water holes and foraging areas.
Droughts may last many months and waterholes may dry up.
Into this hole is inserted a long hollow grass stem.
Early spring is the hardest season: a hot dry period following the cool, dry winter.
Women gather fruit, berries, tubers, bush onions, and other plant materials for the band's consumption.
Depending on location, the San consume 18 to 104 species, including grasshoppers, beetles, caterpillars, moths, butterflies, and termites.
These haplogroups are specific sub-groups of haplogroups A and B, the two earliest branches on the human Y-chromosome tree.
The most divergent (oldest) mitochondrial haplogroup, L0d, has been identified at its highest frequencies in the southern African San groups.
The San have been particularly affected by encroachment by majority peoples and non-indigenous farmers onto land traditionally occupied by San people.
Loss of land is a major contributor to the problems facing Botswana's indigenous people, including especially the San's eviction from the Central Kalahari Game Reserve.
This would award royalties to the San for the benefits of their indigenous knowledge.
Van der Post grew up in South Africa, and had a respectful lifelong fascination with native African cultures.
Driven by a lifelong fascination with this "vanished tribe", Van der Post published a 1958 book about this expedition, entitled The Lost World of the Kalahari.
His early film The Hunters, released in 1957, shows a giraffe hunt.
His sister Elizabeth Marshall Thomas wrote several books and numerous articles about the San, based in part on her experiences living with these people when their culture was still intact.
This was reviewed by Lawrence Van Gelder for the New York Times, who said that the film "constitutes an act of preservation and a requiem".
The BBC's The Life of Mammals (2003) series includes video footage of an indigenous San of the Kalahari desert undertaking a persistence hunt of a kudu through harsh desert conditions.
Because of their similarities, the San works may illustrate the reasons for ancient cave paintings.
The film was directed by Jamie Uys, who returned to the San a decade later with The Gods Must Be Crazy, which proved to be an international hit.
James A. Michener's The Covenant (1980), is a work of historical fiction centered on South Africa.
Norman Rush's 1991 novel Mating features an encampment of Basarwa near the (imaginary) Botswana town where the main action is set.
In 2007, David Gilman published The Devil's Breath.
The fiancé of the protagonist of The No.
The Germanic peoples were a historical group of people living in Central Europe and Scandinavia.
In discussions of the Roman period, the Germanic peoples are sometimes referred to as Germani or ancient Germans, although many scholars consider the second term problematic, since it suggests identity with modern Germans.
In contrast, Roman authors first described Germanic peoples near the Rhine at the time the Roman Empire established its dominance in that region.
Roman efforts to integrate the large area between Rhine and Elbe ended around 16 CE, following the major Roman defeat at the Battle of the Teutoburg Forest in 9 CE.
In the 3rd century the Germanic-speaking Goths dominated the Pontic Steppe, outside Germania, and launched a series of sea expeditions into the Balkans and Anatolia as far as Cyprus.
Archaeology instead shows a complex society and economy throughout Germania.
Traditionally, the Germanic peoples have been seen as possessing a law dominated by the concepts of feuding and blood compensation.
The ancient Germanic-speaking peoples probably shared a common poetic tradition, alliterative verse, and later Germanic peoples also shared legends originating in the Migration Period.
Even the language from which it derives is a subject of dispute, with proposals of Germanic, Celtic, and Latin, and Illyrian origins.
Regardless of its language of origin, the name was transmitted to the Romans via Celtic speakers.
By late antiquity, only peoples near the Rhine, especially the Franks, and sometimes the Alemanni, were called Germani by Latin or Greek writers.
While Roman authors did not consistently exclude Celtic speaking-people, or treat the Germanic peoples as the name of a people, this new definition, by using Germanic language as the main criterion, understood the Germani as a people or nation with a stable group identity linked to language.
Some scholars studying the Early Middle Ages now stress the question of whether the Germanic peoples saw themselves as an ethnic unity, while others point to the existence of Germanic languages as a historical fact that can be used to identify Germanic peoples, regardless of whether they saw themselves as "Germanic".
For such reasons, Goffart argues that the term Germanic should be avoided entirely in favor of "barbarian" except in the linguistic sense, and historians such as Walter Pohl have also called for the term to be avoided or used with careful explanation.
In Caesar's account, the clearest defining characteristic of the Germani people was that they lived east of the Rhine, opposite Gaul on the west side, an observation he made with historical digressions in his writing.
Tacitus was at times unsure whether a people were Germanic or not, expressing his uncertainty about the Bastarnae, who he says looked like Sarmatians but spoke like the Germani, about the Osi and the Cotini, and about the Aesti, who were like Suebi but spoke a different language.
The Upper Danube served as a southern border.
It is unclear if these Germani spoke a Germanic language, and they may have been Celtic speakers instead.
Tacitus continues to mention Germanic tribes on the west bank of the Rhine in the period of the early Empire, such as the Tungri, Nemetes, Ubii, and the Batavi.
Inspired by this, these three groups are also sometimes used in older modern linguistic terminology, attempting to describe the divisions of later Germanic languages.)
Herminones or Hermiones in the interior, included the Suevi, the Hermunduri, the Chatti, the Cherusci according to Pliny.
On the other hand, Tacitus wrote in the same passage that some believe that there are other groups which are just as old as these three, including "the Marsi, Gambrivii, Suevi, Vandilii".
Strabo, who focused mainly on Germani between the Elbe and Rhine, and does not mention the sons of Mannus, also set apart the names of Germani who are not Suevian, in two other groups, similarly implying three main divisions: "smaller German tribes, as the Cherusci, Chatti, Gamabrivi, Chattuarii, and next the ocean the Sicambri, Chaubi, Bructeri, Cimbri, Cauci, Caulci, Campsiani".
During the Pre-Germanic linguistic period (2500–500 BCE), the proto-language has almost certainly been influenced by linguistic substrates still noticeable in the Germanic phonology and lexicon.
There is also a great deal of influence in vocabulary from the Celtic languages, but most of this appears to be much later, with most loanwords occurring either before or during the sound shift described by Grimm's Law.
Although Proto-Germanic is reconstructed without dialects via the comparative method, it is almost certain that it never was a uniform proto-language.
The earliest attested runic inscriptions (Vimose comb, Øvre Stabu spearhead), initially concentrated in modern Denmark and written with the Elder Futhark system, are dated to the second half of the 2nd century CE.
However, the merging of unstressed Proto-Germanic vowels, attested in runic inscriptions from the 4th and 5th centuries CE, also suggests that Primitive Norse could not have been a direct predecessor of West Germanic dialects.
By the late 3rd century CE, linguistic divergences like the West Germanic loss of the final consonant -z had already occurred within the "residual" Northwest dialect continuum.
The inclusion of the Burgundian and Vandalic languages within the East Germanic group, while plausible, is still uncertain due to their scarce attestation.
A society is a group of individuals involved in persistent social interaction, or a large social group sharing the same spatial or social territory, typically subject to the same political authority and dominant cultural expectations.
Societies construct patterns of behavior by deeming certain actions or speech as acceptable or unacceptable.
Insofar as it is collaborative, a society can enable its members to benefit in ways that would otherwise be difficult on an individual basis; both individual and social (common) benefits can thus be distinguished, or in many cases found to overlap.
This was in turn from the Latin word societas, which in turn was derived from the noun socius ("comrade, friend, ally"; adjectival form socialis) used to describe a bond or interaction between parties that are friendly, or at least civil.
In the 1630s it was used in reference to "people bound by neighborhood and intercourse aware of living together in an ordered community".
These structures may have varying degrees of political power, depending on the cultural, geographical, and historical environments that these societies must contend with.
Tribal societies in which there are some limited instances of social rank and prestige.
This cultural evolution has a profound effect on patterns of community.
Cities turned into city-states and nation-states.
Conversely, members of a society may also shun or scapegoat any members of the society who violate its norms.
Some societies bestow status on an individual or group of people when that individual or group performs an admired or desired action.
Although humans have established many types of societies throughout history, anthropologists tend to classify different societies according to the degree to which different groups within a society have unequal access to advantages such as resources, prestige, or power.
However, some hunting and gathering societies in areas with abundant resources (such as people of tlingit) lived in larger groups and formed complex hierarchical social structures such as chiefdom.
Statuses within the tribe are relatively equal, and decisions are reached through general agreement.
There are no political offices containing real power, and a chief is merely a person of influence, a sort of adviser; therefore, tribal consolidations for collective action are not governmental.
Because their food supply is far more reliable, pastoral societies can support larger populations.
For example, some people become craftworkers, producing tools, weapons, and jewelry, among other items of value.
These families often gain power through their increased wealth.
The wild vegetation is cut and burned, and ashes are used as fertilizers.
They may return to the original land several years later and begin the process again.
The size of a village's population depends on the amount of land available for farming; thus villages can range from as few as 30 people to as many as 2000.
Sociologists use the phrase agricultural revolution to refer to the technological changes that occurred as long as 8,500 years ago that led to cultivating crops and raising farm animals.
Greater degrees of social stratification appeared in agrarian societies.
However, as food stores improved and women took on lesser roles in providing food for the family, they increasingly became subordinate to men.
A system of rulers with high social status also appeared.
Europe's exploration of the Americas served as one impetus for the development of capitalism.
This produced further dramatic increases in efficiency.
This larger surplus caused all of the changes discussed earlier in the domestication revolution to become even more pronounced.
However, inequality became even greater than before.
Geographically, it covers at the very least the countries of Western Europe, North America, Australia, and New Zealand.
One of the European Union's areas of interest is the information society.
Some academic, professional, and scientific associations describe themselves as societies (for example, the American Mathematical Society, the American Society of Civil Engineers, or the Royal Society).
A community is a social unit (a group of living things) with commonality such as norms, religion, values, customs, or identity.
In this sense it is synonymous with the concept of an ancient settlement - whether a hamlet, village, town, or city.
Most reconstructions of social communities by archaeologists rely on the principle that social interaction in the past was conditioned by physical distance.
No group is exclusively one or the other.
Socialization is influenced primarily by the family, through which children first learn community norms.
Community development practitioners must understand both how to work with individuals and how to affect communities' positions within the context of larger social institutions.
At the intersection between community development and community building are a number of programs and organizations with community development tools.
Emptiness: Moves beyond the attempts to fix, heal and convert of the chaos stage, when all people become capable of acknowledging their own woundedness and brokenness, common to human beings.
The three basic types of community organizing are grassroots organizing, coalition building, and "institution-based community organizing," (also called "broad-based community organizing," an example of which is faith-based community organizing, or Congregation-based Community Organizing).
Retrieved on: June 22, 2008.
Community organizing can focus on more than just resolving specific issues.
Such groups facilitate and encourage consensus decision-making with a focus on the general health of the community rather than a specific interest group.
Identity-based Communities: range from the local clique, sub-culture, ethnic group, religious, multicultural or pluralistic civilisation, or the global community cultures of today.
Relationships among members in a virtual community tend to focus on information exchange about specific topics.
Scholars in the humanities are "humanities scholars" or humanists.
The humanities generally study local traditions, through their history, literature, music, and arts, with an emphasis on understanding particular individuals, events, or eras.
Anthropology (like some fields of history) does not easily fit into one of these categories, and different branches of anthropology draw on one or more of these domains.
The word anthropos (άνθρωπος) is from the Greek word for "human being" or "person".
This means that, though anthropologists generally specialize in only one sub-field, they always keep in mind the biological, linguistic, historic and cultural aspects of any problem.
The quest for holism leads most anthropologists to study a people in detail, using biogenetic, archaeological, and linguistic data alongside direct observation of contemporary customs.
Archaeology can be considered both a social science and a branch of the humanities.
A good deal of twentieth-century and twenty-first-century philosophy has been devoted to the analysis of language and to the question of whether, as Wittgenstein claimed, many of our philosophical confusions derive from the vocabulary we use; literary theory has explored the rhetorical, associative, and ordering features of language; and historical linguists have studied the development of languages across time.
It has been defined as a "system of rules", as an "interpretive concept" to achieve justice, as an "authority" to mediate people's interests, and even as "the command of a sovereign, backed by the threat of a sanction".
Laws are politics, because politicians create them.
As Immanuel Kant noted, "Ancient Greek philosophy was divided into three sciences: physics, ethics, and logic.")
Shinto, Daoism, and other folk or natural religions do not have ethical codes.
Belief systems imply a logical model that religions do not display because of their internal contradictions, lack of evidence, and falsehoods. .
They are necessary for understanding the human predicament.
The non-founder religions are Hinduism, Shinto, and native or folk religions.
When traditional religions fail to address new concerns, then new religions will emerge.
Performing arts are also supported by workers in related fields, such as songwriting and stagecraft.
This is called Performance art.
Dance is also used to describe methods of non-verbal communication (see body language) between humans or animals (bee dance, mating dance), and motion in inanimate objects (the leaves danced in the wind).
In Byzantine and Gothic art of the Middle Ages, the dominance of the church insisted on the expression of biblical and not material truths.
A characteristic of this style is that the local colour is often defined by an outline (a contemporary equivalent is the cartoon).
It generally involves making marks on a surface by applying pressure from a tool, or moving a tool across a surface.
However, when used in an artistic sense it means the use of this activity in combination with drawing, composition and other aesthetic considerations in order to manifest the expressive and conceptual intention of the practitioner.
Black is associated with mourning in the West, but elsewhere white may be.
The word "red", for example, can cover a wide range of variations on the pure red of the spectrum.
This began with cubism and is not painting in strict sense.
Consequently, many spend the first few years after graduation deciding what to do next, resulting in lower incomes at the start of their career; meanwhile, graduates from career-oriented programs experience more rapid entry into the labour market.
However, the empirical evidence also shows that humanities graduates still earn notably higher incomes than workers with no postsecondary education, and have job satisfaction levels comparable to their peers from other fields.
As a percentage of the type of degrees awarded, however, the humanities seem to be declining.
Federal funding represents a much smaller fraction of funding for humanities than other fields such as STEM or medicine.
This understanding, they claimed, ties like-minded people from similar cultural backgrounds together and provides a sense of cultural continuity with the philosophical past.
Apart from its societal application, narrative imagination is an important tool in the (re)production of understood meaning in history, culture and literature.
Poststructuralism has problematized an approach to the humanistic study based on questions of meaning, intentionality, and authorship.
Furthermore, critical thinking, while arguably a result of humanistic training, can be acquired in other contexts.
Such pleasure contrasts with the increasing privatization of leisure and instant gratification characteristic of Western culture; it thus meets Jürgen Habermas' requirements for the disregard of social status and rational problematization of previously unquestioned areas necessary for an endeavor which takes place in the bourgeois public sphere.
Despite many humanities based arguments against the humanities some within the exact sciences have called for their return.
It’s good to know the history of philosophy.”
Communication (from Latin communicare, meaning "to share"or "to be in relation with") is "an apparent answer to the painful divisions between self and other, private and public, and inner thought and outer word."
Message composition (further internal or technical elaboration on what exactly to express).
Noise sources such as natural forces and in some cases human activity (both intentional and accidental) begin influencing the quality of signals propagating from the sender to one or more receivers.
Interpretation and making sense of the presumed original message.
Examples of intent are voluntary, intentional movements like shaking a hand or winking, as well as involuntary, such as sweating.
Likewise, written texts include nonverbal elements such as handwriting style, the spatial arrangement of words and the use of emoticons to convey emotion.
Some of the functions of nonverbal communication in humans are to complement and illustrate, to reinforce and emphasize, to replace and substitute, to control and regulate, and to contradict the denotative message.
To have total communication, all non-verbal channels such as the body, face, voice, appearance, touch, distance, timing, and other environmental forces must be engaged during face-to-face interaction.
"Non-verbal behaviours may form a universal language system."
Language learning normally occurs most intensively during human childhood.
Constructed languages such as Esperanto, programming languages, and various mathematical formalisms are not necessarily restricted to the properties shared by human languages.
The properties of language are governed by rules.
Contrary to popular belief, signed languages of the world (e.g., American Sign Language) are considered to be verbal communication because their sign vocabulary, grammar, and other linguistic structures abide by all the necessary classifications as spoken languages.
Communication is thus a process by which meaning is assigned and conveyed in an attempt to create shared understanding.
A channel, to which signals are adapted for transmission.
A destination, where the message arrives.
No allowance for differing purposes.
No allowance for situational contexts.
These acts may take many forms, in one of the various manners of communication.
Syntactic (formal properties of signs and symbols).
In light of these weaknesses, Barnlund (2008) proposed a transactional model of communication.
This second attitude of communication, referred to as the constitutive model or constructionist view, focuses on how an individual communicates as the determining factor of the way the message will be interpreted.
The sender's personal filters and the receiver's personal filters may vary depending upon different regional traditions, cultures, or gender; which may alter the intended meaning of message contents.
Although something like code books is implied by the model, they are nowhere represented in the model, which creates many conceptual difficulties.
Companies with limited resources may choose to engage in only a few of these activities, while larger organizations may employ a full spectrum of communications.
The information environment is the aggregate of individuals, organizations, and systems that collect, process, disseminate, or act on information.
In verbal interpersonal communication there are two types of messages being sent: a content message and a relational message.
This is the study of how individuals explain what causes different events and behaviors.
Open and honest communication creates an atmosphere that allows family members to express their differences as well as love and admiration for one another.
Researchers develop theories to understand communication behaviors.
This also includes a lack of expressing "knowledge-appropriate" communication, which occurs when a person uses ambiguous or complex legal words, medical jargon, or descriptions of a situation or environment that is not understood by the recipient.
Likewise, poor or outdated equipment, particularly the failure of management to introduce new technology, may also cause problems.
Examples might include an organizational structure which is unclear and therefore makes it confusing to know whom to communicate with.
It is better if such words are avoided by using alternatives whenever possible.
However, research in communication has shown that confusion can lend legitimacy to research when persuasion fails.
It is when the sender is expressing a thought or a word but the receiver gives it a different meaning.
This has, in turn, led to a notable change in the way younger generations communicate and perceive their own self-efficacy to communicate and connect with others.
Fear of being criticized – This is a major factor that prevents good communication.
This will not only boost your confidence but also improve your language and vocabulary.
Certain attitudes can also make communication difficult.
The act of disambiguation regards the attempt of reducing noise and wrong interpretations, when the semantic value or meaning of a sign can be subject to noise, or in presence of multiple meanings, which makes the sense-making difficult.
For example: words, colours and symbols have different meanings in different cultures.
Understanding cultural aspects of communication refers to having knowledge of different cultures in order to communicate effectively with cross culture people.
It also includes sounds from throat and all these are greatly influenced by cultural differences across borders.
This concept differs from culture to culture as the permissible space varies in different countries.
Some issues explaining this concept are pauses, silences and response lag during an interaction.
In different countries, the same gestures and postures are used to convey different messages.
Plant roots communicate with rhizome bacteria, fungi, and insects within the soil.
In parallel they produce other volatiles to attract parasites which attack these herbivores.
The biochemicals trigger the fungal organism to react in a specific manner, while if the same chemical molecules are not part of biotic messages, they do not trigger the fungal organism to react.
Through quorum sensing, bacteria can sense the density of cells, and regulate gene expression accordingly.
Information, in a general sense, is processed, organised and structured data.
Information is associated with data.
Information can be transmitted in time, via data storage, and space, via communication and telecommunication.
Information can be encoded into various forms for transmission and interpretation (for example, information may be encoded into a sequence of signs, or transmitted via a signal).
Uncertainty is inversely proportional to the probability of occurrence.
Furthermore, Latin itself already contained the word īnfōrmātiō meaning concept or idea, but the extent to which this may have influenced the development of the word information in English is not clear.
In modern Greek the word Πληροφορία is still in daily use and has the same meaning as the word information in English.
The field was fundamentally established by the works of Harry Nyquist and Ralph Hartley in the 1920s, and Claude Shannon in the 1940s.
Entropy quantifies the amount of uncertainty involved in the value of a random variable or the outcome of a random process.
Important sub-fields of information theory include source coding, algorithmic complexity theory, algorithmic information theory, and information-theoretic security.
In his book Sensory Ecology biophysicist David B. Dusenbery called these causal inputs.
In practice, information is usually carried by weak stimuli that must be detected by specialized sensory systems and amplified by energy inputs before they can be functional to the organism or system.
The sequence of nucleotides is a pattern that influences the formation and development of an organism without any need for a conscious mind.
In other words, it can be said that information in this sense is something potentially perceived as representation, though not created or presented for that purpose.
Whether the answer provides knowledge depends on the informed person.
This is the informational equivalent of almost 61 CD-ROM per person in 2007.
Sound records management ensures that the integrity of records is preserved for as long as they are required.
Beynon-Davies explains the multi-faceted concept of information in terms of signs and signal-sign systems.
Pragmatics is concerned with the purpose of communication.
In other words, pragmatics link language to action.
Semantics is the study of the meaning of signs - the association between signs and behaviour.
Syntax as an area studies the form of communication in terms of the logic and grammar of sign systems.
He introduces the concept of lexicographic information costs and refers to the effort a user of a dictionary must make to first find, and then understand data so that they can generate information.
In a communicative situation intentions are expressed through messages that comprise collections of inter-related signs taken from a language mutually understood by the agents involved in the communication.
Information visualization (shortened as InfoVis) depends on the computation and digital representation of data, and assists users in pattern recognition and anomaly detection.
The term is generally employed in sociology and the other social sciences as well as in philosophy and bioethics.
In developing societies it may be mainly based on kinship and shared values while more developed societies accumulate various theories as to what contributes to a sense of solidarity, or rather, social cohesion.
Durkheim introduced the terms mechanical and organic solidarity as part of his theory of the development of societies in The Division of Labour in Society (1893).
Collins Dictionary of Sociology, p405-6.
Definition: it is social cohesion based upon the dependence which individuals have on each other in more advanced societies.
Early ancient philosophers such as Socrates and Aristotle discuss solidarity as a virtue ethics framework because in order to live a good life one must perform actions and behave in a way that is in solidarity with the community.
The modern practice of bioethics is significantly influenced by Immanuel Kant's concept of the Categorical Imperative.
Foreign-area studies were virtually nonexistent.
The former became area-studies advocates, the latter proponents of modernization theory.
From 1953 to 1966 it contributed $270 million to 34 universities for area and language studies.
Other large and important programs followed Ford's.
Others insisted, however, that once they were established on university campuses, area studies began to encompass a much broader and deeper intellectual agenda than the one foreseen by government agencies, thus not American centric.
Other interdisciplinary research fields such as women's studies, gender studies, disability studies, LGBT studies and ethnic studies (including African American studies, Asian American studies, Latino studies, Chicano studies and Native American studies) are not part of area studies but are sometimes included in discussion along with it.
Demography (from prefix demo- from Ancient Greek δῆμος (dēmos) meaning 'the people', and -graphy from γράφω (graphō) meaning 'writing, description or measurement') is the statistical study of populations, especially human beings.
Patient demographics form the core of the data for any medical institution,such as patient and emergency contact information and patient medical record data.
The term Demography refers to the overall study of population.
In the Middle ages, Christian thinkers devoted much time in refuting the Classical ideas on demography.
One of the earliest demographic studies in the modern period was Natural and Political Observations Made upon the Bills of Mortality (1662) by John Graunt, which contains a primitive form of life table.
His work influenced Thomas Robert Malthus, who, writing at the end of the 18th century, feared that, if unchecked, population growth would tend to outstrip growth in food production, leading to ever-increasing famine and poverty (see Malthusian catastrophe).
A census is the other common direct method of collecting demographic data.
Analyses are conducted after a census to estimate how much over or undercounting took place.
Other indirect methods in contemporary demography include asking people about siblings, parents, and children.
They include models of mortality (including the life table, Gompertz models, hazards models, Cox proportional hazards models, multiple decrement life tables, Brass relational logits), fertility (Hernes model, Coale-Trussell models, parity progression ratios), marriage (Singulate Mean at Marriage, Page model), disability (Sullivan's method, multistate life tables), population projections (Lee-Carter model, the Leslie Matrix), and population momentum (Keyfitz).
The age-specific fertility rates, the annual number of live births per 1,000 women in particular age groups (usually age 15–19, 20-24 etc.)
The expectation of life (or life expectancy), the number of years that an individual at a given age could expect to live at present mortality levels.
A stationary population, one that is both stable and unchanging in size (the difference between crude birth rate and crude death rate is zero).
Note that the crude death rate as defined above and applied to a whole population can give a misleading impression.
Individuals who change their ethnic self-labels or whose ethnic classification in government statistics changes over time may be thought of as migrating or moving from one population subcategory to another.
The figure in this section shows the latest (2004) UN projections of world population out to the year 2150 (red = high, orange = medium, green = low).
Mortality is the study of the causes, consequences, and measurement of processes affecting death to members of the population.
Migration researchers do not designate movements 'migrations' unless they are somewhat permanent.
Demography is today widely taught in many universities across the world, attracting students with initial training in social sciences, statistics or health studies.
In this respect, one can see information science as a response to technological determinism, the belief that technology "develops by its own laws, that it realizes its own potential, limited only by the material resources available and the creativity of its developers.
It is concerned with that body of knowledge relating to the origination, collection, organization, storage, retrieval, interpretation, transmission, transformation, and utilization of information.
This is especially true when related to the concept developed by A. I. Mikhailov and other Soviet authors in the mid-1960s.
Definitions reliant on the nature of the tools used for deriving meaningful information from data are emerging in Informatics academic programs.
It can be used to reason about the entities within that domain and may be used to describe the domain.
Traditionally, their work has been with print materials, but these skills are being increasingly used with electronic, visual, audio, and digital materials.
Institutionally, information science emerged in the 19th century along with many other social science disciplines.
In 1731, Benjamin Franklin established the Library Company of Philadelphia, the first library owned by a group of public citizens, which quickly expanded beyond the realm of books and became a center of scientific experiment, and which hosted public exhibitions of scientific experiments.
In 1801, Joseph Marie Jacquard invented a punched card system to control operations of the cloth weaving loom in France.
By 1843 Richard Hoe developed the rotary press, and in 1844 Samuel Morse sent the first public telegraph message.
In 1860 a congress was held at Karlsruhe Technische Hochschule to discuss the feasibility of establishing a systematic and rational nomenclature for chemistry.
The following year the Royal Society began publication of its Catalogue of Papers in London.
Many information science historians cite Paul Otlet and Henri La Fontaine as the fathers of information science with the founding of the International Institute of Bibliography (IIB) in 1895.
Documentalists emphasized the utilitarian integration of technology and technique toward specific social goals.
Otlet and Lafontaine established numerous organizations dedicated to standardization, bibliography, international associations, and consequently, international cooperation.
This collection involved standardized paper sheets and cards filed in custom-designed cabinets according to a hierarchical index (which culled information worldwide from diverse sources) and a commercial information retrieval service (which answered written requests by copying relevant information from index cards).
Additionally, traditional boundaries among disciplines began to fade and many information science scholars joined with other programs.
The 1980s also saw the emergence of numerous special interest groups to respond to the changes.
Zhang, B., Semenov, A., Vos, M. and Veijlainen, J. (2014).
Sharing through social media has become so influential that publishers must "play nice" if they desire to succeed.
It is for this reason that these networks have been realized for the potential they provide. "
What about assigning privileges and restricting access to unauthorized users?
It is an emerging discipline and community of practice focused on bringing together principles of design and architecture to the digital landscape.
Automated information retrieval systems are used to reduce what has been called "information overload".
An information retrieval process begins when a user enters a query into the system.
Instead, several objects may match the query, perhaps with different degrees of relevancy.
Depending on the application the data objects may be, for example, text documents, images, audio, mind maps or videos.
Information seeking is related to, but different from, information retrieval (IR).
Logic is used to supply formal semantics of how reasoning functions should be applied to the symbols in the KR system.
It was also a common belief that natural disasters such as famine and flood were divine retributions bearing signs of Heaven's displeasure with the ruler, so there would often be revolts following major disasters as the people saw these calamities as signs that the Mandate of Heaven had been withdrawn.
The concept is in some ways similar to the European concept of the divine right of kings; however, unlike the European concept, it does not confer an unconditional right to rule.
The Mandate of Heaven was often invoked by philosophers and scholars in China as a way to curtail the abuse of power by the ruler, in a system that had few other checks.
Notably, the dynasty lasted for a considerable time during which 31 kings ruled over an extended period of 17 generations.
As time went on, however, the rulers' abuse of the other social classes led to social unrest and instability.
They created the Mandate of Heaven to explain their right to assume rule and presumed that the only way to hold the mandate was to rule well in the eyes of Heaven.
However, in order to appease some of the citizens, they allowed some Shang beneficiaries to continue governing their small kingdoms in compliance with Zhou rules and regulations.
They also excelled in shipbuilding, which, coupled with their discovery of celestial navigation, made them excellent mariners.
Most of these works are commentaries on the progress and political movement of the dynasty.
Their works primarily stressed the importance of the ruling class, respect, and their relationship with the lower class.
Within these districts were administrators who were appointed by the government, in return, they had to maintain their allegiance to the main internal government.
Finally, when the Zhou dynasty's power decreased, it was wiped out by the State of Qin, which believed that the Zhou had become weak and their rule unjust.
During this reformation, administrative changes were made and a system of legalism was developed which stated that the law is supreme over every individual, including the rulers.
The establishment of the Han dynasty marked a great period in China’s history marked by significant changes in the political structure of the country.
A major purpose was to establish justification for the transference of the Mandate of Heaven through these five dynasties and thus to the Song dynasty.
They also held considerably more territory than any of the other Chinese states that had existed conterminously in the south.
The brutal behavior of Zhu Wen and the Later Liang was a source of considerable embarrassment, and thus there was pressure to exclude them from the Mandate.
However, Kublai Khan was the only indifferent ruler when he claimed the Mandate of Heaven over the Yuan Dynasty since he had a sizable military and was part of the Khitan people, as with many others from the same background since they did not have the same traditions and culture as their Chinese adversaries.
It was solely politics from beginning to end and an attempt from the emperor to maintain a favorable act towards Heaven.
The Right of Rebellion is not coded into any official law.
Since the winner is the one who determines who has obtained the Mandate of Heaven and who has lost it, some Chinese scholars consider it to be a sort of Victor's justice, best characterized in the popular Chinese saying "The winner becomes king, the loser becomes outlaw" (Chinese: “成者爲王，敗者爲寇”).
The kingdom of Silla is also said to be adopted the Mandate of Heaven, but the earliest records are from Joseon Dynasty, which made the Mandate of Heaven an enduring state ideology.
The later and more centralized Vietnamese dynasties adopted Confucianism as the state ideology, which led to the creation of a Vietnamese tributary system in Southeast Asia that was modeled after the Chinese Sinocentric system in East Asia.
In later times, this need was obviated because the Imperial House of Japan claimed to be descended in an unbroken line from the Japanese sun goddess, Amaterasu.
Even after the Meiji Restoration in 1868, when the emperor was placed back in the center of the political bureaucracy, the throne itself had very little power vis-à-vis the Meiji oligarchy.
Media studies is a discipline and field of study that deals with the content, history, and effects of various media; in particular, the mass media.
Media studies in Australia was first developed as an area of study in Victorian universities in the early 1960s, and in secondary schools in the mid 1960s.
In secondary schools, an early film studies course first began being taught as part of the Victorian junior secondary curriculum during the mid 1960s.
It has since become, and continues to be, a strong component of the VCE.
Media studies does not appear to be taught in the state of New South Wales at a secondary level.
Harold Innis and Marshall McLuhan are famous Canadian scholars for their contributions to the fields of media ecology and political economy in the 20th century.
Carleton University and the University of Western Ontario, 1945 and 1946 prospectively, created Journalism specific programs or schools.
Today, most universities offer undergraduate degrees in Media and Communication Studies, and many Canadian scholars actively contribute to the field, among which: Brian Massumi (philosophy, cultural studies), Kim Sawchuk (cultural studies, feminist, ageing studies), Carrie Rentschler (feminist theory), and François Cooren (organizational communication).
A medium is anything that mediates our interaction with the world or other humans.
McLuhan says that the “technique of fragmentation that is the essence of machine technology” shaped the restructuring of human work and association and “the essence of automation technology is the opposite”.
The characteristic of all media means the “content” of any medium is always another medium.
If the electric light is used for Friday night football or to light up your desk you could argue that the content of the electric light is these activities.
It is not until the electric light is used to spell a brand name that it is recognized as medium.
The effect of the medium is made strong because it is given another media “content”.
Hot media are low in participation and cool media are high in participation.
Communication University of China, formerly known as the Beijing Broadcasting Institute, that dates back to 1954.
Bourdieu's analysis is that television provides far less autonomy, or freedom, than we think.
Within the field of Film Studies, again, both Frankfurt and Berlin were dominant in the development of new perspectives on moving image media.
One of the early publications in this new direction is a volume edited by Helmut Kreuzer, Literature Studies - Media Studies (Literaturwissenschaft – Medienwissenschaft), which summarizes the presentations given at the Düsseldorfer Germanistentag 1976.
The German Institute for Media and Communication Policy, founded in 2005 by media scholar Lutz Hachmeister, is one of the few independent research institutions that is dedicated to issues surrounding media and communications policies.
Medienwissenschaften is currently one of the most popular courses of study at universities in Germany, with many applicants mistakenly assuming that studying it will automatically lead to a career in TV or other media.
It offers a five-year integrated programme and a two-year programme in Electronic Media.
Whereas communication sciences focuses on the way people communicate, be it mediated or unmediated, media studies tends to narrow the communication down to just mediated communication.
Communication sciences (or a derivative thereof) can be studied at Erasmus University Rotterdam, Radboud University, Tilburg University, University of Amsterdam, University of Groningen, University of Twente, Roosevelt Academy, University of Utrecht, VU University Amsterdam and Wageningen University and Research Centre.
University of the Punjab Lahore is the oldest department.
Media Studies is now taught all over the UK.
However, the focus of such programs sometimes excludes certain media—film, book publishing, video games, etc.
This is partly thanks to the acquisition of Professor Siva Vaidhyanathan, a cultural historian and media scholar, as well as the Inaugural Verklin Media Policy and Ethics Conference, endowed by the CEO of Canoe Ventures and UVA alumnus David Verklin.
A media studies major at Radford still means someone concentrating on journalism, broadcasting, advertising or Web production.)
Bergson contrasted an open society with what he called a closed society, a closed system of law, morality or religion.
Soros, George, "The Age of Fallibility," Public Affairs (2006).
Totalitarianism forced knowledge to become political which made critical thinking impossible and led to the destruction of knowledge in totalitarian countries.
In the closed society, claims to certain knowledge and ultimate truth lead to the attempted imposition of one version of reality.
Because the electorate's perception of reality can easily be manipulated, democratic political discourse does not necessarily lead to a better understanding of reality.
Popper however, did not identify the open society either with democracy or with capitalism or a laissez-faire economy, but rather with a critical frame of mind on the part of the individual, in the face of communal group think of whatever kind.
Regulatory colleges are legal entities charged with serving the public interest by regulating the practice of a profession.
For example, no worker in Ontario may work in a compulsory trade without membership in the Ontario College of Trades.
For Weber, sociology is the study of society and behavior and must therefore look at the heart of interaction.
The term is more practical and encompassing than Florian Znaniecki's "social phenomena", since the individual performing social action is not passive, but rather active and reactive.
This is also considered alternative means when secondary consequences have ended.
If the student chooses not to do well in college, they know that it will be difficult to get into law school and ultimately achieve the goal of being a lawyer.
Value Relation is divided into the subgroups commands and demands.
These demands have posed several problems even legal formalism has been put to the test.
To the extent that there are many religious firms competing against each other, they will tend to specialize and cater to the particular needs of some segments of religious consumers.
It is well known that strict churches are strong and growing in the contemporary United States, whereas liberal ones are declining.
Affectual action (also known as emotional actions): actions which are taken due to 'one's emotions, to express personal feelings.
In uncontrolled reaction there is no restraint and there is lack of discretion.
When aspirations are not fulfilled there is internal unrest.
A common example is behavioral and rational choice assumptions.
These six concepts were identified by Aristotle and are still the topic of several talks.
Micrological theories of economy consider acts of a group of individuals.
By doing this it causes providers to be competitive and therefore creates order in the economy.
Rational choice theory although increasingly colonized by economist, it does differ from microeconomic conceptions.
Traditional actions: actions which are carried out due to tradition, because they are always carried out in a particular manner for certain situations.
A custom is a practice that rests among familiarity.
A habit is a series of steps learned gradually and sometimes without conscious awareness.
The idea of Cooley's looking glass self is that our sense of self develops as we observe and reflect upon others and what they may think of our actions.
Social capital is "the networks of relationships among people who live and work in a particular society, enabling that society to function effectively".
In the first half of the 19th century, de Tocqueville had observations about American life that seemed to outline and define social capital.
The community as a whole will benefit by the cooperation of all its parts, while the individual will find in his associations the advantages of the help, the sympathy, and the fellowship of his neighbours.
In the words of Stein (1960:1): "The price for maintaining a society that encourages cultural differentiation and experimentation is unquestionably the acceptance of a certain amount of disorganization on both the individual and social level."
All of these reflections contributed remarkably to the development of the social capital concept in the following decades.
Robert D. Putnam (1993) suggested that social capital would facilitate co-operation and mutually supportive relations in communities and nations and would therefore be a valuable means of combating many of the social disorders inherent in modern societies, for example crime.
Nan Lin's concept of social capital has a more individualistic approach: "Investment in social relations with expected returns in the marketplace."
The term capital is used by analogy with other forms of economic capital, as social capital is argued to have similar (although less measurable) benefits.
Robison, Schmid, and Siles (2002) reviewed various definitions of social capital and concluded that many did not satisfy the formal requirement of a definition.
They propose that social capital be defined as sympathy: the object of another's sympathy has social capital; those who have sympathy for others provide social capital.
Social capital is also distinguished from the economic theory social capitalism.
It "creates value for the people who are connected, and for bystanders as well."
According to Robert D. Putnam, social capital refers to "connections among individuals – social networks and the norms of reciprocity and trustworthiness that arise from them."
This is seen in lower levels of trust in government and lower levels of civic participation.
Putnam also suggests that a root cause of the decline in social capital is women's entry the workforce, which could correlate with time restraints that inhibit civic organizational involvement like parent-teacher associations.
Fukuyama suggests that while social capital is beneficial for development, it also imposes cost on non-group members with unintended consequences for general welfare.
This dimension focuses on the advantages derived from the configuration of an actor's, either individual or collective, network.
This is best characterized through trust of others and their cooperation and the identification an individual has within a network.
Research by Sheri Berman and Dylan Riley, as well as economists Shanker Satyanath, Nico Voigtländer, and Hans-Joachim Voth, have linked civic associations to the rise of fascist movements.
The negative consequences of social capital are more often associated with bonding vis-à-vis bridging.
Bonding and bridging social capital can work together productively if in balance, or they may work against each other.
The strengthening of insular ties can lead to a variety of effects such as ethnic marginalization or social isolation.
Germans threw themselves into their clubs, voluntary associations, and professional organizations out of frustration with the failures of the national government and political parties, thereby helping to undermine the Weimar Republic and facilitate Hitler's rise to power.
They were very introverted in the Weimar Republic.
Robert Putnam, in his later work, also suggests that social capital, and the associated growth of public trust are inhibited by immigration and rising racial diversity in communities.
Lack of homogeneity led to people withdrawing from even their closest groups and relationships, creating an atomized society as opposed to a cohesive community.
Human capital, a private resource, could be accessed through what the previous generation accumulated through social capital.
Even though Coleman never truly addresses Pierre Bourdieu in his discussion, this coincides with Bourdieu's argument set forth in Reproduction in Education, Society and Culture.
Thus, it is the social platform, itself, that equips one with the social reality they become accustomed to.
To illustrate this, we assume that an individual wishes to better his place in society.
Is Civil Society an Adequate Theory?
Typical examples are that criminal gangs create bonding social capital, while choirs and bowling clubs (hence the title, as Putnam lamented their decline) create bridging social capital.
Aldrich also applies the ideas of social capital to the fundamental principles of disaster recovery, and discusses factors that either aid or impede recovery, such as extent of damage, population density, quality of government and aid.
People who live their life this way feel that these are norms of society and are able to live their lives free of worry for their credit, children, and receive charity if needed.
All forms of "capital" were, for Marx, possessed only by capitalists and he emphasized the basis of labour in capitalist society, as a class constituted by individuals obliged to sell their labour power, because they lacked sufficient capital, in any sense of the word, to do otherwise.
Portes mentions the donation of a scholarship to a member of the same ethnic group as an example of this.
Bonding and bridging sub-scales are proposed, which have been adopted by over 300 scholarly articles.
However, there is no one quantitative way of determining the level of cohesiveness, but rather a collection of social network models that researchers have used over the decades to operationalize social capital.
Groups with higher membership (such as political parties) contribute more to the amount of capital than groups with lower membership, although many groups with low membership (such as communities) still add up to be significant.
How a group relates to the rest of society also affects social capital, but in a different manner.
Recognizing that one may not be able to influence the sympathy of others, persons seeking to belong may act to increase their own sympathy for others and the organizations or institutions they represent.
According to such authors as Walzer (1992), Alessandrini (2002), Newtown, Stolle & Rochon, Foley & Edwards (1997), and Walters, it is through civil society, or more accurately, the third sector, that individuals are able to establish and maintain relational networks.
Not only has civil society been documented to produce sources of social capital, according to Lyons' Third Sector (2001), social capital does not appear in any guise under either the factors that enable or those that stimulate the growth of the third sector.
The goal is to reintegrate those marginalised from the rewards of the economic system into "the community."
Alessandrini agrees, saying that, "in Australia in particular, neo-liberalism has been recast as economic rationalism and identified by several theorists and commentators as a danger to society at large because of the use to which they are putting social capital to work."
In international development, Ben Fine (2001) and John Harriss (2001) have been heavily critical of the inappropriate adoption of social capital as a supposed panacea (promoting civil society organisations and NGOs, for example, as agents of development) for the inequalities generated by neoliberal economic development.
However, higher levels of social capital led to higher support for democracy.
Careful evaluation of these fundamental factors often suggests that women do not vote at similar levels as men.
Social capital offers a wealth of resources and networks that facilitate political engagement.
Women are more likely to organize themselves in less hierarchical ways and to focus on creating consensus.
For example, a person who is sick with cancer may receive information, money, or moral support he or she needs to endure treatment and recover.
Furthermore, neighbourhood social capital may also aid in buffering health inequities amongst children and adolescents.
The relationships and networks that are maintained by an ethnic minority population in a geographical area where a high percentage of residents belong to the same ethnic group may lead to better health outcomes than would be expected based on other individual and neighbourhood characteristics.
For example, results from a survey given to 13- to 18-year-old students in Sweden showed that low social capital and low social trust are associated with higher rates of psychosomatic symptoms, musculoskeletal pain, and depression.
In one study, informational uses of the Internet correlated positively with an individual's production of social capital, and social-recreational uses were negatively correlated (higher levels of these uses correlated with lower levels of social capital).
This means that individuals can selectively connect with others based on ascertained interests, and backgrounds.
This argument continues, although the preponderance of evidence shows a positive association between social capital and the Internet.
Recent research, conducted in 2006, also shows that Internet users often have wider networks than those who access the Internet irregularly or not at all.
Other research shows that younger people use the Internet as a supplemental medium for communication, rather than letting the Internet communication replace face-to-face contact.
They criticise Coleman, who used only the number of parents present in the family, neglected the unseen effect of more discrete dimensions such as stepparents' and different types of single-parent families.
Morgan and Sorensen (1999) directly challenge Coleman for his lacking of an explicit mechanism to explain why Catholic schools students perform better than public school students on standardised tests of achievement.
It is found that while social capital can bring about positive effect of maintaining an encompassing functional community in norm-enforcing schools, it also brings about the negative consequence of excessive monitoring.
These schools explore a different type of social capital, such as information about opportunities in the extended social networks of parents and other adults.
The similarity of these states is that parents were more associated with their children's education.
Without social capital in the area of education, teachers and parents who play a responsibility in a students learning, the significant impacts on their child's academic learning can rely on these factors.
As Tedin and Weiher (2010) state, "one of the most important factors in promoting student success is the active involvement of parents in a child's education."
Supportive networks, as a form of social capital, is necessary for activating the cultural capital the newly arrived students possessed.
Ethnic solidarity is especially important in the context where immigrants just arrive in the host society.
Ethnic support provides impetus to academic success.
His main argument for classifying social capital as a geographical concept is that the relationships of people is shaped and molded by the areas in which they live.
In his studies, he does not look at the individual participants of these structures, but how the structures and the social connections that stem from them are diffused over space.
Another area where social capital can be seen as an area of study in geography is through the analysis of participation in volunteerism and its support of different governments.
There is a significant connection between leisure and democratic social capital.
In a later study, Kislev (2020) shows the relation between romantic relationships desire and singleness.
Similar results were revealed in a cross-sectional study run by Sarker in Bangladesh.
Epo did this by comparing the welfare outcomes of the entrepreneurs who both had access and no access.
Group cohesiveness (also called group cohesion and social cohesion) arises when bonds link members of a social group to one another and to the group as a whole.
Cohesion can be more specifically defined as the tendency for a group to be in unity while working towards a goal or to satisfy the emotional needs of its members.
Its dynamic nature refers to how it gradually changes over time in its strength and form from the time a group is formed to when a group is disbanded.
This definition can be generalized to most groups characterized by the group definition discussed above.
In a study, they asked the group members to identify all their good friends and calculated the ratio of ingroup choices to outgroup choices.
Group cohesion is similar to a type of group-level attraction which, according to Hogg, is known as social attraction.
Lott and Lott (1965) who refer to interpersonal attraction as group cohesiveness conducted an extensive review on the literature and found that individuals' similarities in background (e.g., race, ethnicity, occupation, age), attitudes, values and personality traits have generally positive association with group cohesiveness.
In addition, similar background makes it more likely that members share similar views on various issues, including group objectives, communication methods and the type of desired leadership.
This is often caused by social loafing, a theory that says individual members of a group will actually put in less effort, because they believe other members will make up for the slack.
Most meta-analyses (studies that have summarized the results of many studies) have shown that there is a relationship between cohesion and performance.
When it is defined as task commitment, it is also correlated with performance, though to a lesser degree than cohesion as attraction.
However, some groups may have a stronger cohesion-performance relationship than others.
There is some evidence that cohesion may be more strongly related to performance for groups that have highly interdependent roles than for groups in which members are independent.
Furthermore, groups with high performance goals were extremely productive.
Members in cohesive groups also are more optimistic and suffer less from social problems than those in non-cohesive groups.
It was found that the masons and carpenters were more satisfied when they worked in cohesive groups.
One study showed that cohesion as task commitment can improve group decision making when the group is under stress, more than when it is not under stress.
The study found that teams with low cohesion and high urgency performed worse than teams with high cohesion and high urgency.
The theory of groupthink suggests that the pressures hinder the group from critically thinking about the decisions it is making.
Another reason is because people value the group and are thus, more willing to give into conformity pressures to maintain or enhance their relationships.
The degree of member liking was presumed to indicate group cohesiveness.
According to the government-commissioned, State of the English Cities thematic reports, there are five different dimensions of social cohesion: material conditions, passive relationships, active relationships, solidarity, inclusion and equality.
These basic necessities of life are the foundations of a strong social fabric and important indicators of social progress.
The third dimension refers to the positive interactions, exchanges and networks between individuals and communities, or "active social relationships".
It also includes people's sense of belonging to a city and the strength of shared experiences, identities and values between those from different backgrounds.
On a societal level Albrekt Larsen defines social cohesion 'as the belief—held by citizens in a given nation state—that they share a moral community, which enables them to trust each other'.
Social formation is a Marxist concept (synonymous with 'society') referring to the concrete, historical articulation between the capitalist mode of production, maintaining pre-capitalist modes of production, and the institutional context of the economy (disambiguation).
In the social sciences, social structure is the patterned social arrangements in society that are both emergent from and determinant of the actions of individuals.
It contrasts with "social system", which refers to the parent structure in which these various structures are embedded.
It determines the norms and patterns of relations between the various institutions of the society.
It is also important in the modern study of organizations, as an organization's structure may determine its flexibility, capacity to change, etc.
On the meso scale, it concerns the structure of social networks between individuals or organizations.
For example, John Levi Martin has theorized that certain macro-scale structures are the emergent properties of micro-scale cultural institutions (i.e., "structure" resembles that used by anthropologist Claude Levi-Strauss).
Alexis de Tocqueville was supposedly the first to use the term "social structure".
One of the earliest and most comprehensive accounts of social structure was provided by Karl Marx, who related political, cultural, and religious life to the mode of production (an underlying economic structure).
Émile Durkheim, drawing on the analogies between biological and social systems popularized by Herbert Spencer and others, introduced the idea that diverse social institutions and practices played a role in assuring the functional integration of society through assimilation of diverse parts into a unified and self-reproducing whole.
Others follow Lévi-Strauss in seeking logical order in cultural structures.
The most influential attempts to combine the concept of social structure with agency are Anthony Giddens' theory of structuration and Pierre Bourdieu's practice theory.
Giddens's analysis, in this respect, closely parallels Jacques Derrida's deconstruction of the binaries that underlie classic sociological and anthropological reasoning (notably the universalizing tendencies of Lévi-Strauss's structuralism).
This was studied by Jacob L. Moreno.
Sociobiology is a field of biology that aims to examine and explain social behavior in terms of evolution.
Sociobiology investigates social behaviors such as mating patterns, territorial fights, pack hunting, and the hive society of social insects.
It predicts that animals will act in ways that have proven to be evolutionarily successful over time.
Behavior is therefore seen as an effort to preserve one's genes in the population.
Altmann developed his own brand of sociobiology to study the social behavior of rhesus macaques, using statistics, and was hired as a "sociobiologist" at the Yerkes Regional Primate Research Center in 1965.
Once a specialist term, "sociobiology" became widely known in 1975 when Wilson published his book Sociobiology: The New Synthesis, which sparked an intense controversy.
However, the influence of evolution on behavior has been of interest to biologists and philosophers since soon after the discovery of evolution itself.
Edward H. Hagen writes in The Handbook of Evolutionary Psychology that sociobiology is, despite the public controversy regarding the applications to humans, "one of the scientific triumphs of the twentieth century".
Therefore, these traits were probably "adaptive" in the environment in which the species evolved.
Thus, they are often interested in instinctive, or intuitive behavior, and in explaining the similarities, rather than the differences, between cultures.
This parental protection would increase in frequency in the population.
E.O. Wilson argued that evolution may also act upon groups.
If altruism is genetically determined, then altruistic individuals must reproduce their own altruistic genetic traits for altruism to survive, but when altruists lavish their resources on non-altruists at the expense of their own kind, the altruists tend to die out and the others tend to increase.
Within sociobiology, a social behavior is first explained as a sociobiological hypothesis by finding an evolutionarily stable strategy that matches the observed behavior.
Altruism between social insects and littermates has been explained in such a way.
In general, females with more bearing opportunities may value offspring less, and may also arrange bearing opportunities to maximize the food and protection from mates.
Studies of human behavior genetics have generally found behavioral traits such as creativity, extroversion, aggressiveness, and IQ have high heritability.
Thus, when FEV is genetically deleted from the mouse genome, male mice will instantly attack other males, whereas their wild-type counterparts take significantly longer to initiate violent behaviour.
During a 1976 meeting of the Sociobiology Study Group, as reported by Ullica Segerstråle, Chomsky argued for the importance of a sociobiologically informed notion of human nature.
Wilson has claimed that he had never meant to imply what ought to be, only what is the case.
Business is the activity of making one's living or making money by producing or buying and selling products (such as goods and services).
If the business acquires debts, the creditors can go after the owner's personal possessions.
The term is also often used colloquially (but not by lawyers or by public officials) to refer to a company.
A privately owned, for-profit corporation is owned by its shareholders, who elect a board of directors to direct the corporation and hire its managerial staff.
A cooperative differs from a corporation in that it has members, not shareholders, and they share decision-making authority.
Limited liability companies (LLC), limited liability partnerships, and other specific types of business organization protect their owners or shareholders from business failure by doing business under a separate legal entity with certain legal protections.
The members guarantee the payment of certain (usually nominal) amounts if the company goes into insolvent liquidation, but otherwise, they have no economic rights in relation to the company.
This type of company may no longer be formed in the UK, although provisions still exist in law for them to exist.
Note that "Ltd after the company's name signifies limited company, and PLC (public limited company) indicates that its shares are widely held."
In a company limited by guarantee, this will be the guarantors.
Private companies do not have publicly traded shares, and often contain restrictions on transfers of shares.
Entertainment companies and mass media agencies generate profits primarily from the sale of intellectual property.
They include tangible goods such as cars, buses, medical devices, glass, or aircraft.
Most stores and catalog companies are distributors or retailers.
They make their profits by selling goods and services that are sports related.
The modern field was established by the Italian mathematician Luca Pacioli in 1494.
Finance can also be defined as the science of money management.
Owners may manage their businesses themselves, or employ managers to do so for them.
Business process management (BPM) is a holistic management approach focused on aligning all aspects of an organization with the wants and needs of clients.
Many businesses are operated through a separate entity such as a corporation or a partnership (either formed with or without limited liability).
Generally speaking, shareholders in a corporation, limited partners in a limited partnership, and members in a limited liability company are shielded from personal liability for the debts and obligations of the entity, which is legally treated as a separate "person".
The terms of a partnership are partly governed by a partnership agreement if one is created, and partly by the law of the jurisdiction where the partnership is located.
In some tax systems, this can give rise to so-called double taxation, because first the corporation pays tax on the profit, and then when the corporation distributes its profits to its owners, individuals have to include dividends in their income when they complete their personal tax returns, at which point a second layer of income tax is imposed.
"Going public" through a process known as an initial public offering (IPO) means that part of the business will be owned by members of the public.
The Code of Hammurabi dates back to about 1772 BC for example and contains provisions that relate, among other matters, to shipping costs and dealings between merchants and brokers.
Local jurisdictions may also require special licenses and taxes just to operate a business.
Most countries with capital markets have at least one.
Other western nations have comparable regulatory bodies.
The proliferation and increasing complexity of the laws governing business have forced increasing specialization in corporate law.
Most businesses have names, logos, and similar branding techniques that could benefit from trademarking.
Economics is the social science that studies how people interact with value; in particular, the production, distribution, and consumption of goods and services.
He affirmed that previous economists have usually centred their studies on the analysis of wealth: how wealth is created (production), distributed, and consumed; and how wealth can grow.
If the war is not winnable or if the expected costs outweigh the benefits, the deciding actors (assuming they are rational) may never go to war (a decision) but rather explore other alternatives.
Economic precepts occur throughout the writings of the Boeotian poet Hesiod and several economic historians have described Hesiod himself as the "first economist".
Two groups, who later were called "mercantilists" and "physiocrats", more directly influenced the subsequent development of the subject.
It held that a nation's wealth depended on its accumulation of gold and silver.
Physiocrats, a group of 18th-century French thinkers and writers, developed the idea of the economy as a circular flow of income and output.
Physiocrats advocated replacing administratively costly tax collections with a single tax on income of land owners.
Smith discusses potential benefits of specialization by division of labour, including increased labour productivity and gains from trade, whether between town and country or across countries.
The force of a rapidly growing population against a limited amount of land meant diminishing returns to labour.
While Adam Smith emphasized the production of income, David Ricardo (1817) focused on the distribution of income among landowners, workers, and capitalists.
Ricardo was the first to state and prove the principle of comparative advantage, according to which each country should specialize in producing and exporting goods in that it has a lower relative cost of production, rather relying only on its own production.
Mill pointed to a distinct difference between the market's two roles: allocation of resources and distribution of income.
Smith wrote that the "real price of every thing ... is the toil and trouble of acquiring it".
Say's definition has prevailed up to our time, saved by substituting the word "wealth" for "goods and services" meaning that wealth may include non-material objects as well.
For Robbins, the insufficiency was solved, and his definition allows us to proclaim, with an easy conscience, education economics, safety and security economics, health economics, war economics, and of course, production, distribution and consumption economics as valid subjects of the economic science."
Although far from unanimous, most mainstream economists would accept some version of Robbins' definition, even though many have raised serious objections to the scope and method of economics, emanating from that definition.
The term "economics" was popularized by such neoclassical economists as Alfred Marshall as a concise synonym for "economic science" and a substitute for the earlier "political economy".
It dispensed with the labour theory of value inherited from classical economics in favour of a marginal utility theory of value on the demand side and a more general theory of costs on the supply side.
An immediate example of this is the consumer theory of individual demand, which isolates how prices (as costs) and income affect quantity demanded.
Modern mainstream economics builds on neoclassical economics but with many refinements that either supplement or generalize earlier analysis, such as econometrics, game theory, analysis of market failure and imperfect competition, and the neoclassical model of economic growth for analysing long-run variables affecting national income.
There exists an economic problem, subject to study by economic science, when a decision (choice) is made by one or more resource-controlling players to attain the best possible outcome under bounded rational conditions.
The book focused on determinants of national income in the short run when prices are relatively inflexible.
Keynesian economics has two successors.
It is generally associated with the University of Cambridge and the work of Joan Robinson.
Ben Bernanke, former Chairman of the Federal Reserve, is among the economists today generally accepting Friedman's analysis of the causes of the Great Depression.
When creating theories, the objective is to find ones which are at least as simple in information requirements, more precise in predictions, and more fruitful in generating additional research than prior theories.
Early macroeconomic models focused on modelling the relationships between aggregate variables, but as the relationships appeared to change over time macroeconomists, including new Keynesians, reformulated their models in microfoundations.
Sometimes an economic hypothesis is only qualitative, not quantitative.
However, the field of experimental economics is growing, and increasing use is being made of natural experiments.
By such means, a hypothesis may gain acceptance, although in a probabilistic, rather than certain, sense.
Criticisms based on professional standards and non-replicability of results serve as further checks against bias, errors, and over-generalization, although much economic research has been accused of being non-replicable, and prestigious journals have been accused of not facilitating replication through the provision of the code and data.
In applied economics, input–output models employing linear programming methods are quite common.
This has reduced the long-noted distinction of economics from natural sciences because it allows direct tests of what were previously taken as axioms.
Similar empirical testing occurs in neuroeconomics.
In perfectly competitive markets, no participants are large enough to have the market power to set the price of a homogeneous product.
Microeconomics studies individual markets by simplifying the economic system by assuming that activity in the market being analysed does not affect other markets.
General-equilibrium theory studies various markets and their behaviour.
Choices must be made between desirable yet mutually exclusive actions.
Part of the cost of making pretzels is that neither the flour nor the morning are available any longer, for use in some other way.
Inputs used in the production process include such primary factors of production as labour services, capital (durable produced goods used in production, such as an existing factory), and land (including natural resources).
Efficiency is improved if more output is generated without changing inputs, or in other words, the amount of "waste" is reduced.
In the simplest case an economy can produce just two goods (say "guns" and "butter").
Scarcity is represented in the figure by people being willing but unable in the aggregate to consume beyond the PPF (such as at X) and by the negative slope of the curve.
The slope of the curve at a point on it gives the trade-off between the two goods.
Along the PPF, scarcity implies that choosing more of one good in the aggregate entails doing with less of the other good.
A point inside the curve (as at A), is feasible but represents production inefficiency (wasteful use of inputs), in that output of one or both goods could increase by moving in a northeast direction to a point on the curve.
It has been observed that a high volume of trade occurs among regions even with access to a similar technology and mix of factor inputs, including high-income countries.
Among each of these production systems, there may be a corresponding division of labour with different work groups specializing, or correspondingly different types of capital equipment and differentiated land uses.
Theory and observation set out the conditions such that market prices of outputs and productive inputs select an allocation of factor inputs by comparative advantage, so that (relatively) low-cost inputs go to producing low-cost outputs.
In microeconomics, it applies to price and output determination for a market with perfect competition, which includes the condition of no buyers or sellers large enough to have price-setting power.
Demand theory describes individual consumers as rationally choosing the most preferred quantity of each good, given income, prices, tastes, etc.
The law of demand states that, in general, price and quantity demanded in a given market are inversely related.
In addition, purchasing power from the price decline increases ability to buy (the income effect).
Supply is the relation between the price of a good and the quantity available for sale at that price.
Supply is typically represented as a function relating price and quantity, if other factors are unchanged.
Just as on the demand side, the position of the supply can shift, say from a change in the price of a productive input or a technical improvement.
Market equilibrium occurs where quantity supplied equals quantity demanded, the intersection of the supply and demand curves in the figure above.
At a price above equilibrium, there is a surplus of quantity supplied compared to quantity demanded.
The most obvious kinds of firms are corporations, partnerships and trusts.
In perfectly competitive markets studied in the theory of supply and demand, there are many producers, none of which significantly influence price.
Common market structures studied besides perfect competition include monopolistic competition, various forms of oligopoly, and monopoly.
Given its different forms, there are various ways of representing uncertainty and modelling economic agents' responses to it.
In behavioural economics, it has been used to model the strategies agents choose when interacting with others whose interests are at least partially adverse to their own.
It has significant applications seemingly outside of economics in such diverse subjects as formulation of nuclear strategies, ethics, political science, and evolutionary biology.
It also analyses the pricing of financial instruments, the financial structure of companies, the efficiency and fragility of financial markets, financial crises, and related government policy or regulation.
Customers without knowledge of whether a car is a "lemon" depress its price below what a quality second-hand car would be.
Both problems may raise insurance costs and reduce efficiency by driving otherwise willing transactors from the market ("incomplete markets").
Information asymmetries and incomplete markets may result in economic inefficiency but also a possibility of improving efficiency through market, legal, and regulatory remedies, as discussed above.
Public goods are goods which are under-supplied in a typical market.
For example, air pollution may generate a negative externality, and education may generate a positive externality (less crime, etc.).
In many areas, some form of price stickiness is postulated to account for quantities, rather than prices, adjusting in the short run to changes on the demand side or the supply side.
Examples of such price stickiness in particular markets include wage rates in labour markets and posted prices in markets deviating from perfect competition.
Such aggregates include national income and output, the unemployment rate, and price inflation and subaggregates like total consumption and investment spending and their components.
This has addressed a long-standing concern about inconsistent developments of the same subject.
Keynes contended that aggregate demand for goods might be insufficient during economic downturns, leading to unnecessarily high unemployment and losses of potential output.
New classical macroeconomics, as distinct from the Keynesian view of the business cycle, posits market clearing with imperfect information.
The labour force only includes workers actively looking for jobs.
Classical models of unemployment occurs when wages are too high for employers to be willing to hire more workers.
Large amounts of structural unemployment can occur when an economy is transitioning industries and workers find their previous set of skills are no longer in demand.
Money has general acceptability, relative consistency in value, divisibility, durability, portability, elasticity in supply, and longevity with mass public confidence.
In the words of Francis Amasa Walker, a well-known 19th-century economist, "Money is what money does" ("Money is that money does" in the original).
Its economic function can be contrasted with barter (non-monetary exchange).
When aggregate demand falls below the potential output of the economy, there is an output gap where some productive capacity is left unemployed.
For example, unemployed home builders can be hired to expand highways.
The effects of fiscal policy can be limited by crowding out.
Some economists think that crowding out is always an issue while others do not think it is a major issue when output is depressed.
The latter, an aspect of public choice theory, models public-sector behaviour analogously to microeconomics, involving interactions of self-interested voters, politicians, and bureaucrats.
It also concerns the size and distribution of gains from trade.
It is often stated that Carlyle gave economics the nickname "the dismal science" as a response to the late 18th century writings of The Reverend Thomas Robert Malthus, who grimly predicted that starvation would result, as projected population growth exceeded the rate of increase in the food supply.
The close relation of economic theory and practice with politics is a focus of contention that may shade or distort the most unpretentious original tenets of economics, and is often confused with specific social agendas and value systems.
Some academic economic journals have increased their efforts to gauge the consensus of economists regarding certain policy issues in hopes of effecting a more informed political environment.
Issues like central bank independence, central bank policies and rhetoric in central bank governors discourse or the premises of macroeconomic policies (monetary and fiscal policy) of the state, are focus of contention and criticism.
The field of information economics includes both mathematical-economical research and also behavioural economics, akin to studies in behavioural psychology, and confounding factors to the neoclassical assumptions are the subject of substantial study in many areas of economics.
Joskow had a strong feeling that the important work in oligopoly was done through informal observations while formal models were "trotted out ex post".
Another major theme is evolution, which explains the unity and diversity of life.
His works such as History of Animals were especially important because they revealed his naturalist leanings, and later more empirical works that focused on biological causation and the diversity of life.
Medicine was especially well studied by Islamic scholars working in Greek philosopher traditions, while natural history drew heavily on Aristotelian thought, especially in upholding a fixed hierarchy of life.
Investigations by Jan Swammerdam led to new interest in entomology and helped to develop the basic techniques of microscopic dissection and staining.
Then, in 1838, Schleiden and Schwann began promoting the now universal ideas that (1) the basic unit of organisms is the cell and (2) that individual cells have all the characteristics of life, although they opposed the idea that (3) all cells come from the division of other cells.
Carl Linnaeus published a basic taxonomy for the natural world in 1735 (variations of which have been in use ever since), and in the 1750s introduced scientific names for all his species.
Lamarck believed that these acquired traits could then be passed on to the animal's offspring, who would further develop and perfect them.
The basis for modern genetics began with the work of Gregor Mendel, who presented his paper, "Versuche über Pflanzenhybriden" ("Experiments on Plant Hybridization"), in 1865, which outlined the principles of biological inheritance, serving as the basis for modern genetics.
A focus on new kinds of model organisms such as viruses and bacteria, along with the discovery of the double-helical structure of DNA by James Watson and Francis Crick in 1953, marked the transition to the era of molecular genetics.
Finally, the Human Genome Project was launched in 1990 with the goal of mapping the general human genome.
Life on Earth began from water and remained there for about three billions years prior to migrating onto land.
The nucleus is made of one or more protons and a number of neutrons.
The atom of each specific element contains a unique number of protons, which is known as its atomic number, and the sum of its protons and neutrons is an atom's mass number.
Carbon, for example, can exist as a stable isotope (carbon-12 or carbon-13) or as a radioactive isotope (carbon-14), the latter of which can be used in radiometric dating (specifically radiocarbon dating) to determine the age of organic materials.
Ionic bonding involves the electrostatic attraction between oppositely charged ions, or between two atoms with sharply different electronegativities, and is the primary interaction occurring in ionic compounds.
Unlike ionic bonds, a covalent bond involves the sharing of electron pairs between atoms.
A ubiquitous example of a hydrogen bond is found between water molecules.
Water is important to life because it is an effective solvent, capable of dissolving solutes such as sodium and chloride ions or other small molecules to form an aqueous solution.
Because the O–H bonds are polar, the oxygen atom has a slight negative charge and the two hydrogen atoms have a slight positive charge.
Water is also adhesive as it is able to adhere to the surface of any polar or charged non-water molecules.
The lower density of ice compared to liquid water is due to the lower number of water molecules that form the crystal lattice structure of ice, which leaves a large amount of space between water molecules.
Thus, a large amount of energy is needed to break the hydrogen bonds between water molecules to convert liquid water into gas (or water vapor).
With the exception of water, nearly all the molecules that make up each organism contain carbon.
For example, a single carbon atom can form four single covalent bonds such as in methane, two double covalent bonds such as in carbon dioxide, or a triple covalent bond such as in carbon monoxide (CO).
A hydrocarbon backbone can be substituted by other elements such as oxygen (O), hydrogen (H), phosphorus (P), and sulfur (S), which can change the chemical behavior of that compound.
When two monosaccharides such as glucose and fructose are linked together, they can form a disaccharide such as sucrose.
These lipids are organic compounds that are largely nonpolar and hydrophobic.
The glycerol and phosphate group together constitute the polar and hydrophilic (or head) region of the molecule whereas the fatty acids make up the nonpolar and hydrophobic (or tail) region.
Proteins are the most diverse of the macromolecules, which include enzymes, transport proteins, large signaling molecules, antibodies, and structural proteins.
The polarity and charge of the side chains affect the solubility of amino acids.
The primary structure consists of a unique sequence of amino acids that are covalently linked together by peptide bonds.
The folding of alpha helices and beta sheets gives a protein its three-dimensional or tertiary structure.
The purines include guanine (G) and adenine (A) whereas the pyrimidines consist of cytosine (T), uracil (U), and thymine (T).
A cell membrane consists of a lipid bilayer, including cholesterols that sit between phospholipids to maintain their fluidity at various temperatures.
Cell membranes are involved in various cellular processes such as cell adhesion, storing electrical energy, and cell signalling and serve as the attachment surface for several extracellular structures such as a cell wall, glycocalyx, and cytoskeleton.
The Alberts text discusses how the "cellular building blocks" move to shape developing embryos.
Plant cells have additional organelles that distinguish them from animal cells such as a cell wall that provides support for the plant cell, chloroplasts that harvest sunlight energy to produce sugar, and vacuoles that provide storage and structural support as well as being involved in reproduction and breakdown of plant seeds.
According to the first law of thermodynamics, energy is conserved, i.e., cannot be created or destroyed.
As a result, an organism requires continuous input of energy to maintain a low state of entropy.
Usually, catabolism releases energy, and anabolism consumes energy.
The overall reaction occurs in a series of biochemical steps, some of which are redox reactions.
Acetyl-Coa enters the citric acid cycle, which takes places inside the mitochondrial matrix.
Oxidative phosphorylation comprises the electron transport chain, which is a series of four protein complexes that transfer electrons from one complex to another, thereby releasing energy from NADH and FADH2 that is coupled to the pumping of protons (hydrogen ions) across the inner mitochondrial membrane (chemiosmosis), which generates a proton motive force.
If oxygen were not present, pyruvate would not be metabolized by cellular respiration but undergoes a process of fermentation.
Fermentation oxidizes NADH to NAD+ so it can be re-used in glycolysis.
In skeletal muscles, the waste product is lactic acid.
During anaerobic glycolysis, NAD+ regenerates when pairs of hydrogen combine with pyruvate to form lactate.
During recovery, when oxygen becomes available, NAD+ attaches to hydrogen from lactate to form ATP.
In most cases, oxygen is also released as a waste product.
This is analogous to the proton-motive force generated across the inner mitochondrial membrane in aerobic respiration.
In autocrine signaling, the ligand affects the same cell that releases it.
In eukaryotes (i.e., animal, plant, fungal, and protist cells), there are two distinct types of cell division: mitosis and meiosis.
After cell division, each of the daughter cells begin the interphase of a new cycle.
Both of these cell division cycles are used in the process of sexual reproduction at some point in their life cycle.
Unlike the processes of mitosis and meiosis in eukaryotes, binary fission takes in prokaryotes takes place without the formation of a spindle apparatus on the cell.
Mendelian inheritance, specifically, is the process by which genes and traits are passed on from parents to offspring.
The first is that genetic characteristics, which are now called alleles, are discrete and have alternate forms (e.g., purple vs. white or tall vs. dwarf), each inherited from one of two parents.
Mendel noted that during gamete formation, the alleles for each gene segregate from each other so that each gamete carries only one allele for each gene, which is stated by his law of segregation.
The nucleotides are joined to one another in a chain by covalent bonds between the sugar of one nucleotide and the phosphate of the next, resulting in an alternating sugar-phosphate backbone.
The bases are divided into two groups: pyrimidines and purines.
DNA is replicated once the two strands separate.
A chromosome is an organized structure consisting of DNA and histones.
In prokaryotes, the DNA is held within an irregularly shaped body in the cytoplasm called the nucleoid.
The genetic information stored in DNA represents the genotype, whereas the phenotype results from the synthesis of proteins that control an organism's structure and development, or that act as enzymes catalyzing specific metabolic pathways.
Under the genetic code, these mRNA strands specify the sequence of amino acids within proteins in a process called translation, which occurs in ribosomes.
Sequencing and analysis of genomes can be done using high throughput DNA sequencing and bioinformatics to assemble and analyze the function and structure of entire genomes.
The genomes of prokaryotes are small, compact, and diverse.
There are four key processes that underlie development: Determination, differentiation, morphogenesis, and growth.
Stem cells are undifferentiated or partially differentiated cells that can differentiate into various types of cells and proliferate indefinitely to produce more of the same stem cell.
Apoptosis, or programmed cell death, also occurs during morphogenesis, such as the death of cells between digits in human embryonic development, which frees up individual fingers and toes.
These toolkit genes are highly conserved among phyla, meaning that they are ancient and very similar in widely separated groups of animals.
Hox genes determine where repeating parts, such as the many vertebrae of snakes, will grow in a developing embryo or larva.
A toolkit gene can be expressed in a different pattern, as when the beak of Darwin's large ground-finch was enlarged by the BMP gene, or when snakes lost their legs as Distal-less (Dlx) genes became under-expressed or not expressed at all in the places where other reptiles continued to form their limbs.
This perspective holds that evolution occurs when there are changes in the allele frequencies within a population of interbreeding organisms.
When selective forces are absent or relatively weak, allele frequencies are equally likely to drift upward or downward at each successive generation because the alleles are subject to sampling error.
Reproductive isolation also tends to increase with genetic divergence.
When a lineage divides into two, it is represented as a node (or split) on the phylogenetic tree.
Within a tree, any group of species designated by a name is a taxon (e.g., humans, primates, mammals, or vertebrates) and a taxon that consists of all its evolutionary descendants is a clade, otherwise known as a monophyletic taxon.
A species or group that is closely related to the ingroup but is phylogenetically outside of it is called the outgroup, which serves a reference point in the tree.
Based on the principle of Parsimony (or Occam's razor), the tree that is favored is the one with the fewest evolutionary changes needed to be assumed over all traits in all groups.
Based on this system, each species is given two names, one for its genus and another for its species.
Biologists regard the ubiquity of the genetic code as evidence of universal common descent for all bacteria, archaea, and eukaryotes.
Later, around 1.7 billion years ago, multicellular organisms began to appear, with differentiated cells performing specialised functions.
Land plants were so successful that they are thought to have contributed to the Late Devonian extinction event.
During the recovery from this catastrophe, archosaurs became the most abundant land vertebrates; one archosaur group, the dinosaurs, dominated the Jurassic and Cretaceous periods.
Bacteria inhabit soil, water, acidic hot springs, radioactive waste, and the deep biosphere of the earth's crust.
Archaea constitute the other domain of prokaryotic cells and were initially classified as bacteria, receiving the name archaebacteria (in the Archaebacteria kingdom), a term that has fallen out of use.
Archaea and bacteria are generally similar in size and shape, although a few archaea have very different shapes, such as the flat and square cells of Haloquadratum walsbyi.
Archaea use more energy sources than eukaryotes: these range from organic compounds, such as sugars, to ammonia, metal ions or even hydrogen gas.
The first observed archaea were extremophiles, living in extreme environments, such as hot springs and salt lakes with no other organisms.
Archaea are a major part of Earth's life.
Five of these clades are also collectively known as protists, which are mostly microscopic eukaryotic organisms that are not plants, fungi, or animals.
Most protists are unicellular, which are also known as microbial eukaryotes.
Dinoflagellates are photosynthetic and can be found in the ocean where they play a role as primary producers of organic matter.
Ciliates are alveolates that possess numerous hair-like structure called cilia.
The excavates are groups of protists that began to diversify approximately 1.5 billion years ago shortly after the origin of the eukaryotes.
Stramenopiles, most of which can be characterized by the presence of tubular hairs on the longer of their two flagella, include diatoms and brown algae.
The rhizarians comprise three main groups: cercozoans, foraminiferans, and radiolarians.
Algae comprise several distinct clades such as glaucophytes, which are microscopic freshwater algae that may have resembled in form to the early unicellular ancestor of Plantae.
Land plants (embryophytes) first appeared in terrestrial environments approximately 450 to 500 million years ago.
In contrast, the other three clades are nonvascular plants as they do not have tracheids.
They tend to be found in areas where water is readily available.
Most nonvascular plants are terrestrial, with a few living in freshwater environments and none living in the oceans.
Gymnosperms includes conifers, cycads, Ginkgo, and gnetophytes.
They do so through a process called absorptive heterotrophy whereby they would first secrete digestive enzymes that break down large food molecules before absorbing them through their cell membranes.
Fungi, along with two other lineages, choanoflagellates and animals, can be grouped as opisthokonts.
Multicellular fungi, on the other hand, have a body called mycelium, which is composed of a mass of individual tubular filaments called hyphae that allows for nutrient absorption to occur.
With few exceptions, animals consume organic material, breathe oxygen, are able to move, can reproduce sexually, and grow from a hollow sphere of cells, the blastula, during embryonic development.
Animals can be distinguished into two groups based on their developmental characteristics.
In protostomes, the blastopore gives rise to the mouth, which is then followed by the formation of the anus.
The bodies of most animals are symmetrical, with symmetry being either radial or bilateral.
Finally, animals can be distinguished based on the type and location of their appendages such as antennae for sensing the environment or claws for capturing prey.
The majority (~97%) of animal species are invertebrates, which are animals that neither possess nor develop a vertebral column (commonly known as a backbone or spine), derived from the notochord.
Many invertebrate taxa have a greater number and variety of species than the entire subphylum of Vertebrata.
More than 6,000 virus species have been described in detail.
When not inside an infected cell or in the process of infecting a cell, viruses exist in the form of independent particles, or virions, consisting of the genetic material (DNA or RNA), a protein coat called capsid, and in some cases an outside envelope of lipids.
The origins of viruses in the evolutionary history of life are unclear: some may have evolved from plasmids—pieces of DNA that can move between cells—while others may have evolved from bacteria.
Viruses can spread in many ways.
Norovirus and rotavirus, common causes of viral gastroenteritis, are transmitted by the faecal–oral route, passed by hand-to-mouth contact or in food or water.
The shoot system is composed of stem, leaves, and flowers.
The direction of water movement across a semipermeable membrane is determined by the water potential across that membrane.
Most plant seeds are usually dormant, a condition in which the seed's normal activity is suspended.
Imbibition is the first step in germination, whereby water is absorbed by the seed.
These monomers are obtained from the hydrolysis of starch, proteins, and lipids that are stored in either the cotyledons or endosperm.
Their flowers are organs that facilitate reproduction, usually by providing a mechanism for the union of sperm with eggs.
Cross-pollination is the transfer of pollen from the anther of one flower to the stigma of another flower on a different individual of the same species.
These changes may be affected by genetic, chemical, and physical factors.
The photoreceptor proteins relay information such as whether it is day or night, duration of the day, intensity of light available, and the source of light.
Many flowering plants bloom at the appropriate time because of light-sensitive compounds that respond to the length of the night, a phenomenon known as photoperiodism.
Animals can be classified as either regulators or conformers.
In contrast, animals such as fishes and frogs are conformers as they adapt their internal environment (e.g., body temperature) to match their external environments.
Mice, for example, are able to consume three times more food than rabbits in proportion to their weights as the basal metabolic rate per unit weight in mice is greater than in rabbits.
However, the relationship is non-linear in animals that swim or fly.
At low flight speeds, a bird must maintain a high metabolic rates to remain airborne.
Finally, freshwater animals have body fluids that are hyperosmotic to fresh water.
If an animal were to consume food that contains an excess amount of chemical energy, it will store most of that energy in the form of lipids for future use and some of that energy as glycogen for more immediate use (e.g., meeting the brain's energy needs).
In addition to their digestive tracts, vertebrate animals have accessory glands such as a liver and pancreas as part of their digestive systems.
Upon leaving the stomach, food enters into the midgut, which is the first part of the intestine (or small intestine in mammals) and is the principal site of digestion and absorption.
Gas exchange in the lungs occurs in millions of small air sacs; in mammals and reptiles these are called alveoli, and in birds they are known as atria.
These enter the lungs where they branch into progressively narrower secondary and tertiary bronchi that branch into numerous smaller tubes, the bronchioles.
There are two types of circulatory systems: open and closed.
Circulation in animals occur between two types of tissues: systemic tissues and breathing (or pulmonary) organs.
In birds and mammals, the systemic and pulmonary systems are connected in series.
Skeletal muscle contractions are neurogenic as they require synaptic input from motor neurons.
The contraction produced can be described as a twitch, summation, or tetanus, depending on the frequency of action potentials.
The mechanisms of contraction are similar in all three muscle tissues.
Other animals such as mollusks, and nematodes, possess obliquely striated muscles, which contain bands of thick and thin filaments that are arranged helically rather than transversely, like in vertebrate skeletal or cardiac muscles.
They can transmit or receive information at sites of contacts called synapses.
Cells such as neurons or muscle cells may be excited or inhibited upon receiving a signal from another neuron.
In vertebrates, the nervous system consists of the central nervous system (CNS), which includes the brain and spinal cord, and the peripheral nervous system (PNS), which consists of nerves that connect the CNS to every other part of the body.
The PNS is divided into three separate subsystems, the somatic, autonomic, and enteric nervous systems.
The sympathetic nervous system is activated in cases of emergencies to mobilize energy, while the parasympathetic nervous system is activated when organisms are in a relaxed state.
Nerves that exit directly from the brain are called cranial nerves while those exiting from the spinal cord are called spinal nerves.
In humans specifically, the major endocrine glands are the thyroid gland and the adrenal glands.
Hormones can be amino acid complexes, steroids, eicosanoids, leukotrienes, or prostaglandins.
They produce haploid gametes by meiosis.
In most cases, a third germ layer, the mesoderm, also develops between them.
Gastrulation occurs, whereby morphogenetic movements convert the cell mass into a three germ layers that comprise the ectoderm, mesoderm and endoderm.
Cellular differentiation is influenced by extracellular signals such as growth factors that are exchanged to adjacent cells, which is called juxtracrine signaling, or to neighboring cells over short distances, which is called paracrine signaling.
The adaptive immune system provides a tailored response to each stimulus by learning to recognize molecules it has previously encountered.
Bacteria have a rudimentary immune system in the form of enzymes that protect against virus infections.
Jawed vertebrates, including humans, have even more sophisticated defense mechanisms, including the ability to adapt to recognize pathogens more efficiently.
Fixed action patterns, for instance, are genetically determined and stereotyped behaviors that occur without learning.
The community of living (biotic) organisms in conjunction with the nonliving (abiotic) components (e.g., water, light, radiation, temperature, humidity, atmosphere, acidity, and soil) of their environment is called an ecosystem.
By feeding on plants and on one another, animals play an important role in the movement of matter and energy through the system.
The Earth's physical environment is shaped by solar energy and topography.
Weather is the day-to-day temperature and precipitation activity, whereas climate is the long-term average of weather, typically averaged over a period of 30 years.
As a result, wet environments allow for lush vegetation to grow.
Population growth during short-term intervals can be determined using the population growth rate equation, which takes into consideration birth, death, and immigration rates.
A biological interaction is the effect that a pair of organisms living together in a community have on each other.
A long-term interaction is called a symbiosis.
There are different trophic levels within any food web, with the lowest level being the primary producers (or autotrophs) such as plants and algae that convert energy and inorganic material into organic compounds, which can then be used by the rest of the community.
And those that eat secondary consumers are tertiary consumers and so on.
In some cycles there are reservoirs where a substance remains or is sequestered for a long period of time.
The largest driver of warming is the emission of greenhouse gases, of which more than 90% are carbon dioxide and methane.
Biodiversity affects the functioning of ecosystems, which provide a variety of services upon which people depend.
Traditionally, botany has also included the study of fungi and algae by mycologists and phycologists respectively, with the study of these three groups of organisms remaining within the sphere of interest of the International Botanical Congress.
Medieval physic gardens, often attached to monasteries, contained plants of medical importance.
These gardens facilitated the academic study of plants.
In the last two decades of the 20th century, botanists exploited the techniques of molecular genetic analysis, including genomics and proteomics and DNA sequences to classify plants more accurately.
Modern botany traces its roots back to Ancient Greece specifically to Theophrastus (c. 371–287 BCE), a student of Aristotle who invented and described many of its principles and is widely regarded in the scientific community as the "Father of Botany".
De Materia Medica was widely read for more than 1,500 years.
In the mid-16th century, botanical gardens were founded in a number of Italian universities.
They supported the growth of botany as an academic subject.
Throughout this period, botany remained firmly subordinate to medicine.
Bock created his own system of plant classification.
The choice and sequence of the characters may be artificial in keys designed purely for identification (diagnostic keys) or more closely related to the natural or phyletic order of the taxa in synoptic keys.
This established a standardised binomial or two-part naming scheme where the first name represented the genus and the second identified the species within the genus.
Increasing knowledge of plant anatomy, morphology and life cycles led to the realisation that there were more natural affinities between plants than the artificial sexual system of Linnaeus.
The work of Katherine Esau (1898–1997) on plant anatomy is still a major foundation of modern botany.
The concept that the composition of plant communities such as temperate broadleaf forest changes by a process of ecological succession was developed by Henry Chandler Cowles, Arthur Tansley and Frederic Clements.
The discovery and identification of the auxin plant hormones by Kenneth V. Thimann in 1948 enabled regulation of plant growth by externally applied chemicals.
20th century developments in plant biochemistry have been driven by modern techniques of organic chemical analysis, such as spectroscopy, chromatography and electrophoresis.
These technologies enable the biotechnological use of whole plants or plant cell cultures grown in bioreactors to synthesise pesticides, antibiotics or other pharmaceuticals, as well as the practical application of genetically modified crops designed for traits such as improved yield.
Modern systematics aims to reflect and discover phylogenetic relationships between plants.
As a by-product of photosynthesis, plants release oxygen into the atmosphere, a gas that is required by nearly all living things to carry out cellular respiration.
Historically, all living things were classified as either animals or plants and botany covered the study of all organisms not considered animals.
The strictest definition of "plant" includes only the "land plants" or embryophytes, which include seed plants (gymnosperms, including the pines, and flowering plants) and the free-sporing cryptogams including ferns, clubmosses, liverworts, hornworts and mosses.
The sexual haploid phase of embryophytes, known as the gametophyte, nurtures the developing diploid embryo sporophyte within its tissues for at least part of its life, even in the seed plants, where the gametophyte itself is nurtured by its parent sporophyte.
Palaeobotanists study ancient plants in the fossil record to provide information about the evolutionary history of plants.
This is what ecologists call the first trophic level.
Botanists also study weeds, which are a considerable problem in agriculture, and the biology and control of plant pathogens in agriculture and natural ecosystems.
The light energy captured by chlorophyll a is initially in the form of electrons (and later a proton gradient) that's used to make molecules of ATP and NADPH which temporarily store and transport energy.
Some of the glucose is converted to starch which is stored in the chloroplast.
Unlike in animals (which lack chloroplasts), plants and their eukaryote relatives have delegated many biochemical roles to their chloroplasts, including synthesising all their fatty acids, and most amino acids.
Vascular land plants make lignin, a polymer used to strengthen the secondary cell walls of xylem tracheids and vessels to keep them from collapsing when a plant sucks water through them under water stress.
Others, such as the essential oils peppermint oil and lemon oil are useful for their aroma, as flavourings and spices (e.g., capsaicin), and in medicine as pharmaceuticals as in opium from opium poppies.
For example, the pain killer aspirin is the acetyl ester of salicylic acid, originally isolated from the bark of willow trees, and a wide range of opiate painkillers like heroin are obtained by chemical modification of morphine obtained from the opium poppy.
Native Americans have used various plants as ways of treating illness or disease for thousands of years.
Sugar, starch, cotton, linen, hemp, some types of rope, wood and particle boards, papyrus and paper, vegetable oils, wax, and natural rubber are examples of commercially important materials made from plant tissues or their secondary products.
Products made from cellulose include rayon and cellophane, wallpaper paste, biobutanol and gun cotton.
Some ecologists even rely on empirical data from indigenous people that is gathered by ethnobotanists.
Plants depend on certain edaphic (soil) and climatic factors in their environment but can modify these factors too.
They interact with their neighbours at a variety of spatial scales in groups, populations and communities that collectively constitute vegetation.
Gregor Mendel discovered the genetic laws of inheritance by studying inherited traits such as shape in Pisum sativum (peas).
Nevertheless, there are some distinctive genetic differences between plants and other organisms.
The many cultivated varieties of wheat are the result of multiple inter- and intra-specific crosses between wild species and their hybrids.
In many land plants the male and female gametes are produced by separate individuals.
The formation of stem tubers in potato is one example.
Apomixis can also happen in a seed, producing a seed that contains an embryo genetically identical to the parent.
An allopolyploid plant may result from a hybridisation event between two different species.
Some otherwise sterile plant polyploids can still reproduce vegetatively or by seed apomixis, forming clonal populations of identical individuals.
Common dandelion is a triploid that produces viable seeds by apomictic seed.
The sequencing of some other relatively small genomes, of rice (Oryza sativa) and Brachypodium distachyon, has made them important model species for understanding the genetics, cellular and molecular biology of cereals, grasses and monocots generally.
Spinach, peas, soybeans and a moss Physcomitrella patens are commonly used to study plant cell biology.
Gene expression can also be controlled by repressor proteins that attach to silencer regions of the DNA and prevent that region of the DNA code from being expressed.
Some epigenetic changes have been shown to be heritable, while others are reset in the germ cells.
Unlike animals, many plant cells, particularly those of the parenchyma, do not terminally differentiate, remaining totipotent with the ability to give rise to a new individual plant.
The algae are a polyphyletic group and are placed in various divisions, some more closely related to plants than others.
The Charophyte class Charophyceae and the land plant sub-kingdom Embryophyta together form the monophyletic group or clade Streptophytina.
Pteridophytic vascular plants with true xylem and phloem that reproduced by spores germinating into free-living gametophytes evolved during the Silurian period and diversified into several lineages during the late Silurian and early Devonian.
Their reduced gametophytes developed from megaspores retained within the spore-producing organs (megasporangia) of the sporophyte, a condition known as endospory.
The earliest known seed plants date from the latest Devonian Famennian stage.
Chemicals obtained from the air, soil and water form the basis of all plant metabolism.
Heterotrophs including all animals, all fungi, all completely parasitic plants, and non-photosynthetic bacteria take in organic molecules produced by photoautotrophs and respire them or use them in the construction of cells and tissues.
Subcellular transport of ions, electrons and molecules such as water and enzymes occurs across cell membranes.
Examples of elements that plants need to transport are nitrogen, phosphorus, potassium, calcium, magnesium, and sulfur.
This compound mediates the tropic responses of shoots and roots towards light and gravity.
The natural cytokinin zeatin was discovered in corn, Zea mays, and is a derivative of the purine adenine.
They are involved in the promotion of germination and dormancy-breaking in seeds, in regulation of plant height by controlling stem elongation and the control of flowering.
It was so named because it was originally thought to control abscission.
Another class of phytohormones is the jasmonates, first isolated from the oil of Jasminum grandiflorum which regulates wound responses in plants by unblocking the expression of genes required in the systemic acquired resistance response to pathogen attack.
Non-vascular plants, the liverworts, hornworts and mosses do not produce ground-penetrating vascular roots and most of the plant participates in photosynthesis.
Cells in each system are capable of creating cells of the other and producing adventitious shoots or roots.
In the event that one of the systems is lost, the other can often regrow it.
In vascular plants, the xylem and phloem are the conductive tissues that transport resources between shoots and roots.
Leaves gather sunlight and carry out photosynthesis.
Angiosperms are seed-producing plants that produce flowers and have enclosed seeds.
Some plants reproduce sexually, some asexually, and some via both means.
Biological classification is a form of scientific taxonomy.
While scientists do not always agree on how to classify organisms, molecular phylogenetics, which uses DNA sequences as data, has driven many recent revisions along evolutionary lines and is likely to continue to do so.
The nomenclature of botanical organisms is codified in the International Code of Nomenclature for algae, fungi, and plants (ICN) and administered by the International Botanical Congress.
The scientific name of a plant represents its genus and its species within the genus, resulting in a single worldwide name for each organism.
The combination is the name of the species.
The evolutionary relationships and heredity of a group of organisms is called its phylogeny.
As an example, species of Pereskia are trees or bushes with prominent leaves.
Judging relationships based on shared characters requires care, since plants may resemble one another through convergent evolution in which characters have arisen independently.
Only derived characters, such as the spine-producing areoles of cacti, provide evidence for descent from a common ancestor.
The difference is that the genetic code itself is used to decide evolutionary relationships, instead of being used indirectly via the characters it gives rise to.
Genetic evidence suggests that the true evolutionary relationship of multicelled organisms is as shown in the cladogram below – fungi are more closely related to animals than to plants.
Investigating how plant species are related to each other allows botanists to better understand the process of evolution in plants.
Although humans have always been interested in the natural history of the animals they saw around them, and made use of this knowledge to domesticate certain species, the formal study of zoology can be said to have originated with Aristotle.
Modern zoology has its origins during the Renaissance and early modern period, with Carl Linnaeus, Antonie van Leeuwenhoek, Robert Hooke, Charles Darwin, Gregor Mendel and many others.
There are cave paintings, engravings and sculptures in France dating back 15,000 years showing bison, horses and deer in carefully rendered detail.
Ancient knowledge of wildlife is illustrated by the realistic depictions of wild and domestic animals in the Near East, Mesopotamia and Egypt, including husbandry practices and techniques, hunting and fishing.
Aristotle, in the fourth century BC, looked at animals as living organisms, studying their structure, development and vital phenomena.
Four hundred years later, Roman physician Galen dissected animals to study their anatomy and the function of the different parts, because the dissection of human cadavers was prohibited at the time.
In Europe, Galen's work on anatomy remained largely unsurpassed and unchallenged up until the 16th century.
Having previously been the realm of gentlemen naturalists, over the 18th, 19th and 20th centuries, zoology became an increasingly professional scientific discipline.
These developments, as well as the results from embryology and paleontology, were synthesized in the 1859 publication of Charles Darwin's theory of evolution by natural selection; in this Darwin placed the theory of organic evolution on a new footing, by explaining the processes by which it can occur, and providing observational evidence that it had done so.
Darwin gave a new direction to morphology and physiology, by uniting them in a common biological theory: the theory of organic evolution.
An early necessity was to identify the organisms and group them according to their characteristics, differences and relationships, and this is the field of the taxonomist.
His ideas were centered on the morphology of animals.
These groupings have since been revised to improve consistency with the Darwinian principle of common descent.
Homo is the genus, and sapiens the specific epithet, both of them combined make up the species name.
The dominant classification system is called the Linnaean taxonomy.
Understanding the structure and function of cells is fundamental to all of the biological sciences.
It focuses on how organs and organ systems work together in the bodies of humans and animals, in addition to how they work independently.
Physiological studies have traditionally been divided into plant physiology and animal physiology, but some principles of physiology are universal, no matter what particular organism is being studied.
For example, it generally involves scientists who have special training in particular organisms such as mammalogy, ornithology, herpetology, or entomology, but use those organisms as systems to answer general questions about evolution.
Ethologists have been particularly concerned with the evolution of behavior and the understanding of behavior in terms of the theory of natural selection.
While researchers practice techniques specific to molecular biology, it is common to combine these with methods from genetics and biochemistry.
Biological systematics is the study of the diversification of living forms, both past and present, and the relationships among living things through time.
Phylogenetic trees of species and higher taxa are used to study the evolution of traits (e.g., anatomical or molecular characteristics) and the distribution of organisms (biogeography).
Biological systematics classifies species by using three specific branches.
Experimental systematics identifies and classifies animals based on the evolutionary units that comprise a species, as well as their importance in evolution itself.
Explaining the biodiversity of the planet and its organisms.
Taxonomy is that part of Systematics concerned with topics (a) to (d) above.
However, in modern usage, they can all be considered synonyms of each other.
Some claim systematics alone deals specifically with relationships through time, and that it can be synonymous with phylogenetics, broadly dealing with the inferred hierarchy of organisms.
Scientific classifications are aids in recording and reporting information to other scientists and to laymen.
In biology, a species is the basic unit of classification and a taxonomic rank of an organism, as well as a unit of biodiversity.
In addition, paleontologists use the concept of the chronospecies since fossil reproduction cannot be examined.
All species (except viruses) are given a two-part name, a "binomial".
For example, Boa constrictor is one of four species of the genus Boa, with constrictor being the species's epithet.
Also, among organisms that reproduce only asexually, the concept of a reproductive species breaks down, and each clone is potentially a microspecies.
Species were seen from the time of Aristotle until the 18th century as fixed categories that could be arranged in a hierarchy, the great chain of being.
That understanding was greatly extended in the 20th century through genetics and population ecology.
Ernst Mayr emphasised reproductive isolation, but this, like other species concepts, is hard or even impossible to test.
This method was used as a "classical" method of determining species, such as with Linnaeus early in evolutionary theory.
As a rule of thumb, microbiologists have assumed that kinds of Bacteria or Archaea with 16S ribosomal RNA gene sequences more similar than 97% to each other need to be checked by DNA-DNA hybridisation to decide if they belong to the same species or not.
Modern approaches compare sequence similarity using computational methods.
A database, Barcode of Life Data Systems (BOLD), contains DNA barcode sequences from over 190,000 species.
For example, in a study done on fungi, studying the nucleotide characters using cladistic species produced the most accurate results in recognising the numerous fungi species of all the concepts studied.
Yet others defend this approach, considering "taxonomic inflation" pejorative and labelling the opposing view as "taxonomic conservatism"; claiming it is politically expedient to split species and recognise smaller populations at the species level, because this means they can more easily be included as endangered in the IUCN red list and can attract conservation legislation and funding.
If scientists mean that something applies to all species within a genus, they use the genus name without the specific name or epithet.
As further information comes to hand, the hypothesis may be corroborated or refuted.
Dividing a taxon into multiple, often new, taxa is called splitting.
The term quasispecies is sometimes used for rapidly mutating entities like viruses.
In ring species, when members of adjacent populations in a widely continuous distribution range interbreed successfully but members of more distant populations do not.
Ring species thus present a difficulty for any species concept that relies on reproductive isolation.
Speciation depends on a measure of reproductive isolation, a reduced gene flow.
Bacteria can exchange plasmids with bacteria of other species, including some apparently distantly related ones in different phylogenetic domains, making analysis of their relationships difficult, and weakening the concept of a bacterial species.
Mass extinctions had a variety of causes including volcanic activity, climate change, and changes in oceanic and atmospheric chemistry, and they in turn had major effects on Earth's ecology, atmosphere, land surface and waters.
Some observers claim that there is an inherent conflict between the desire to understand the processes of speciation and the need to identify and to categorise.
One of the classic cases in North America is that of the protected northern spotted owl which hybridises with the unprotected California spotted owl and the barred owl; this has led to legal debates.
A form was distinguished by being shared by all its members, the young inheriting any variations they might have from their parents.
He established the idea of a taxonomic hierarchy of classification based upon observable characteristics and intended to reflect natural relationships.
Jean-Baptiste Lamarck, in his 1809 Zoological Philosophy, described the transmutation of species, proposing that a species could change over time, in a radical departure from Aristotelian thinking.
Genus (plural genera) is a taxonomic rank used in the biological classification of living and fossil organisms as well as viruses.
E.g. Panthera leo (lion) and Panthera onca (jaguar) are two species within the genus Panthera.
A botanical example would be Hibiscus arnottianus, a particular species of the genus Hibiscus native to Hawaii.
Available names are those published in accordance with the International Code of Zoological Nomenclature and not otherwise suppressed by subsequent decisions of the International Commission on Zoological Nomenclature (ICZN); the earliest such name for any taxon (for example, a genus) should then be selected as the "valid" (i.e., current or accepted) name for the taxon in question.
In botany, similar concepts exist but with different labels.
However, many names have been assigned (usually unintentionally) to two or more different genera.
A name that means two different things is a homonym.
However, a genus in one kingdom is allowed to bear a scientific name that is in use as a generic name (or the name of a taxon in another rank) in a kingdom that is governed by a different nomenclature code.
For instance, among (non-avian) reptiles, which have about 1180 genera, the most (>300) have only 1 species, ~360 have between 2 and 4 species, 260 have 5–10 species, ~200 have 11–50 species, and only 27 genera have more than 50 species.
Which species are assigned to a genus is somewhat arbitrary.
What belongs to a family—or if a described family should be recognized at all—are proposed and determined by practicing taxonomists.
Often there is no exact agreement, with different taxonomists each taking a different position.
Michael Novacek (1986) inserted them at the same position.
There are no objective rules for describing a class, but for well-known animals there is likely to be consensus.
In botany, classes are now rarely discussed.
Informally, phyla can be thought of as groupings of organisms based on general specialization of body plan.
So phyla can be merged or split if it becomes apparent that they are related to one another or not.
By Budd and Jensen's definition, a phylum is defined by a set of characters shared by all its living representatives.
However, as it is character based, it is easy to apply to the fossil record.
However, proving that a fossil belongs to the crown group of a phylum is difficult, as it must display a character unique to a sub-set of the crown group.
The table below follows the influential (though contentious) Cavalier-Smith system in equating "Plantae" with Archaeplastida, a group containing Viridiplantae and the algal Rhodophyta and Glaucophyta divisions.
The division Pinophyta may be used for all gymnosperms (i.e. including cycads, ginkgos and gnetophytes), or for conifers alone as below.
Protista is a polyphyletic taxon, which is less acceptable to present-day biologists than in the past.
Carl Linnaeus (1707–1778) laid the foundations for modern biological nomenclature, now regulated by the Nomenclature Codes, in 1735.
In 1937 Édouard Chatton introduced the terms "prokaryote" and "eukaryote" to differentiate these organisms.
Robert Whittaker recognized an additional kingdom for the Fungi.
The remaining two kingdoms, Protista and Monera, included unicellular and simple cellular colonies.
In other systems, such as Lynn Margulis's system of five kingdoms, the plants included just the land plants (Embryophyta), and Protoctista has a broader definition.
Technological advances in electron microscopy allowed the separation of the Chromista from the Plantae kingdom.
Finally, some protists lacking mitochondria were discovered.
This superkingdom was opposed to the Metakaryota superkingdom, grouping together the five other eukaryotic kingdoms (Animalia, Protozoa, Fungi, Plantae and Chromista).
Cavalier-Smith no longer accepted the importance of the fundamental Eubacteria–Archaebacteria divide put forward by Woese and others and supported by recent research.
Cavalier-Smith does not accept the requirement for taxa to be monophyletic ("holophyletic" in his terminology) to be valid.
The advances of phylogenetic studies allowed Cavalier-Smith to realize that all the phyla thought to be archezoans (i.e. primitively amitochondriate eukaryotes) had in fact secondarily lost their mitochondria, typically by transforming them into new organelles: Hydrogenosomes.
Based on such RNA studies, Carl Woese thought life could be divided into three large divisions and referred to them as the "three primary kingdom" model or "urkingdom" model.
Woese divided the prokaryotes (previously classified as the Kingdom Monera) into two groups, called Eubacteria and Archaebacteria, stressing that there was as much genetic difference between these two groups as between either of them and all eukaryotes.
They held that only monophyletic groups should be accepted as formal ranks in a classification and that – while this approach had been impractical previously (necessitating "literally dozens of eukaryotic 'kingdoms) – it had now become possible to divide the eukaryotes into "just a few major groups that are probably all monophyletic".
It divided the eukaryotes into the same six "supergroups".
Plants are thought to be more distantly related to animals and fungi.
The ten arguments against include the fact that they are obligate intracellular parasites that lack metabolism and are not capable of replication outside of a host cell.
The first two are all prokaryotic microorganisms, or mostly single-celled organisms whose cells have a distorted or non-membrane bound nucleus.
Halophiles, organisms that thrive in highly salty environments, and hyperthermophiles, organisms that thrive in extremely hot environments, are examples of Archaea.
Cyanobacteria and mycoplasmas are two examples of bacteria.
Evolution is change in the heritable characteristics of biological populations over successive generations.
Evolution occurs when evolutionary processes such as natural selection (including sexual selection) and genetic drift act on this variation, resulting in certain characteristics becoming more common or rare within a population.
The scientific theory of evolution by natural selection was conceived independently by Charles Darwin and Alfred Russel Wallace in the mid-19th century and was set out in detail in Darwin's book On the Origin of Species.
Thus, in successive generations members of a population are more likely to be replaced by the progenies of parents with favourable characteristics that have enabled them to survive and reproduce in their respective environments.
The fossil record includes a progression from early biogenic graphite, to microbial mat fossils, to fossilised multicellular organisms.
It sought explanations of natural phenomena in terms of physical laws that were the same for all visible things and that did not require the existence of any fixed natural categories or divine cosmic order.
The biological classification introduced by Carl Linnaeus in 1735 explicitly recognised the hierarchical nature of species relationships, but still viewed species as fixed according to a divine plan.
These ideas were condemned by established naturalists as speculation lacking empirical support.
Partly influenced by An Essay on the Principle of Population (1798) by Thomas Robert Malthus, Darwin noted that population growth would lead to a "struggle for existence" in which favourable variations prevailed as others perished.
Darwin developed his theory of "natural selection" from 1838 onwards and was writing up his "big book" on the subject when Alfred Russel Wallace sent him a version of virtually the same theory in 1858.
Towards this end, Darwin developed his provisional theory of pangenesis.
To explain how new variants originate, de Vries developed a mutation theory that led to a temporary rift between those who accepted Darwinian evolution and biometricians who allied with de Vries.
The publication of the structure of DNA by James Watson and Francis Crick with contribution of Rosalind Franklin in 1953 demonstrated a physical mechanism for inheritance.
In 1973, evolutionary biologist Theodosius Dobzhansky penned that "nothing in biology makes sense except in the light of evolution," because it has brought to light the relations of what first seemed disjointed facts in natural history into a coherent explanatory body of knowledge that describes and predicts many observable facts about life on this planet.
The complete set of observable traits that make up the structure and behaviour of an organism is called its phenotype.
For example, suntanned skin comes from the interaction between a person's genotype and sunlight; thus, suntans are not passed on to people's children.
DNA is a long biopolymer composed of four types of bases.
Portions of a DNA molecule that specify a single functional unit are called genes; different genes have different sequences of bases.
If the DNA sequence at a locus varies between individuals, the different forms of this sequence are called alleles.
However, while this simple correspondence between an allele and a trait works in some cases, most traits are more complex and are controlled by quantitative trait loci (multiple interacting genes).
DNA methylation marking chromatin, self-sustaining metabolic loops, gene silencing by RNA interference and the three-dimensional conformation of proteins (such as prions) are areas where epigenetic inheritance systems have been discovered at the organismic level.
For example, ecological inheritance through the process of niche construction is defined by the regular and repeated activities of organisms in their environment.
Despite the constant introduction of new variation through mutation and gene flow, most of the genome of a species is identical in all individuals of that species.
A substantial part of the phenotypic variation in a population is caused by genotypic variation.
Variation disappears when a new allele reaches the point of fixation—when it either disappears from the population or replaces the ancestral allele entirely.
When mutations occur, they may alter the product of a gene, or prevent the gene from functioning, or have no effect.
Extra copies of genes are a major source of the raw material needed for new genes to evolve.
New genes can be generated from an ancestral gene when a duplicate copy mutates and acquires a new function.
The generation of new genes can also involve small parts of several genes being duplicated, with these fragments then recombining to form new combinations with new functions.
Recombination and reassortment do not alter allele frequencies, but instead change which alleles are associated with each other, producing offspring with new combinations of alleles.
The first cost is that in sexually dimorphic species only one of the two sexes can bear young.
Yet sexual reproduction is the more common means of reproduction among eukaryotes and multicellular organisms.
Gene transfer between species includes the formation of hybrid organisms and horizontal gene transfer.
Horizontal transfer of genes from bacteria to eukaryotes such as the yeast Saccharomyces cerevisiae and the adzuki bean weevil Callosobruchus chinensis has occurred.
Different traits confer different rates of survival and reproduction (differential fitness).
Consequently, organisms with traits that give them an advantage over their competitors are more likely to pass on their traits to the next generation than those with traits that do not confer an advantage.
The central concept of natural selection is the evolutionary fitness of an organism.
For example, if an organism could survive well and reproduce rapidly, but its offspring were all too small and weak to survive, this organism would make little genetic contribution to future generations and would thus have low fitness.
Examples of traits that can increase fitness are enhanced survival and increased fecundity.
However, even if the direction of selection does reverse in this way, traits that were lost in the past may not re-evolve in an identical form (see Dollo's law).
The first is directional selection, which is a shift in the average value of a trait over time—for example, organisms slowly getting taller.
Finally, in stabilising selection there is selection against extreme trait values on both ends, which causes a decrease in variance around the average value and less diversity.
This broad understanding of nature enables scientists to delineate specific forces which, together, comprise natural selection.
However, the rate of recombination is low (approximately two events per chromosome per generation).
A set of alleles that is usually inherited in a group is called a haplotype.
This drift halts when an allele eventually becomes fixed, either by disappearing from the population or replacing the other alleles entirely.
The neutral theory of molecular evolution proposed that most evolutionary changes are the result of the fixation of neutral mutations by genetic drift.
However, a more recent and better-supported version of this model is the nearly neutral theory, where a mutation that would be effectively neutral in a small population is not necessarily neutral in a large population.
The number of individuals in a population is not critical, but instead a measure known as the effective population size.
The presence or absence of gene flow fundamentally changes the course of evolution.
This opposing-pressures argument was long used to dismiss the possibility of internal tendencies in evolution, until the molecular era prompted renewed interest in neutral evolution.
For instance, mutation biases are frequently invoked in models of codon usage.
Different insertion vs. deletion biases in different taxa can lead to the evolution of different genome sizes.
Contemporary thinking about the role of mutation biases reflects a different theory from that of Haldane and Fisher.
Organisms can also respond to selection by cooperating with each other, usually by aiding their relatives or engaging in mutually beneficial symbiosis.
Macroevolution refers to evolution that occurs at or above the level of species, in particular speciation and extinction; whereas microevolution refers to smaller evolutionary changes within a species or population, in particular shifts in allele frequency and adaptation.
However, in macroevolution, the traits of the entire species may be important.
A common misconception is that evolution has goals, long-term plans, or an innate tendency for "progress", as expressed in beliefs such as orthogenesis and evolutionism; realistically however, evolution has no long-term goal and does not necessarily produce greater complexity.
Also, the term adaptation may refer to a trait that is important for an organism's survival.
An adaptive trait is an aspect of the developmental pattern of the organism which enables or enhances the probability of that organism surviving and reproducing.
Other striking examples are the bacteria Escherichia coli evolving the ability to use citric acid as a nutrient in a long-term laboratory experiment, Flavobacterium evolving a novel enzyme that allows these bacteria to grow on the by-products of nylon manufacturing, and the soil bacterium Sphingobium evolving an entirely new metabolic pathway that degrades the synthetic pesticide pentachlorophenol.
Consequently, structures with similar internal organisation may have different functions in related organisms.
However, since all living organisms are related to some extent, even organs that appear to have little or no structural similarity, such as arthropod, squid and vertebrate eyes, or the limbs and wings of arthropods and vertebrates, can depend on a common set of homologous genes that control their assembly and function; this is called deep homology.
Examples include pseudogenes, the non-functional remains of eyes in blind cave-dwelling fish, wings in flightless birds, the presence of hip bones in whales and snakes, and sexual traits in organisms that reproduce via asexual reproduction.
One example is the African lizard Holaspis guentheri, which developed an extremely flat head for hiding in crevices, as can be seen by looking at its near relatives.
Another example is the recruitment of enzymes from glycolysis and xenobiotic metabolism to serve as structural proteins called crystallins within the lenses of organisms' eyes.
These studies have shown that evolution can alter development to produce new structures, such as embryonic bone structures that develop into the jaw in other animals instead forming part of the middle ear in mammals.
These changes in the second species then, in turn, cause new adaptations in the first species.
For instance, an extreme cooperation exists between plants and the mycorrhizal fungi that grow on their roots and aid the plant in absorbing nutrients from the soil.
Coalitions between organisms of the same species have also evolved.
Here, somatic cells respond to specific signals that instruct them whether to grow, remain as they are, or die.
There are multiple ways to define the concept of "species."
Despite the diversity of various species concepts, these various concepts can be placed into one of three broad philosophical approaches: interbreeding, ecological and phylogenetic.
Despite its wide and long-term use, the BSC like others is not without controversy, for example because these concepts cannot be applied to prokaryotes, and this is called the species problem.
Gene flow may slow this process by spreading the new genetic variants also to the other populations.
In this case, closely related species may regularly interbreed, but hybrids will be selected against and the species will remain distinct.
Speciation has been observed multiple times under both controlled laboratory conditions (see laboratory experiments of speciation) and in nature.
The most common in animals is allopatric speciation, which occurs in populations initially isolated geographically, such as by habitat fragmentation or migration.
The second mode of speciation is peripatric speciation, which occurs when small populations of organisms become isolated in a new environment.
The third mode is parapatric speciation.
Generally this occurs when there has been a drastic change in the environment within the parental species' habitat.
Selection against interbreeding with the metal-sensitive parental population produced a gradual change in the flowering time of the metal-resistant plants, which eventually produced complete reproductive isolation.
This form is rare since even a small amount of gene flow may remove genetic differences between parts of a population.
This is not common in animals as animal hybrids are usually sterile.
This allows the chromosomes from each parental species to form matching pairs during meiosis, since each parent's chromosomes are represented by a pair already.
Indeed, chromosome doubling within a species may be a common cause of reproductive isolation, as half the doubled chromosomes will be unmatched when breeding with undoubled organisms.
Nearly all animal and plant species that have lived on Earth are now extinct, and extinction appears to be the ultimate fate of all species.
Despite the estimated extinction of more than 99 percent of all species that ever lived on Earth, about 1 trillion species are estimated to be on Earth currently with only one-thousandth of one percent described.
The earliest undisputed evidence of life on Earth dates from at least 3.5 billion years ago, during the Eoarchean Era after a geological crust started to solidify following the earlier molten Hadean Eon.
Commenting on the Australian findings, Stephen Blair Hedges wrote, "If life arose relatively quickly on Earth, then it could be common in the universe."
Estimates on the number of Earth's current species range from 10 million to 14 million, of which about 1.9 million are estimated to have been named and 1.6 million documented in a central database to date, leaving at least 80 percent not yet described.
The common descent of organisms was first deduced from four simple facts about organisms: First, they have geographic distributions that cannot be explained by local adaptation.
Fourth, organisms can be classified using these similarities into a hierarchy of nested groups, similar to a family tree.
This view dates back to an idea briefly mentioned by Darwin but later abandoned.
By comparing the anatomies of both modern and extinct species, palaeontologists can infer the lineages of those species.
More recently, evidence for common descent has come from the study of biochemical similarities between organisms.
The eukaryotic cells emerged between 1.6 and 2.7 billion years ago.
Another engulfment of cyanobacterial-like organisms led to the formation of chloroplasts in algae and plants.
In January 2016, scientists reported that, about 800 million years ago, a minor genetic change in a single molecule called GK-PID may have allowed organisms to go from a single cell organism to one of many cells.
Various triggers for the Cambrian explosion have been proposed, including the accumulation of oxygen in the atmosphere from photosynthesis.
Artificial selection is the intentional selection of traits in a population of organisms.
Proteins with valuable properties have evolved by repeated rounds of mutation and selection (for example modified enzymes and new antibodies) in a process called directed evolution.
Breeding together different populations of this blind fish produced some offspring with functional eyes, since different mutations had occurred in the isolated populations that had evolved in different caves.
Many human diseases are not static phenomena, but capable of evolution.
It is possible that we are facing the end of the effective life of most of available antibiotics and predicting the evolution and evolvability of our pathogens and devising strategies to slow or circumvent it is requiring deeper knowledge of the complex forces driving evolution at the molecular level.
He used evolution strategies to solve complex engineering problems.
In some countries, notably the United States, these tensions between science and religion have fuelled the current creation–evolution controversy, a religious conflict focusing on politics and public education.
The Scopes Trial decision of 1925 caused the subject to become very rare in American secondary biology textbooks for a generation, but it was gradually re-introduced later and became legally protected with the 1968 Epperson v. Arkansas decision.
Natural selection is the differential survival and reproduction of individuals due to differences in phenotype.
Variation exists within all populations of organisms.
The environment of a genome includes the molecular biology in the cell, other cells, other individuals, populations, species, as well as the abiotic environment.
Natural selection is a cornerstone of modern biology.
The concept of natural selection originally developed in the absence of a valid theory of heredity; at the time of Darwin's writing, science had yet to develop modern theories of genetics.
The classical arguments were reintroduced in the 18th century by Pierre Louis Maupertuis and others, including Darwin's grandfather, Erasmus Darwin.
The success of this theory raised awareness of the vast scale of geological time and made plausible the idea that tiny, virtually imperceptible changes in successive generations could produce consequences on the scale of differences between species.
He was in the process of writing his "big book" to present his research when the naturalist Alfred Russel Wallace independently conceived of the principle and described it in an essay he sent to Darwin to forward to Charles Lyell.
In the 3rd edition of 1861 Darwin acknowledged that others—like William Charles Wells in 1813, and Patrick Matthew in 1831—had proposed similar ideas, but had neither developed them nor presented them in notable scientific publications.
In a letter to Charles Lyell in September 1860, Darwin regretted the use of the term "Natural Selection", preferring the term "Natural Preservation".
However, natural selection remained controversial as a mechanism, partly because it was perceived to be too weak to explain the range of observed characteristics of living organisms, and partly because even supporters of evolution balked at its "unguided" and non-progressive nature, a response that has been characterised as the single most significant impediment to the idea's acceptance.
With the early 20th century integration of evolution with Mendel's laws of inheritance, the so-called modern synthesis, scientists generally came to accept natural selection.
J. B. S. Haldane introduced the concept of the "cost" of natural selection.
However, natural selection is "blind" in the sense that changes in phenotype can give a reproductive advantage regardless of whether or not the trait is heritable.
If the traits that give these individuals a reproductive advantage are also heritable, that is, passed from parent to offspring, then there will be differential reproduction, that is, a slightly higher proportion of fast rabbits or efficient algae in the next generation.
This gives the appearance of purpose, but in natural selection there is no intentional choice.
This gave dark-coloured moths a better chance of surviving to produce dark-coloured offspring, and in just fifty years from the first dark moth being caught, nearly all of the moths in industrial Manchester were dark.
If an organism lives half as long as others of its species, but has twice as many offspring surviving to adulthood, its genes become more common in the adult population of the next generation.
A distinction must be made between the concept of "survival of the fittest" and "improvement in fitness". "
Haldane called this process "substitution" or more commonly in biology, this is called "fixation".
The probability of a beneficial mutation occurring on some member of a population depends on the total number of replications of that variant.
In this experiment, "improvement in fitness" depends on the number of replications of the particular variant for a new variant to appear that is capable of growing in the next higher drug concentration region.
Richard Lenski's classic E. coli long-term evolution experiment is an example of adaptation in a competitive environment, ("improvement in fitness" during "survival of the fittest").
The uncommon disruptive selection also acts during transition periods when the current mode is sub-optimal, but alters the trait in more than one direction.
Some biologists recognise just two types: viability (or survival) selection, which acts to increase an organism's probability of survival, and fecundity (or fertility or reproductive) selection, which acts to increase the rate of reproduction, given survival.
In kin selection and intragenomic conflict, gene-level selection provides a more apt explanation of the underlying process.
Ecological selection is natural selection via any means other than sexual selection, such as kin selection, competition, and infanticide.
However, in some species, mate choice is primarily by males, as in some fishes of the family Syngnathidae.
Since the discovery of penicillin in 1928, antibiotics have been used to fight bacterial diseases.
Genetic variation is the result of mutations, genetic recombinations and alterations in the karyotype (the number, shape, size and internal arrangement of the chromosomes).
However, many mutations in non-coding DNA have deleterious effects.
Changes in these often have large effects on the phenotype of the individual because they regulate the function of many other genes.
When such mutations result in a higher fitness, natural selection favours these phenotypes and the novel trait spreads in the population.
However, it is intrinsic to the concept of a species that hybrids are selected against, opposing the evolution of reproductive isolation, a problem that was recognised by Darwin.
Phenotype is determined by an organism's genetic make-up (genotype) and the environment in which the organism lives.
An example is the ABO blood type antigens in humans, where three alleles govern the phenotype.
This process can continue until the allele is fixed and the entire population shares the fitter phenotype.
Stabilizing selection conserves functional genetic features, such as protein-coding genes or regulatory sequences, over time by selective pressure against deleterious variants.
Some forms of balancing selection do not result in fixation, but maintain an allele at intermediate frequencies in a population.
Maintenance of allelic variation can also occur through disruptive or diversifying selection, which favours genotypes that depart from the average in either direction (that is, the opposite of over-dominance), and can result in a bimodal distribution of trait values.
However, after a period with no new mutations, the genetic variation at these sites is eliminated due to genetic drift.
The exact outcome of the two processes depends both on the rate at which new mutations occur and on the strength of the natural selection, which is a function of how unfavourable the mutation proves to be.
The chance that such a reshuffle occurs between two alleles is inversely related to the distance between them.
A strong selective sweep results in a region of the genome where the positively selected haplotype (the allele and its neighbours) are in essence the only ones that exist in the population.
Background selection is the opposite of a selective sweep.
In the words of the philosopher Daniel Dennett, "Darwin's dangerous idea" of evolution by natural selection is a "universal acid," which cannot be kept restricted to any vessel or container, as it soon leaks out, working its way into ever-wider surroundings.
These conditions are: heritability, variation of type, and competition for limited resources.
Herbert Spencer and the eugenics advocate Francis Galton's interpretation of natural selection as necessarily progressive, leading to supposed advances in intelligence and civilisation, became a justification for colonialism, eugenics, and social Darwinism.
The racial idea as the basis of our state has already accomplished much in this respect."
The most prominent example of evolutionary psychology, notably advanced in the early work of Noam Chomsky and later by Steven Pinker, is the hypothesis that the human brain has adapted to acquire the grammatical rules of natural language.
He observed that organisms (pea plants) inherit traits by way of discrete "units of inheritance".
Gene structure and function, variation, and distribution are studied within the context of the cell, the organism (e.g. dominance), and within the context of a population.
Genetic processes work in combination with an organism's environment and experiences to influence development and behavior, often referred to as nature versus nurture.
The modern science of genetics, seeking to understand this process, began with the work of the Augustinian friar Gregor Mendel in the mid-19th century.
His second law is the same as what Mendel published.
A popular theory during the 19th century, and implied by Charles Darwin's 1859 On the Origin of Species, was blending inheritance: the idea that individuals inherit a smooth blend of traits from their parents.
In his paper "Versuche über Pflanzenhybriden" ("Experiments on Plant Hybridization"), presented in 1865 to the Naturforschender Verein (Society for Research in Nature) in Brünn, Mendel traced the inheritance patterns of certain traits in pea plants and described them mathematically.
William Bateson, a proponent of Mendel's work, coined the word genetics in 1905 (the adjective genetic, derived from the Greek word genesis—γένεσις, "origin", predates the noun and was first used in a biological sense in 1860).
Over the next 11 years, she discovered that females only had the X chromosome and males had both X and Y chromosomes.
James Watson and Francis Crick determined the structure of DNA in 1953, using the X-ray crystallography work of Rosalind Franklin and Maurice Wilkins that indicated DNA has a helical structure (i.e., shaped like a corkscrew).
The structure also suggested a simple method for replication: if the strands are separated, new partner strands can be reconstructed for each based on the sequence of the old strand.
In the following years, scientists tried to understand how DNA controls the process of protein production.
With the newfound molecular understanding of inheritance came an explosion of research.
One important development was chain-termination DNA sequencing in 1977 by Frederick Sanger.
In his experiments studying the trait for flower color, Mendel observed that the flowers of each pea plant were either purple or white—but never an intermediate between the two colors.
Many species, including humans, have this pattern of inheritance.
When organisms are heterozygous at a gene, often one allele is called dominant as its qualities dominate the phenotype of the organism, while the other allele is called recessive as its qualities recede and are not observed.
Often a "+" symbol is used to mark the usual, non-mutant allele for a gene.
One of the common diagrams used to predict the result of cross-breeding is the Punnett square.
Some genes do not assort independently, demonstrating genetic linkage, a topic discussed later in this article.)
Another gene, however, controls whether the flowers have color at all or are white.
Many traits are not discrete features (e.g. purple or white flowers) but are instead continuous features (e.g. human height and skin color).
The degree to which an organism's genes contribute to a complex trait is called heritability.
DNA is composed of a chain of nucleotides, of which there are four types: adenine (A), cytosine (C), guanine (G), and thymine (T).
Viruses cannot reproduce without a host and are unaffected by many genetic processes, so tend not to be considered living organisms.
This structure of DNA is the physical basis for inheritance: DNA replication duplicates the genetic information by splitting the strands and using each strand as a template for synthesis of a new partner strand.
These DNA strands are often extremely long; the largest human chromosome, for example, is about 247 million base pairs in length.
DNA is most often found in the nucleus of cells, but Ruth Sager helped in the discovery of nonchromosomal genes found outside of the nucleus.
While haploid organisms have only one copy of each chromosome, most animals and many plants are diploid, containing two of each chromosome and thus two copies of every gene.
In humans and many other animals, the Y chromosome contains the gene that triggers the development of the specifically male characteristics.
This process, called mitosis, is the simplest form of reproduction and is the basis for asexual reproduction.
Eukaryotic organisms often use sexual reproduction to generate offspring that contain a mixture of genetic material inherited from two different parents.
Some bacteria can undergo conjugation, transferring a small circular piece of DNA to another bacterium.
In this way new combinations of genes can occur in the offspring of a mating pair.
During crossover, chromosomes exchange stretches of DNA, effectively shuffling the gene alleles between the chromosomes.
The first cytological demonstration of crossing over was performed by Harriet Creighton and Barbara McClintock in 1931.
For an arbitrarily long distance, the probability of crossover is high enough that the inheritance of the genes is effectively uncorrelated.
The specific sequence of amino acids results in a unique three-dimensional structure for that protein, and the three-dimensional structures of proteins are related to their functions.
Protein structure is dynamic; the protein hemoglobin bends into slightly different forms as it facilitates the capture, transport, and release of oxygen molecules within mammalian blood.
For example, sickle-cell anemia is a human genetic disease that results from a single base difference within the coding region for the β-globin section of hemoglobin, causing a single amino acid change that changes hemoglobin's physical properties.
Some DNA sequences are transcribed into RNA but are not translated into protein products—such RNA molecules are called non-coding RNA.
An interesting example is the coat coloration of the Siamese cat.
But these dark hair-producing proteins are sensitive to temperature (i.e. have a mutation causing temperature-sensitivity) and denature in higher-temperature environments, failing to produce dark-hair pigment in areas where the cat has a higher body temperature.
After the fall of the Western Roman Empire, knowledge of Greek conceptions of the world deteriorated in Western Europe during the early centuries (400 to 1000 CE) of the Middle Ages, but was preserved in the Muslim world during the Islamic Golden Age.
Modern science is typically divided into three major branches that consist of the natural sciences (e.g., biology, chemistry, and physics), which study nature in the broadest sense; the social sciences (e.g., economics, psychology, and sociology), which study individuals and societies; and the formal sciences (e.g., logic, mathematics, and theoretical computer science), which deal with symbols governed by rules.
New knowledge in science is advanced by research from scientists who are motivated by curiosity about the world and a desire to solve problems.
In particular, it was the type of knowledge that people can communicate to each other and share.
However, no consistent conscious distinction was made between knowledge of such things, which are true in every community, and other types of communal knowledge, such as mythologies and legal systems.
They even developed an official calendar that contained twelve months, thirty days each, and five days at the end of the year.
For this reason, it is claimed these men were the first philosophers in the strict sense, and also the first people to clearly distinguish "nature" and "convention."
In contrast, trying to use knowledge of nature to imitate nature (artifice or technology, Greek technē) was seen by classical scientists as a more appropriate interest for artisans of lower social class.
The theory of atoms was developed by the Greek philosopher Leucippus and his student Democritus.
The Socratic method as documented by Plato's dialogues is a dialectic method of hypothesis elimination: better hypotheses are found by steadily identifying and eliminating those that lead to contradictions.
Socrates criticized the older type of study of physics as too purely speculative and lacking in self-criticism.
Aristotle later created a systematic programme of teleological philosophy: Motion and change is described as the actualization of potentials already in things, according to what types of things they are.
The Socratics also insisted that philosophy should be used to consider the practical question of the best way to live for a human being (a study Aristotle divided into ethics and political philosophy).
Aristarchus's model was widely rejected because it was believed to violate the laws of physics.
John Philoponus, a Byzantine scholar in the 500s, questioned Aristotle's teaching of physics, noting its flaws.
Aristotle's four causes prescribed that the question "why" should be answered in four ways in order to explain things scientifically.
However, Aristotle's original texts were eventually lost in Western Europe, and only one text by Plato was widely known, the Timaeus, which was the only Platonic dialogue, and one of the few original works of classical natural philosophy, available to Latin readers in the early Middle Ages.
Many Syriac translations were done by groups such as the Nestorians and Monophysites.
p. 465: "only when the influence of ibn al-Haytam and others on the mainstream of later medieval physical writings has been seriously investigated can Schramm's claim that ibn al-Haytam was the true founder of modern physics be evaluated."
Avicenna's canon is considered to be one of the most important publications in medicine and they both contributed significantly to the practice of experimental medicine, using clinical trials and experiments to back their claims.
In addition, classical Greek texts started to be translated from Arabic and Greek into Latin, giving a higher level of scientific discussion in Western Europe.
Manuscript copies of Alhazen's Book of Optics also propagated across Europe before 1240, as evidenced by its incorporation into Vitello's Perspectiva.
The influx of ancient texts caused the Renaissance of the 12th century and the flourishing of a synthesis of Catholicism and Aristotelianism known as Scholasticism in western Europe, which became a new geographic center of science.
A model of vision later known as perspectivism was exploited and studied by the artists of the Renaissance.
This was based on a theorem that the orbital periods of the planets are longer as their orbs are farther from the centre of motion, which he found not to agree with Ptolemy's model.
He found that all the light from a single point of the scene was imaged at a single point at the back of the glass sphere.
Kepler did not reject Aristotelian metaphysics and described his work as a search for the Harmony of the Spheres.
Galileo had used arguments from the Pope and put them in the voice of the simpleton in the work "Dialogue Concerning the Two Chief World Systems", which greatly offended Urban VIII.
Descartes emphasized individual thought and argued that mathematics rather than geometry should be used in order to study nature.
This new science began to see itself as describing "laws of nature".
In the style of Francis Bacon, Leibniz assumed that different types of things all work according to the same general laws of nature, with no special formal or final causes for each type of thing.
In Bacon's words, "the real and legitimate goal of sciences is the endowment of human life with new inventions and riches", and he discouraged scientists from pursuing intangible philosophical or spiritual ideas, which he believed contributed little to human happiness beyond "the fume of subtle, sublime, or pleasing speculation".
Another important development was the popularization of science among an increasingly literate population.
Enlightenment philosophers chose a short history of scientific predecessors – Galileo, Boyle, and Newton principally – as the guides and guarantors of their applications of the singular concept of nature and natural law to every physical and social field of the day.
Hume and other Scottish Enlightenment thinkers developed a "science of man", which was expressed historically in works by authors including James Burnett, Adam Ferguson, John Millar and William Robertson, all of whom merged a scientific study of how humans behaved in ancient and primitive cultures with a strong awareness of the determining forces of modernity.
Both John Herschel and William Whewell systematized methodology: the latter coined the term scientist.
Separately, Gregor Mendel presented his paper, "Versuche über Pflanzenhybriden" ("Experiments on Plant Hybridization"), in 1865, which outlined the principles of biological inheritance, serving as the basis for modern genetics.
The phenomena that would allow the deconstruction of the atom were discovered in the last decade of the 19th century: the discovery of X-rays inspired the discovery of radioactivity.
In addition, the extensive use of technological innovation stimulated by the wars of this century led to revolutions in transportation (automobiles and aircraft), the development of ICBMs, a space race, and a nuclear arms race.
The discovery of the cosmic microwave background radiation in 1964 led to a rejection of the Steady State theory of the universe in favor of the Big Bang theory of Georges Lemaître.
Widespread use of integrated circuits in the last quarter of the 20th century combined with communications satellites led to a revolution in information technology and the rise of the global internet and mobile computing, including smartphones.
Both natural and social sciences are empirical sciences, as their knowledge is based on empirical observations and is capable of being tested for its validity by other researchers working under the same conditions.
For example, physical science can be subdivided into physics, chemistry, astronomy, and earth science.
Still, philosophical perspectives, conjectures, and presuppositions, often overlooked, remain necessary in natural science.
It includes mathematics, systems theory, and theoretical computer science.
The formal sciences are therefore a priori disciplines and because of this, there is disagreement on whether they actually constitute a science.
Engineering itself encompasses a range of more specialized fields of engineering, each with a more specific emphasis on particular areas of applied mathematics, science, and types of application.
he responded: "Sir, what is the use of a new-born child?".
This new explanation is used to make falsifiable predictions that are testable by experiment or observation.
This is done partly through observation of natural phenomena, but also through experimentation that tries to simulate natural events under controlled conditions as appropriate to the discipline (in the observational sciences, such as astronomy or geology, a predicted observation might take the place of a controlled experiment).
If the hypothesis survived testing, it may become adopted into the framework of a scientific theory, a logically reasoned, self-consistent model or framework for describing the behavior of certain natural phenomena.
In that vein, theories are formulated according to most of the same scientific principles as hypotheses.
This can be achieved by careful experimental design, transparency, and a thorough peer review process of the experimental results as well as any conclusions.
Statistics, a branch of mathematics, is used to summarize and analyze data, which allow scientists to assess the reliability and variability of their experimental results.
It can be contrasted with anti-realism, the view that the success of science does not depend on it being accurate about unobservable entities such as electrons.
There are different schools of thought in the philosophy of science.
This is necessary because the number of predictions those theories make is infinite, which means that they cannot be known from the finite amount of evidence using deductive logic only.
Critical rationalism is a contrasting 20th-century approach to science, first defined by Austrian-British philosopher Karl Popper.
Popper proposed replacing verifiability with falsifiability as the landmark of scientific theories and replacing induction with falsification as the empirical method.
Another approach, instrumentalism, emphasizes the utility of theories as instruments for explaining and predicting phenomena.
Close to instrumentalism is constructive empiricism, according to which the main criterion for the success of a scientific theory is whether what it says about observable entities is true.
Each paradigm has its own distinct questions, aims, and interpretations.
That is, the choice of a new paradigm is based on observations, even though those observations are made against the background of the old paradigm.
Its main point is that a difference between natural and supernatural explanations should be made and that science should be restricted methodologically to natural explanations.
That is, no theory is ever considered strictly certain as science accepts the concept of fallibilism.
New scientific knowledge rarely results in vast changes in our understanding.
Knowledge in science is gained by a gradual synthesis of information from different experiments by various researchers across different branches of science; it is more like a climb than a leap.
Philosopher Barry Stroud adds that, although the best definition for "knowledge" is contested, being skeptical and entertaining the possibility that one is incorrect is compatible with being correct.
This is especially the case in the more macroscopic fields of science (e.g. psychology, physical cosmology).
Since that time the total number of active periodicals has steadily increased.
Although the journals are in 39 languages, 91 percent of the indexed articles are published in English.
Science magazines such as New Scientist, Science & Vie, and Scientific American cater to the needs of a much wider readership and provide a non-technical summary of popular areas of research, including notable discoveries and advances in certain fields of research.
Various types of commercial advertising, ranging from hype to fraud, may fall into these categories.
Many scientists pursue careers in various sectors of the economy such as academia, industry, government, and nonprofit organizations.
For example, Christine Ladd (1847–1930) was able to enter a Ph.D. program as "C. Ladd"; Christine "Kitty" Ladd completed the requirements in 1882, but was awarded her degree only in 1926, after a career which spanned the algebra of logic (see truth table), color vision, and psychology.
In the late 20th century, active recruitment of women and elimination of institutional discrimination on the basis of sex greatly increased the number of women scientists, but large gender disparities remain in some fields; in the early 21st century over half of the new biologists were female, while 80% of PhDs in physics are given to men.
Membership may be open to all, may require possession of some scientific credentials, or may be an honor conferred by election.
Science policy thus deals with the entire domain of issues that involve the natural sciences.
Prominent historical examples include the Great Wall of China, completed over the course of two millennia through the state support of several dynasties, and the Grand Canal of the Yangtze River, an immense feat of hydraulic engineering begun by Sunshu Ao (孫叔敖 7th cent.
Such processes, which are run by government, corporations, or foundations, allocate scarce funds.
The government funding proportion in certain industries is higher, and it dominates research in social science and humanities.
Many factors can act as facets of the politicization of science such as populist anti-intellectualism, perceived threats to religious beliefs, postmodernist subjectivism, and fear for business interests.
An experiment is a procedure carried out to support or refute a hypothesis.
Experiments can raise test scores and help a student become more engaged and interested in the material they are learning, especially when used over time.
Experiments typically include controls, which are designed to minimize the effects of variables other than the single independent variable.
Researchers also use experimentation to test existing theories or new hypotheses to support or disprove them.
If an experiment is carefully conducted, the results usually either support or disprove the hypothesis.
In medicine and the social sciences, the prevalence of experimental research varies widely across disciplines.
A single study typically does not involve replications of the experiment, but separate studies may be aggregated through systematic review and meta-analysis.
We may in this way eventually come to the truth that gratifies the heart and gradually and carefully reach the end at which certainty appears; while through criticism and caution we may seize the truth that dispels disagreement and resolves doubtful matters.
In this process of critical consideration, the man himself should not forget that he tends to subjective opinions—through "prejudices" and "leniency"—and thus has to be critical about his own way of building hypotheses.
Bacon wanted a method that relied on repeatable observations, or experiments.
For example, Galileo Galilei (1564–1642) accurately measured time and experimented to make accurate measurements and conclusions about the speed of a falling body.
In some disciplines (e.g., psychology or political science), a 'true experiment' is a method of social research in which there are two kinds of variables.
A good example would be a drug trial.
The results from replicate samples can often be averaged, or if one of the replicates is obviously inconsistent with the results from the other samples, it can be discarded as being the result of an experimental error (some step of the test procedure may have been mistakenly omitted for that sample).
A negative control is known to give a negative result.
Most often the value of the negative control is treated as a "background" value to subtract from the test sample results.
Students might be given a fluid sample containing an unknown (to the student) amount of protein.
Students could make several positive control samples containing various dilutions of the protein standard.
The assay is a colorimetric assay in which a spectrophotometer can measure the amount of protein in samples by detecting a colored complex formed by the interaction of protein molecules and molecules of an added dye.
In this case, the experiment begins by creating two or more sample groups that are probabilistically equivalent, which means that measurements of traits should be similar among the groups and that the groups should respond in the same manner if given the same treatment.
Once equivalent groups have been formed, the experimenter tries to treat them identically except for the one variable that he or she wishes to isolate.
This ensures that any effects on the volunteer are due to the treatment itself and are not a response to the knowledge that he is being treated.
These hypotheses suggest reasons to explain a phenomenon, or predict the results of an action.
The null hypothesis is that there is no explanation or predictive power of the phenomenon through the reasoning that is being investigated.
To the degree possible, they attempt to collect data for the system in such a way that contribution from all variables can be determined, and where the effects of variation in certain variables remain approximately constant so that the effects of other variables can be discerned.
Usually, however, there is some correlation between these variables, which reduces the reliability of natural experiments relative to what could be concluded if a controlled experiment were performed.
For example, in astronomy it is clearly impossible, when testing the hypothesis "Stars are collapsed clouds of hydrogen", to start out with a giant cloud of hydrogen, and then perform the experiment of waiting a few billion years for it to form a star.
For this reason, field experiments are sometimes seen as having higher external validity than laboratory experiments.
In these situations, observational studies have value because they often suggest hypotheses that can be tested with randomized experiments or by collecting fresh data.
In addition, observational studies (e.g., in biological or social systems) often involve variables that are difficult to quantify or control.
Without a statistical model that reflects an objective randomization, the statistical analysis relies on a subjective model.
For example, epidemiological studies of colon cancer consistently show beneficial correlations with broccoli consumption, while experiments find no benefit.
For any randomized trial, some variation from the mean is expected, of course, but the randomization ensures that the experimental groups have mean values that are close, due to the central limit theorem and Markov's inequality.
To avoid conditions that render an experiment far less useful, physicians conducting medical trials—say for U.S. Food and Drug Administration approval—quantify and randomize the covariates that can be identified.
It is also generally unethical (and often illegal) to conduct randomized experiments on the effects of substandard or harmful treatments, such as the effects of ingesting arsenic on human health.
A physics laboratory might contain a particle accelerator or vacuum chamber, while a metallurgy laboratory could have apparatus for casting or refining metals or for testing their strength.
Scientists in other fields will use still other types of laboratories.
Despite the underlying notion of the lab as a confined space for experts, the term "laboratory" is also increasingly applied to workshop spaces such as Living Labs, Fab Labs, or Hackerspaces, in which people meet to work on societal problems or make prototypes, working collaboratively or sharing resources.
This laboratory was created when Pythagoras conducted an experiment about tones of sound and vibration of string.
A 16th century underground alchemical laboratory was accidentally discovered in the year 2002.
Laboratory hazards might include poisons; infectious agents; flammable, explosive, or radioactive materials; moving machinery; extreme temperatures; lasers, strong magnetic fields or high voltage.
The Occupational Safety and Health Administration (OSHA) in the United States, recognizing the unique characteristics of the laboratory workplace, has tailored a standard for occupational exposure to hazardous chemicals in laboratories.
In determining the proper Chemical Hygiene Plan for a particular business or laboratory, it is necessary to understand the requirements of the standard, evaluation of the current safety, health and environmental practices and assessment of the hazards.
Additionally, third party review is also used to provide an objective "outside view" which provides a fresh look at areas and problems that may be taken for granted or overlooked due to habit.
Training is critical to the ongoing safe operation of the laboratory facility.
For example, one research group has a schedule where they conduct research on their own topic of interest for one day of the week, but for the rest they work on a given group project.
A Locator is an employee of a Laboratory who is in charge of knowing where each member of the laboratory currently is, based on a unique signal emitted from the badge of each staff member.
Through ethnographic studies, one finding is that, among the personnel, each class (researchers, administrators...) has a different degree of entitlement, which varies per laboratory.
By looking at the various interactions among staff members, we can determine their social position in the organization.
So a consequence of this social hierarchy is that the Locator discloses various degrees of information, based on the staff member and their rights.
Social hierarchy is also related to attitudes towards technologies.
For example, a receptionist would view the badge as useful, as it would help them locate members of staff during the day.
Staff members feel ill at ease when changing patterns of entitlement, obligation, respect, informal and formal hierarchy, and more.
Nature, in the broadest sense, is the natural, physical, material world or universe. "
Although humans are part of nature, human activity is often understood as a separate category from other natural phenomena.
The concept of nature as a whole, the physical universe, is one of several expansions of the original notion; it began with certain core applications of the word φύσις by pre-Socratic philosophers (though this word had a dynamic dimension then, especially for Heraclitus), and has steadily gained currency ever since.
However, a vitalist vision of nature, closer to the presocratic one, got reborn at the same time, especially after Charles Darwin.
It is often taken to mean the "natural environment" or wilderness—wild animals, rocks, forest, and in general those things that have not been substantially altered by human intervention, or which persist despite human intervention.
Its most prominent climatic features are its two large polar regions, two relatively narrow temperate zones, and a wide equatorial tropical to subtropical region.
The remainder consists of continents and islands, with most of the inhabited land in the Northern Hemisphere.
The interior remains active, with a thick layer of plastic mantle and an iron-filled core that generates a magnetic field.
Rock units are first emplaced either by deposition onto the surface or intrude into the overlying rock.
Outgassing and volcanic activity produced the primordial atmosphere.
Continents formed, then broke up and reformed as the surface of Earth reshaped over hundreds of millions of years, occasionally combining to make a supercontinent.
During the Neoproterozoic era, freezing temperatures covered much of the Earth in glaciers and ice sheets.
The last mass extinction occurred some 66 million years ago, when a meteorite collision probably triggered the extinction of the non-avian dinosaurs and other large reptiles, but spared small animals such as mammals.
The subsequent advent of human life, and the development of agriculture and further civilization allowed humans to affect the Earth more rapidly than any previous life form, affecting both the nature and quantity of other organisms as well as global climate.
The thin layer of gases that envelops the Earth is held in place by gravity.
The ozone layer plays an important role in depleting the amount of ultraviolet (UV) radiation that reaches the surface.
Terrestrial weather occurs almost exclusively in the lower part of the atmosphere, and serves as a convective system for redistributing heat.
Also, without the redistributions of heat energy by the ocean currents and atmosphere, the tropics would be much hotter, and the polar regions much colder.
Surface vegetation has evolved a dependence on the seasonal variation of the weather, and sudden changes lasting only a few years can have a dramatic effect, both on the vegetation and on the animals which depend on its growth for their food.
Based on historical records, the Earth is known to have undergone drastic climate changes in the past, including ice ages.
There are a number of such regions, ranging from the tropical climate at the equator to the polar climate in the northern and southern extremes.
This exposure alternates as the Earth revolves in its orbit.
Water covers 71% of the Earth's surface.
Smaller regions of the oceans are called seas, gulfs, bays and other names.
It is not known if Titan's lakes are fed by rivers, though Titan's surface is carved by numerous river beds.
A wide variety of man-made bodies of water are classified as ponds, including water gardens designed for aesthetic ornamentation, fish ponds designed for commercial fish breeding, and solar ponds designed to store thermal energy.
Small rivers may also be called by several other names, including stream, creek, brook, rivulet, and rill; there is no general rule that defines what can be called a river.
The structure and composition is determined by various environmental factors that are interrelated.
Central to the ecosystem concept is the idea that living organisms interact with every other element in their local environment.
Life may also be said to be simply the characteristic state of organisms.
However, not every definition of life considers all of these properties to be essential.
From the broadest geophysiological point of view, the biosphere is the global ecological system integrating all living beings and their relationships, including their interaction with the elements of the lithosphere (rocks), hydrosphere (water), and atmosphere (air).
More than 2 million species of plant and animal life have been identified to date, and estimates of the actual number of existing species range from several million to well over 50 million.
Species that were unable to adapt to the changing environment and competition from other life forms became extinct.
When basic forms of plant life developed the process of photosynthesis the sun's energy could be harvested to create conditions which allowed for more complex life forms.
Microorganisms are single-celled organisms that are generally microscopic, and smaller than the human eye can see.
Their reproduction is both rapid and profuse.
Since then, it has become clear that the Plantae as originally defined included several unrelated groups, and the fungi and several groups of algae were removed to new kingdoms.
Among the many ways of classifying plants are by regional floras, which, depending on the purpose of study, can also include fossil flora, remnants of plant life from a previous era.
Some types of "native flora" actually have been introduced centuries ago by people migrating from one region or continent to another, and become an integral part of the native, or natural flora of the place to which they were introduced.
Animals as a category have several characteristics that generally set them apart from other living things.
They are also distinguished from plants, algae, and fungi by lacking cell walls.
There is also typically an internal digestive chamber.
A 2020 study published in Nature found that anthropogenic mass (human-made materials) outweighs all living biomass on earth, with plastic alone exceeding the mass of all land and marine animals combined.
In spite of this progress, however, the fate of human civilization remains closely linked to changes in the environment.
Humans have contributed to the extinction of many plants and animals, with roughly 1 million species threatened with extinction within decades.
This distorts market pricing of natural resources and at the same time leads to underinvestment in our natural assets.
Governments have not prevented these economic externalities.
Some activities, such as hunting and fishing, are used for both sustenance and leisure, often by different people.
That nature has been depicted and celebrated by so much art, photography, poetry, and other literature shows the strength with which many people associate nature and beauty.
Nature and wildness have been important subjects in various eras of world history.
Although natural wonders are celebrated in the Psalms and the Book of Job, wilderness portrayals in art became more prevalent in the 1800s, especially in the works of the Romantic movement.
For this reason the most fundamental science is generally understood to be "physics"—the name for which is still recognizable as meaning that it is the "study of nature".
The visible components of the universe are now believed to compose only 4.9 percent of the total mass.
The behaviour of matter and energy throughout the observable universe appears to follow well-defined physical laws.
There is no discrete boundary between Earth's atmosphere and space, as the atmosphere gradually attenuates with increasing altitude.
There is also some gas, plasma and dust, and small meteors.
Although Earth is the only body within the solar system known to support life, evidence suggests that in the distant past the planet Mars possessed bodies of liquid water on the surface.
If life exists at all on Mars, it is most likely to be located underground where liquid water can still exist.
Observation is the active acquisition of information from a primary source.
The use of measurement developed to allow recording and comparison of observations made at different times and places, by different people.
In measurement the number of standard units which is equal to the observation is counted.
Scientific instruments were developed to aid human abilities of observation, such as weighing scales, clocks, telescopes, microscopes, thermometers, cameras, and tape recorders, and also translate into perceptible form events that are unobservable by the senses, such as indicator dyes, voltmeters, spectrometers, infrared cameras, oscilloscopes, interferometers, geiger counters, and radio receivers.
For example, it is not normally possible to check the air pressure in an automobile tire without letting out some of the air, thereby changing the pressure.
For example, in the twin paradox one twin goes on a trip near the speed of light and comes home younger than the twin who stayed at home.
Quantum mechanics: In quantum mechanics, which deals with the behavior of very small objects, it is not possible to observe a system without changing the system, and the "observer" must be considered part of the system being observed.
Human perception occurs by a complex, unconscious process of abstraction, in which certain details of the incoming sense data are noticed and remembered, and the rest forgotten.
Later when events are remembered, memory gaps may even be filled by "plausible" data the mind makes up to fit the model; this is called reconstructive memory.
In psychology, this is called confirmation bias.
For example, let us suppose that an observer sees a parent beat their child; and consequently may observe that such an action is either good or bad.
Research is "creative and systematic work undertaken to increase the stock of knowledge".
To test the validity of instruments, procedures, or experiments, research may replicate elements of prior projects or the project as a whole.
This material is of a primary-source character.
In experimental work, it typically involves direct or indirect observation of the researched subject(s), e.g., in the laboratory or in the field, documents the methodology, results, and conclusions of an experiment or set of experiments, or offers a novel interpretation of previous results.
The degree of originality of the research is among major criteria for articles to be published in academic journals and usually established by means of peer review.
This research provides scientific information and theories for the explanation of the nature and the properties of the world.
Scientific research can be subdivided into different classifications according to their academic and application disciplines.
Humanities scholars usually do not search for the ultimate correct answer to a question, but instead, explore the issues and details that surround it.
Historians use primary sources and other evidence to systematically investigate a topic, and then to write histories in the form of accounts of the past.
The research will have to be justified by linking its importance to already existing knowledge about the topic.
Generally, a hypothesis is used to make predictions that can be tested by observing the outcome of an experiment.
This careful language is used because researchers recognize that alternative hypotheses may also be consistent with the observations.
As the accuracy of observation improves with time, the hypothesis may no longer provide an accurate prediction.
Artistic research has been defined by the School of Dance and Circus (Dans och Cirkushögskolan, DOCH), Stockholm in the following manner – "Artistic research is to investigate and test with the purpose of gaining knowledge within and for our artistic disciplines.
Artistic research aims to enhance knowledge and understanding with presentation of the arts.
According to artist Hakan Topal, in artistic research, "perhaps more so than other disciplines, intuition is utilized as a method to identify a wide range of new and unexpected productive modalities".
Background research could include, for example, geographical or procedural research.
The literature review identifies flaws or holes in previous research which provides justification for the study.
The research question may be parallel to the hypothesis.
The researcher(s) then analyzes and interprets the data via a variety of statistical methods, engaging in what is known as empirical research.
However, some researchers advocate for the reverse approach: starting with articulating findings and discussion of them, moving "up" to identification of a research problem that emerges in the findings and literature review.
Qualitative research is often used as a method of exploratory research as a basis for later quantitative research hypotheses.
Quantitative research is linked with the philosophical and theoretical stance of positivism.
Quantitative research is concerned with testing hypotheses derived from theory or being able to estimate the size of a phenomenon of interest.
If the intent is to generalize from the research participants to a larger population, the researcher will employ probability sampling to select participants.
Secondary data is data that already exists, such as census data, which can be re-used for the research.
This method has benefits that using one method alone cannot offer.
Non-empirical research is not an absolute alternative to empirical research because they may be used together to strengthen a research approach.
The management of research ethics is inconsistent across countries and there is no universally accepted approach to how it should be addressed.
Regardless of approach, the application of ethical theory to specific controversial topics is known as applied ethics and research ethics can be viewed as a form of applied ethics because ethical theory is applied in real-world research scenarios.
Research ethics is most developed as a concept in medical research, the most notable Code being the 1964 Declaration of Helsinki.
Meta-research concerns itself with the detection of bias, methodological flaws, and other errors and inefficiencies.
Periphery scholars face the challenges of exclusion and linguicism in research and academic publication.
For comparative politics, Western countries are over-represented in single-country studies, with heavy emphasis on Western Europe, Canada, Australia, and New Zealand.
Studies with a narrow scope can result in a lack of generalizability, meaning that the results may not be applicable to other populations or regions.
Usually, the peer review process involves experts in the same field who are consulted by editors to give a review of the scholarly works produced by a colleague of theirs from an unbiased and impartial point of view, and this is usually done free of charge.
For instance, most indigenous communities consider that access to certain information proper to the group should be determined by relationships.
The system varies widely by field and is also always changing, if often slowly.
These forms of research can be found in databases explicitly for theses and dissertations.
The kinds of publications that are accepted as contributions of knowledge or research vary greatly between fields, from the print to the electronic format.
Business models are different in the electronic environment.
Many senior researchers (such as group leaders) spend a significant amount of their time applying for grants for research funds.
The scientific method is an empirical method of acquiring knowledge that has characterized the development of science since at least the 17th century (with notable practitioners in previous centuries).
These are principles of the scientific method, as distinguished from a definitive series of steps applicable to all scientific enterprises.
A hypothesis is a conjecture, based on knowledge obtained while seeking answers to the question.
There are difficulties in a formulaic statement of method, however.
The term "scientific method" emerged in the 19th century, when a significant institutional development of science was taking place and terminologies establishing clear boundaries between science and non-science, such as "scientist" and "pseudoscience", appeared.
Gauch 2003, and Tow 2010 disagree with Feyerabend's claim; problem solvers, and researchers are to be prudent with their resources during their inquiry.
Philosophers Robert Nola and Howard Sankey, in their 2007 book Theories of Scientific Method, said that debates over scientific method continue, and argued that Feyerabend, despite the title of Against Method, accepted certain rules of method and attempted to justify those rules with a meta methodology.
The ubiquitous element in the scientific method is empiricism.
The scientific method counters claims that revelation, political or religious dogma, appeals to tradition, commonly held beliefs, common sense, or currently held theories pose the only possible means of demonstrating truth.
From the 16th century onwards, experiments were advocated by Francis Bacon, and performed by Giambattista della Porta, Johannes Kepler, and Galileo Galilei.
As in other areas of inquiry, science (through the scientific method) can build on previous knowledge and develop a more sophisticated understanding of its topics of study over time.
This model can be seen to underlie the scientific revolution.: "
One conjecture might be that a new drug will cure the disease in some of the people in that population, as in a clinical trial of the drug.
These predictions are expectations for the results of testing.
The difference between expected versus actual indicates which hypothesis better explains the resulting data from the experiment.
Depending on the complexity of the experiment, iteration of the process may be required to gather sufficient evidence to answer the question with confidence, or to build up other answers to highly specific questions, to answer a single broader question.
X-ray diffraction patterns of DNA by Florence Bell in her Ph.D. thesis (1939) were similar to (although not as good as) "photo 51", but this research was interrupted by the events of World War II.
June 1952 — Watson had succeeded in getting X-ray pictures of TMV showing a diffraction pattern consistent with the transform of a helix.
This prediction was a mathematical construct, completely independent from the biological problem at hand.
DNA is not a helix."
For example, the number of strands in the backbone of the helix (Crick suspected 2 strands, but cautioned Watson to examine that more critically), the location of the base pairs (inside the backbone or outside the backbone), etc.
But Wilkins agrees to do so only after Franklin's departure.: "
He and Crick then produced their model, using this information along with the previously known information about DNA's composition, especially Chargaff's rules of base pairing.:
For significant or surprising results, other scientists may also attempt to replicate the results for themselves, especially if those results would be important to their own work.
Peer review does not certify the correctness of the results, only that, in the opinion of the reviewer, the experiments themselves were sound (based on the description supplied by the experimenter).
These methodological elements and organization of procedures tend to be more characteristic of experimental sciences than social sciences.
The elements above are often taught in the educational system as "the scientific method".
For example, when Einstein developed the Special and General Theories of Relativity, he did not in any way refute or discount Newton's Principia.
The systematic, careful collection of measurements or counts of relevant quantities is often the critical difference between pseudo-sciences, such as alchemy, and science, such as chemistry or biology.
Uncertainties may also be calculated by consideration of the uncertainties of the individual underlying quantities used.
The operational definition of a thing often relies on comparisons with standards: the operational definition of "mass" ultimately relies on the use of an artifact, such as a particular kilogram of platinum-iridium kept in a laboratory in France.
Scientific quantities are often characterized by their units of measure which can later be described in terms of conventional physical units when communicating the work.
It took thousands of years of measurements, from the Chaldean, Indian, Persian, Greek, Arabic, and European astronomers, to fully record the motion of planet Earth.
The observed difference for Mercury's precession between Newtonian theory and observation was one of the things that occurred to Albert Einstein as a possible early test of his theory of General relativity.
Scientists are free to use whatever resources they have – their own creativity, ideas from other fields, inductive reasoning, Bayesian inference, and so on – to imagine possible explanations for a phenomenon under study.
Scientists often use these terms to refer to a theory that is following the known facts but is nevertheless relatively simple and easy to handle.
It is essential that the outcome of testing such a prediction be currently unknown.
If the predictions are not accessible by observation or experience, the hypothesis is not yet testable and so will remain to that extent unscientific in a strict sense.
This implied that DNA's X-ray diffraction pattern would be 'x shaped'.
Sometimes the experiments are conducted incorrectly or are not very well designed when compared to a crucial experiment.
This technique uses the contrast between multiple samples, or observations, or populations, under differing conditions, to see what varies or what remains the same.
Factor analysis is one technique for discovering the important factor in an effect.
Even taking a plane from New York to Paris is an experiment that tests the aerodynamical hypotheses used for constructing the plane.
Franklin immediately spotted the flaws which concerned the water content.
Failure to develop an interesting hypothesis may lead a scientist to re-define the subject under consideration.
Other scientists may start their own research and enter the process at any stage.
Crucially, experimental and theoretical results must be reproduced by others within the scientific community.
The better an explanation is at making predictions, the more useful it frequently can be, and the more likely it will continue to explain a body of evidence better than its alternatives.
Scientific models vary in the extent to which they have been experimentally tested and for how long, and in their acceptance in the scientific community.
If such evidence is found, a new theory may be proposed, or (more commonly) it is found that modifications to the previous theory are sufficient to explain the new evidence.
For example, Newton's laws explained thousands of years of scientific observations of the planets almost perfectly.
Since new theories might be more comprehensive than what preceded them, and thus be able to explain more than previous ones, successor theories might be able to meet a higher standard by explaining a larger body of observations than their predecessors.
Once a structurally complete and closed system of opinions consisting of many details and relations has been formed, it offers enduring resistance to anything that contradicts it".
Its successes can shine but tend to be transitory.
The method of the a priori – which promotes conformity less brutally but fosters opinions as something like tastes, arising in conversation and comparisons of perspectives in terms of "what is agreeable to reason."
That is a destination as far, or near, as the truth itself to you or me or the given finite community.
From abduction, Peirce distinguishes induction as inferring, based on tests, the proportion of truth in the hypothesis.
Oftenest, even a well-prepared mind guesses wrong.
Peirce, Charles S. (1902), Carnegie application, see MS L75.329330, from Draft D of Memoir 27: "Consequently, to discover is simply to expedite an event that would occur sooner or later, if we had not troubled ourselves to make the discovery.
Consequently, the conduct of abduction, which is chiefly a question of heuretic and is the first question of heuretic, is to be governed by economical considerations."
The hypothesis, being insecure, needs to have practical implications leading at least to mental tests and, in science, lending themselves to scientific tests.
Einstein, Albert (1936, 1956) One may say "the eternal mystery of the world is its comprehensibility."
These assumptions from methodological naturalism form a basis on which science may be grounded.
His observations of science practice are essentially sociological and do not speak to how science is or can be practiced in other times and other cultures.
He opens Chapter 1 with a discussion of the Golgi bodies and their initial rejection as an artefact of staining technique, and a discussion of Brahe and Kepler observing the dawn and seeing a "different" sunrise despite the same physiological phenomenon.
In essence, he says that for any specific method or norm of science, one can find a historic episode where violating it has contributed to the progress of science.
The postmodernist critiques of science have themselves been the subject of intense controversy.
Models, in both science and mathematics, need to be internally consistent and also ought to be falsifiable (capable of disproof).
For example, the technical concept of time arose in science, and timelessness was a hallmark of a mathematical topic.
Eugene Wigner's paper, The Unreasonable Effectiveness of Mathematics in the Natural Sciences, is a very well-known account of the issue from a Nobel Prize-winning physicist.
In Proofs and Refutations, Lakatos gave several basic rules for finding proofs and counterexamples to conjectures.
This may explain why scientists so often express that they were lucky.
Mahwah, NJ: Lawrence Erlbaum Associates.
This is what Nassim Nicholas Taleb calls "Anti-fragility"; while some systems of investigation are fragile in the face of human error, human bias, and randomness, the scientific method is more than resistant or tough – it actually benefits from such randomness in many ways (it is anti-fragile).
These unexpected results lead researchers to try to fix what they think is an error in their method.
A scientific theory is an explanation of an aspect of the natural world and universe that has been repeatedly tested and verified in accordance with the scientific method, using accepted protocols of observation, measurement, and evaluation of results.
Established scientific theories have withstood rigorous scrutiny and embody scientific knowledge.
Stephen Jay Gould wrote that "...facts and theories are different things, not rungs in a hierarchy of increasing certainty.
The meaning of the term scientific theory (often contracted to theory for brevity) as used in the disciplines of science is significantly different from the common vernacular usage of theory.
In everyday speech, theory can imply an explanation that represents an unsubstantiated and speculative guess, whereas in science it describes an explanation that has been tested and is widely accepted as valid.
Some theories are so well-established that they are unlikely ever to be fundamentally changed (for example, scientific theories such as evolution, heliocentric theory, cell theory, theory of plate tectonics, germ theory of disease, etc.).
Scientific theories are testable and make falsifiable predictions.
The defining characteristic of all scientific knowledge, including theories, is the ability to make falsifiable or testable predictions.
It is well-supported by many independent strands of evidence, rather than a single foundation.
The theory of biological evolution is more than "just a theory".
This provides evidence either for or against the hypothesis.
This can take many years, as it can be difficult or complicated to gather sufficient evidence.
The strength of the evidence is evaluated by the scientific community, and the most important experiments will have been replicated by multiple independent groups.
In chemistry, there are many acid-base theories providing highly divergent explanations of the underlying nature of acidic and basic compounds, but they are very useful for predicting their chemical behavior.
Acceptance of a theory does not require that all of its major predictions be tested, if it is already supported by sufficiently strong evidence.
Solutions may require minor or major changes to the theory, or none at all if a satisfactory explanation is found within the theory's existing framework.
If modifications to the theory or other explanations seem to be insufficient to account for the new results, then a new theory may be required.
This is because it is still the best available explanation for many other phenomena, as verified by its predictive power in other contexts.
After the changes, the accepted theory will explain more phenomena and have greater predictive power (if it did not, the changes would not be adopted); this new explanation will then be open to further replacement or modification.
For example, electricity and magnetism are now known to be two aspects of the same phenomenon, referred to as electromagnetism.
This was resolved by the discovery of nuclear fusion, the main energy source of the Sun.
By omitting from special relativity the luminiferous aether, Einstein stated that time dilation and length contraction measured in an object in relative motion is inertial—that is, the object exhibits constant velocity, which is speed with direction, when measured by its observer.
Einstein sought to generalize the invariance principle to all reference frames, whether inertial or accelerating.
Even massless energy exerts gravitational motion on local objects by "curving" the geometrical "surface" of 4D space-time.
However, scientific laws are descriptive accounts of how nature will behave under certain conditions.
A common misconception is that scientific theories are rudimentary ideas that will eventually graduate into scientific laws when enough data and evidence have been accumulated.
Both theories and laws could potentially be falsified by countervailing evidence.
First-order logic is an example of a formal language.
The phenomena explained by the theories, if they could not be directly observed by the senses (for example, atoms and radio waves), were treated as theoretical concepts.
The phrase "the received view of theories" is used to describe this approach.
One can use language to describe a model; however, the theory is the model (or a collection of similar models), and not the description of the model.
The model parameters, e.g., Newton's Law of Gravitation, determine how the positions and velocities change with time.
The word "semantic" refers to the way that a model represents the real world.
Engineering practice makes a distinction between "mathematical models" and "physical models"; the cost of fabricating a physical model can be minimized by first creating a mathematical model using a computer software package, such as a computer aided design tool.
Certain assumptions are necessary for all empirical claims (e.g. the assumption that reality exists).
This may be as simple as observing that the theory makes accurate predictions, which is evidence that any assumptions made at the outset are correct or approximately correct under the conditions tested.
The theory makes accurate predictions when the assumption is valid, and does not make accurate predictions when the assumption is not valid.
The Oxford English Dictionary (OED) and online Wiktionary indicate its Latin source as assumere ("accept, to take to oneself, adopt, usurp"), which is a conjunction of ad- ("to, towards, at") and sumere (to take).
The term was originally employed in religious contexts as in "to receive up into heaven", especially "the reception of the Virgin Mary into heaven, with body preserved from corruption", (1297 CE) but it was also simply used to refer to "receive into association" or "adopt into partnership".
Confirmations should count only if they are the result of risky predictions; that is to say, if, unenlightened by the theory in question, we should have expected an event which was incompatible with the theory—an event which would have refuted the theory.
A theory which is not refutable by any conceivable event is non-scientific.
Some genuinely testable theories, when found to be false, might still be upheld by their admirers—for example by introducing post hoc (after the fact) some auxiliary hypothesis or assumption, or by reinterpreting the theory post hoc in such a way that it escapes refutation.
Popper summarized these statements by saying that the central criterion of the scientific status of a theory is its "falsifiability, or refutability, or testability".
Several philosophers and historians of science have, however, argued that Popper's definition of theory as a set of falsifiable statements is wrong because, as Philip Kitcher has pointed out, if one took a strictly Popperian view of "theory", observations of Uranus when first discovered in 1781 would have "falsified" Newton's celestial mechanics.
Fecundity: "A great scientific theory, like Newton's, opens up new areas of research….
At any time, it raises more questions than it can currently answer.
Like other definitions of theories, including Popper's, Kitcher makes it clear that a theory must include statements that have observational consequences.
It may be set out on paper as a system of rules, and it is the more truly a theory the more completely it can be put down in such terms.
The specific mathematical aspects of classical electromagnetic theory are termed "laws of electromagnetism," reflecting the level of consistent and reproducible evidence that supports them.
An example of the latter might be the radiation reaction force.
A scientist is a person who conducts scientific research to advance knowledge in an area of interest.
Scientists of different eras (and before them, natural philosophers, mathematicians, natural historians, natural theologians, engineers, and others who contributed to the development of science) have had widely different places in society, and the social norms, ethical values, and epistemic virtues associated with scientists—and expected of them—have changed over time as well.
Many proto-scientists from the Islamic Golden Age are considered polymaths, in part because of the lack of anything corresponding to modern scientific disciplines.
Propositions arrived at by purely logical means are completely empty as regards reality.
Descartes was not only a pioneer of analytic geometry but formulated a theory of mechanics and advanced ideas about the origins of animal movement and perception.
He provided a comprehensive formulation of classical mechanics and investigated light and optics.
He discovered that a charge applied to the spinal cord of a frog could generate muscular spasms throughout its body.
Lazzaro Spallanzani is one of the most influential figures in experimental physiology and the natural sciences.
However, there is no formal process to determine who is a scientist and who is not a scientist.
A little over half of the respondents wanted to pursue a career in academia, with smaller proportions hoping to work in industry, government, and nonprofit environments.
They exhibit a strong curiosity about reality.
Some scientists have a desire to apply scientific knowledge for the benefit of people's health, the nations, the world, nature, or industries (academic scientist and industrial scientist).
These include cosmology and biology, especially molecular biology and the human genome project.
The figure included twice as many men as women.
Relevant phenomena include supernova explosions, gamma ray bursts, quasars, blazars, pulsars, and cosmic microwave background radiation.
Astronomy is one of the oldest natural sciences.
In the past, astronomy included disciplines as diverse as astrometry, celestial navigation, observational astronomy, and the making of calendars.
Observational astronomy is focused on acquiring data from observations of astronomical objects.
These two fields complement each other.
Based on strict dictionary definitions, "astronomy" refers to "the study of objects and matter outside the Earth's atmosphere and of their physical and chemical properties," while "astrophysics" refers to the branch of astronomy dealing with "the behavior, physical properties, and dynamic processes of celestial objects and phenomena".
Some fields, such as astrometry, are purely astronomy rather than also astrophysics.
From these observations, early ideas about the motions of the planets were formed, and the nature of the Sun, Moon and the Earth in the Universe were explored philosophically.
A particularly important early development was the beginning of mathematical and scientific astronomy, which began among the Babylonians, who laid the foundations for the later astronomical traditions that developed in many other civilizations.
Greek astronomy is characterized from the start by seeking a rational, physical explanation for celestial phenomena.
Hipparchus also created a comprehensive catalog of 1020 stars, and most of the constellations of the northern hemisphere derive from Greek astronomy.
Georg von Peuerbach (1423–1461) and Regiomontanus (1436–1476) helped make astronomical progress instrumental to Copernicus's development of the heliocentric model decades later.
In 964, the Andromeda Galaxy, the largest galaxy in the Local Group, was described by the Persian Muslim astronomer Abd al-Rahman al-Sufi in his Book of Fixed Stars.
Astronomers during that time introduced many Arabic names now used for individual stars.
Songhai historian Mahmud Kati documented a meteor shower in August 1583.
Kepler was the first to devise a system that correctly described the details of the motion of the planets around the Sun.
The English astronomer John Flamsteed catalogued over 3000 stars, More extensive star catalogues were produced by Nicolas Louis de Lacaille.
This work was further refined by Joseph-Louis Lagrange and Pierre Simon Laplace, allowing the masses of the planets and moons to be estimated from their perturbations.
Stars were proven to be similar to the Earth's own Sun, but with a wide range of temperatures, masses, and sizes.
Theoretical astronomy led to speculations on the existence of objects such as black holes and neutron stars, which have been used to explain such observed phenomena as quasars, pulsars, blazars, and radio galaxies.
Observational astronomy may be categorized according to the corresponding region of the electromagnetic spectrum on which the observations are made.
Although some radio waves are emitted directly by astronomical objects, a product of thermal emission, most of the radio emission that is observed is the result of synchrotron radiation, which is produced when electrons orbit magnetic fields.
Observations from the Wide-field Infrared Survey Explorer (WISE) have been particularly effective at unveiling numerous galactic protostars and their host star clusters.
Images of observations were originally drawn by hand.
Ultraviolet astronomy is best suited to the study of thermal radiation and spectral emission lines from hot blue stars (OB stars) that are very bright in this wave band.
Gamma rays may be observed directly by satellites such as the Compton Gamma Ray Observatory or by specialized telescopes called atmospheric Cherenkov telescopes.
Gravitational-wave astronomy is an emerging field of astronomy that employs gravitational-wave detectors to collect observational data about distant massive objects.
Historically, accurate knowledge of the positions of the Sun, Moon, planets and stars has been essential in celestial navigation (the use of celestial objects to guide navigation) and in the making of calendars.
The measurement of stellar parallax of nearby stars provides a fundamental baseline in the cosmic distance ladder that is used to measure the scale of the Universe.
Analytical models of a process are better for giving broader insight into the heart of what is going on.
The observation of a phenomenon predicted by a model allows astronomers to select between several alternate or conflicting models as the one best able to describe the phenomena.
In some cases, a large amount of inconsistent data over time may lead to the total abandonment of a model.
Because astrophysics is a very broad subject, astrophysicists typically apply many disciplines of physics, including mechanics, electromagnetism, statistical mechanics, thermodynamics, quantum mechanics, relativity, nuclear and particle physics, and atomic and molecular physics.
The word "astrochemistry" may be applied to both the Solar System and the interstellar medium.
The term exobiology is similar.
Observations of the large-scale structure of the Universe, a branch known as physical cosmology, have provided a deep understanding of the formation and evolution of the cosmos.
A hierarchical structure of matter began to form from minute variations in the mass density of space.
Gravitational aggregations clustered into filaments, leaving voids in the gaps.
Various fields of physics are crucial to studying the universe.
Finally, the latter is important for the understanding of the large-scale structure of the cosmos.
As the name suggests, an elliptical galaxy has the cross-sectional shape of an ellipse.
Elliptical galaxies are more commonly found at the core of galactic clusters, and may have been formed through mergers of large galaxies.
Spiral galaxies are typically surrounded by a halo of older stars.
About a quarter of all galaxies are irregular, and the peculiar shapes of such galaxies may be the result of gravitational interaction.
A radio galaxy is an active galaxy that is very luminous in the radio portion of the spectrum, and is emitting immense plumes or lobes of gas.
The large-scale structure of the cosmos is represented by groups and clusters of galaxies.
In the center of the Milky Way is the core, a bar-shaped bulge with what is believed to be a supermassive black hole at its center.
The disk is surrounded by a spheroid halo of older, population II stars, as well as relatively dense concentrations of stars known as globular clusters.
These begin as a compact pre-stellar core or dark nebulae, which concentrate and collapse (in volumes determined by the Jeans length) to form compact protostars.
These clusters gradually disperse, and the stars join the population of the Milky Way.
7–18 Star formation occurs in dense regions of dust and gas, known as giant molecular clouds.
Almost all elements heavier than hydrogen and helium were created inside the cores of stars.
Over time, this hydrogen fuel is completely converted into helium, and the star begins to evolve.
The ejection of the outer layers forms a planetary nebula.
This is an 11-year oscillation in sunspot number.
The Sun has also undergone periodic changes in luminosity that can have a significant impact on the Earth.
Above this layer is a thin region known as the chromosphere.
Above the core is the radiation zone, where the plasma conveys the energy flux by means of radiation.
A solar wind of plasma particles constantly streams outward from the Sun until, at the outermost limit of the Solar System, it reaches the heliopause.
The planets were formed 4.6 billion years ago in the protoplanetary disk that surrounded the early Sun.
The planets continued to sweep up, or eject, the remaining matter during a period of intense bombardment, evidenced by the many impact craters on the Moon.
This process can form a stony or metallic core, surrounded by a mantle and an outer crust.
Some planets and moons accumulate enough heat to drive geologic processes such as volcanism and tectonics.
Astrostatistics is the application of statistics to astrophysics to the analysis of a vast amount of observational astrophysical data.
Cosmochemistry is the study of the chemicals found within the Solar System, including the origins of the elements and variations in the isotope ratios.
Astronomy clubs are located throughout the world and many have programs to help their members set up and complete observational programs including those to observe all the objects in the Messier (110 objects) or Herschel 400 catalogues of points of interest in the night sky.
Most amateurs work at visible wavelengths, but a small minority experiment with wavelengths outside the visible spectrum.
A number of amateur astronomers use either homemade telescopes or use radio telescopes which were originally built for astronomy research but which are now available to amateurs (e.g. the One-Mile Telescope).
Answers to these may require the construction of new ground- and space-based instruments, and possibly new developments in theoretical and experimental physics.
A deeper understanding of the formation of stars and planets is needed.
If so, what is the explanation for the Fermi paradox?
What is the nature of dark matter and dark energy?
How did the first galaxies form?
Astrobiology, formerly known as exobiology, is an interdisciplinary scientific field that studies the origins, early evolution, distribution, and future of life in the universe.
The origin and early evolution of life is an inseparable part of the discipline of astrobiology.
Biochemistry may have begun shortly after the Big Bang, 13.8 billion years ago, during a habitable epoch when the Universe was only 10–17 million years old.
Nonetheless, Earth is the only place in the universe humans know to harbor life.
The term exobiology was coined by molecular biologist and Nobel Prize winner Joshua Lederberg.
The term xenobiology is now used in a more specialized sense, to mean "biology based on foreign chemistry", whether of extraterrestrial or terrestrial (possibly synthetic) origin.
Though once considered outside the mainstream of scientific inquiry, astrobiology has become a formalized field of study.
In 1959, NASA funded its first exobiology project, and in 1960, NASA founded an Exobiology Program, which is now one of four main elements of NASA's current Astrobiology Program.
Advancements in the fields of astrobiology, observational astronomy and discovery of large varieties of extremophiles with extraordinary capability to thrive in the harshest environments on Earth, have led to speculation that life may possibly be thriving on many of the extraterrestrial bodies in the universe.
Missions specifically designed to search for current life on Mars were the Viking program and Beagle 2 probes.
In late 2008, the Phoenix lander probed the environment for past and present planetary habitability of microbial life on Mars, and researched the history of water there.
In November 2011, NASA launched the Mars Science Laboratory mission carrying the Curiosity rover, which landed on Mars at Gale Crater in August 2012.
One is the informed assumption that the vast majority of life forms in our galaxy are based on carbon chemistries, as are all life forms on Earth.
The fact that carbon atoms bond readily to other carbon atoms allows for the building of extremely long and complex molecules.
A third assumption is to focus on planets orbiting Sun-like stars for increased probabilities of planetary habitability.
To that end, a number of instruments designed to detect Earth-sized exoplanets have been considered, most notably NASA's Terrestrial Planet Finder (TPF) and ESA's Darwin programs, both of which have been cancelled.
Drake originally formulated the equation merely as an agenda for discussion at the Green Bank conference, but some applications of the formula had been taken literally and related to simplistic or pseudoscientific arguments.
The discovery of extremophiles, organisms able to survive in extreme environments, became a core research element for astrobiologists, as they are important to understand four areas in the limits of life in planetary context: the potential for panspermia, forward contamination due to human exploration ventures, planetary colonization by humans, and the exploration of extinct and extant extraterrestrial life.
Even life in the ocean depths, where sunlight cannot reach, was thought to obtain its nourishment either from consuming organic detritus rained down from the surface waters or from eating animals that did.
This chemosynthesis revolutionized the study of biology and astrobiology by revealing that life need not be sun-dependent; it only requires water and an energy gradient in order to exist.
Ten hardy organisms selected for the LIFE project, by Amir Alexander Deinococcus radiodurans, Bacillus subtilis, yeast Saccharomyces cerevisiae, seeds from Arabidopsis thaliana ('mouse-ear cress'), as well as the invertebrate animal Tardigrade.
Jupiter's moon, Europa, and Saturn's moon, Enceladus, are now considered the most likely locations for extant extraterrestrial life in the Solar System due to their subsurface water oceans where radiogenic and tidal heating enables liquid water to exist.
The cosmic dust permeating the universe contains complex organic compounds ("amorphous organic solids with a mixed aromatic-aliphatic structure") that could be created naturally, and rapidly, by stars.
PAHs seem to have been formed shortly after the Big Bang, are widespread throughout the universe, and are associated with new stars and exoplanets.
Experimental astroecology investigates resources in planetary soils, using actual space materials in meteorites.
On the largest scale, cosmoecology concerns life in the universe over cosmological times.
Specializations include cosmochemistry, biochemistry and organic geochemistry.
Some regions on Earth, such as the Pilbara in Western Australia and the McMurdo Dry Valleys of Antarctica, are also considered to be geological analogs to regions of Mars, and as such, might be able to provide clues on how to search for past life on Mars.
Indeed, it seems likely that the basic building blocks of life anywhere will be similar to those on Earth, in the generality if not in the detail.
Only two of the natural atoms, carbon and silicon, are known to serve as the backbones of molecules sufficiently large to carry biological information.
The four most likely candidates for life in the Solar System are the planet Mars, the Jovian moon Europa, and Saturn's moons Titan and Enceladus.
At the Martian low temperatures and low pressure, liquid water is likely to be highly saline.
On 11 December 2013, NASA reported the detection of "clay-like minerals" (specifically, phyllosilicates), often associated with organic materials, on the icy crust of Europa.
Some scientists think it possible that these liquid hydrocarbons might take the place of water in living cells different from those on Earth.
There are no known abiotic processes on the planet that could cause its presence.
Yamato 000593, the second largest meteorite from Mars, was found on Earth in 2000.
On 5 March 2011, Richard B. Hoover, a scientist with the Marshall Space Flight Center, speculated on the finding of alleged microfossils similar to cyanobacteria in CI1 carbonaceous meteorites in the fringe Journal of Cosmology, a story widely reported on by mainstream media.
Evidence of perchlorates have been found throughout the solar system, and specifically on Mars.
Improved detection methods and increased observation time will undoubtedly discover more planetary systems, and possibly some more like ours.
The aim is to detect those organisms that are able to survive space travel conditions and to maintain the proliferating capacity.
These stress responses could also allow them to survive in harsh space conditions, although evolution also puts some restrictions on their use as analogues to extraterrestrial life.
The formation of spores allows for it to survive extreme environments while still being able to restart cellular growth.
The two landers were identical, so the same tests were carried out at two places on Mars' surface; Viking 1 near the equator and Viking 2 further north.
In astronomy, extinction is the absorption and scattering of electromagnetic radiation by dust and gas between an emitting astronomical object and the observer.
For stars that lie near the plane of the Milky Way and are within a few thousand parsecs of the Earth, extinction in the visual band of frequencies (photometric system) is roughly 1.8 magnitudes per kiloparsec.
Reddening occurs due to the light scattering off dust and other matter in the interstellar medium.
In most photometric systems filters (passbands) are used from which readings of magnitude of light may take account of latitude and humidity among terrestrial factors.
Broadly speaking, interstellar extinction is strongest at short wavelengths, generally observed by using techniques from spectroscopy.
The amount of extinction can be significantly higher than this in specific directions.
As a result, when computing cosmic distances it can be advantageous to move to star data from the near-infared (of which the filter or passband Ks is quite standard) where the variations and amount of extinction are significantly less, and similar ratios as to R(Ks): 0.49±0.02 and 0.528±0.015 were found respectively by independent groups.
This feature was first observed in the 1960s, but its origin is still not well understood.
In the SMC, more extreme variation is seen with no 2175 Å and very strong far-UV extinction in the star forming Bar and fairly normal ultraviolet extinction seen in the more quiescent Wing.
Finding extinction curves in both the LMC and SMC which are similar to those found in the Milky Way and finding extinction curves in the Milky Way that look more like those found in the LMC2 supershell of the LMC and in the SMC Bar has given rise to a new interpretation.
This extinction has three main components: Rayleigh scattering by air molecules, scattering by particulates, and molecular absorption.
The amount of such extinction is lowest at the observer's zenith and highest near the horizon.
The Drake equation speculates about the existence of sapient life elsewhere in the universe.
This encompasses a search for current and historic extraterrestrial life, and a narrower search for extraterrestrial intelligent life.
Over the years, science fiction communicated scientific ideas, imagined a wide range of possibilities, and influenced public interest in and perspectives of extraterrestrial life.
According to this argument, made by scientists such as Carl Sagan and Stephen Hawking, as well as notable personalities such as Winston Churchill, it would be improbable for life not to exist somewhere other than Earth.
Life may have emerged independently at many places throughout the universe.
At each level of the organism there will be mechanisms in place to eliminate conflict, maintain cooperation, and keep the organism functioning.
Life based on ammonia (rather than water) has been suggested as an alternative, though this solvent appears less suitable than water.
About 95% of living matter is built upon only six elements: carbon, hydrogen, nitrogen, oxygen, phosphorus and sulfur.
The carbon atom has the unique ability to make four strong chemical bonds with other atoms, including other carbon atoms.
According to NASA's 2015 Astrobiology Strategy, "Life on other worlds is most likely to include microbes, and any complex living system elsewhere is likely to have arisen from and be founded upon microbial life.
Rick Colwell, a member of the Deep Carbon Observatory team from Oregon State University, told the BBC: "I think it’s probably reasonable to assume that the subsurface of other planets and their moons are habitable, especially since we’ve seen here on Earth that organisms can function far away from sunlight using the energy provided directly from the rocks deep underground".
The panspermia hypothesis proposes that life elsewhere in the Solar System may have a common origin.
In the 19th century it was again revived in modern form by several scientists, including Jöns Jacob Berzelius (1834), Kelvin (1871), Hermann von Helmholtz (1879) and, somewhat later, by Svante Arrhenius (1903).
One of the early scientific inquires into the topic appeared in an 1878 Scientific American article entitled "Is the Moon Inhabited?"
Warm and pressurized regions in the Moon's interior might still contain liquid water.
There is evidence that Mars had a warmer and wetter past: dried-up riverbeds, polar ice caps, volcanoes, and minerals that form in the presence of water have all been found.
The vapor could have been produced by ice volcanoes or by ice near the surface sublimating (transforming from solid to gas).
It is also possible that Europa could support aerobic macrofauna using oxygen created by cosmic rays impacting its surface ice.
On 11 December 2013, NASA reported the detection of "clay-like minerals" (specifically, phyllosilicates), often associated with organic materials, on the icy crust of Europa.
Some claim to have identified evidence that microbial life has existed on Mars.
In 1996, a controversial report stated that structures resembling nanobacteria were discovered in a meteorite, ALH84001, formed of rock ejected from Mars.
NASA officials soon distanced NASA from the scientists' claims, and Stoker herself backed off from her initial assertions.
It is designed to assess the past and present habitability on Mars using a variety of scientific instruments.
However, significant advances in the ability to find and resolve light from smaller rocky worlds near their stars are necessary before such spectroscopic methods can be used to analyze extrasolar planets.
In August 2011, findings by NASA, based on studies of meteorites found on Earth, suggest DNA and RNA components (adenine, guanine and related organic molecules), building blocks for life as we know it, may be formed extraterrestrially in outer space.
In August 2012, and in a world first, astronomers at Copenhagen University reported the detection of a specific sugar molecule, glycolaldehyde, in a distant star system.
The Kepler space telescope has also detected a few thousand candidate planets, of which about 11% may be false positives.
The most massive planet listed on the NASA Exoplanet Archive is DENIS-P J082303.1-491201 b, about 29 times the mass of Jupiter, although according to most definitions of a planet, it is too massive to be a planet and may be a brown dwarf instead.
One sign that a planet probably already contains life is the presence of an atmosphere with significant amounts of oxygen, since that gas is highly reactive and generally would not last long without constant replenishment.
Even if it is assumed that only one out of a billion of these stars has planets supporting life, there would be some 6.25 billion life-supporting planetary systems in the observable universe.
The earliest recorded assertion of extraterrestrial human life is found in ancient scriptures of Jainism.
Medieval Muslim writers like Fakhr al-Din al-Razi and Muhammad al-Baqir supported cosmic pluralism on the basis of the Qur'an.
Once it became clear that Earth was merely one planet amongst countless bodies in the universe, the theory of extraterrestrial life started to become a topic in the scientific community.
The possibility of extraterrestrials remained a widespread speculation as scientific discovery accelerated.
The idea of life on Mars led British writer H. G. Wells to write the novel The War of the Worlds in 1897, telling of an invasion by aliens from Mars who were fleeing the planet's desiccation.
Belief in extraterrestrial beings continues to be voiced in pseudoscience, conspiracy theories, and popular folklore, notably "Area 51" and legends.
Ward and Brownlee are open to the idea of evolution on other planets that is not based on essential Earth-like characteristics (such as DNA and carbon).
If aliens visit us, the outcome would be much as when Columbus landed in America, which didn't turn out well for the Native Americans", he said.
COSPAR also provides guidelines for planetary protection.
Also, according to the response, there is "no credible information to suggest that any evidence is being hidden from the public's eye."
Top: Light sources of different magnitudes.
Comet Borrelly, the colors show its brightness over the range of three orders of magnitude (right).
The scale is logarithmic and defined such that each step of one magnitude changes the brightness by a factor of the fifth root of 100, or approximately 2.512.
Astronomers use two different definitions of magnitude: apparent magnitude and absolute magnitude.
The absolute magnitude describes the intrinsic luminosity emitted by an object and is defined to be equal to the apparent magnitude that the object would have if it were placed at a certain distance from Earth, 10 parsecs for stars.
The development of the telescope showed that these large sizes were illusory—stars appeared much smaller through the telescope.
The more negative the value, the brighter the object.
Stars that have magnitudes between 1.5 and 2.5 are called second-magnitude; there are some 20 stars brighter than 1.5, which are first-magnitude stars (see the list of brightest stars).
Absolute magnitudes for solar system objects are frequently quoted based on a distance of 1 AU.
The simplest form of technology is the development and use of basic tools.
It has helped develop more advanced economies (including today's global economy) and has allowed the rise of a leisure class.
Examples include the rise of the notion of efficiency in terms of human productivity, and the challenges of bioethics.
The term's meanings changed in the early 20th century when American social scientists, beginning with Thorstein Veblen, translated ideas from the German concept of Technik into "technology."
In 1937, the American sociologist Read Bain wrote that "technology includes all tools, machines, utensils, weapons, instruments, housing, clothing, communicating and transporting devices and the skills by which we produce and use them."
More recently, scholars have borrowed from European philosophers of "technique" to extend the meaning of technology to various forms of instrumental reason, as in Foucault's work on technologies of the self (techniques de soi).
to invent useful things or to solve problems" and "a machine, piece of equipment, method, etc.,
The term is often used to imply a specific field of technology, or to refer to high technology or just consumer electronics, rather than technology as a whole.
In this usage, technology refers to tools and machines that may be used to solve real-world problems.
W. Brian Arthur defines technology in a similarly broad way as "a means to fulfill a human purpose."
When combined with another term, such as "medical technology" or "space technology," it refers to the state of the respective field's knowledge and tools. "
Additionally, technology is the application of mathematics, science, and the arts for the benefit of life as it is known.
Engineering is the goal-oriented process of designing and making tools and systems to exploit natural phenomena for practical human means, often (but not always) using results and techniques from science.
For example, science might study the flow of electrons in electrical conductors by using already-existing tools and knowledge.
The exact relations between science and technology, in particular, have been debated by scientists, historians, and policymakers in the late 20th century, in part because the debate can inform the funding of basic and applied science.
Early humans evolved from a species of foraging hominids which were already bipedal, with a brain mass approximately one third of modern humans.
The invention of polished stone axes was a major advance that allowed forest clearance on a large scale to create farms.
The earliest known use of wind power is the sailing ship; the earliest record of a ship under sail is that of a Nile boat dating to the 8th-millennium BCE.
According to archaeologists, the wheel was invented around 4000 BCE probably independently and nearly simultaneously in Mesopotamia (in present-day Iraq), the Northern Caucasus (Maykop culture) and Central Europe.
More recently, the oldest-known wooden wheel in the world was found in the Ljubljana marshes of Slovenia.
The ancient Sumerians used the potter's wheel and may have invented it.
The first two-wheeled carts were derived from travois and were first used in Mesopotamia and Iran in around 3000 BCE.
A bathtub virtually identical to modern ones was unearthed at the Palace of Knossos.
The primary sewer in Rome was the Cloaca Maxima; construction began on it in the sixth century BCE and it is still in use today.
Medieval technology saw the use of simple machines (such as the lever, the screw, and the pulley) being combined to form more complicated tools, such as the wheelbarrow, windmills and clocks, and a system of universities developed and spread scientific ideas and practices.
Starting in the United Kingdom in the 18th century, the Industrial Revolution was a period of great technological discovery, particularly in the areas of agriculture, manufacturing, mining, metallurgy, and transport, driven by the discovery of steam power and the widespread application of the factory system.
The rise in technology has led to skyscrapers and broad urban areas whose inhabitants rely on motors to transport them and their food supplies.
The 20th century brought a host of innovations.
Information technology subsequently led to the birth in the 1980s of the Internet, which ushered in the current Information Age.
Complex manufacturing and construction techniques and organizations are needed to make and maintain some of the newer technologies, and entire industries have arisen to support and develop succeeding generations of increasingly more complex tools.
Transhumanists generally believe that the point of technology is to overcome barriers, and that what we commonly refer to as the human condition is just another barrier to be surpassed.
They suggest that the inevitable result of such a society is to become evermore technological at the cost of freedom and psychological health.
He hopes to reveal the essence of technology in a way that 'in no way confines us to a stultified compulsion to push on blindly with technology or, what comes to the same thing, to rebel helplessly against it.'
Some of the most poignant criticisms of technology are found in what are now considered to be dystopian literary classics such as Aldous Huxley's Brave New World, Anthony Burgess's A Clockwork Orange, and George Orwell's Nineteen Eighty-Four.
The late cultural critic Neil Postman distinguished tool-using societies from technological societies and from what he called "technopolies," societies that are dominated by the ideology of technological and scientific progress to the exclusion or harm of other cultural practices, values, and world-views.
Nikolas Kompridis has also written about the dangers of new technology, such as genetic engineering, nanotechnology, synthetic biology, and robotics.
Another prominent critic of technology is Hubert Dreyfus, who has published books such as On the Internet and What Computers Still Can't Do.
In his article, Jared Bernstein, a Senior Fellow at the Center on Budget and Policy Priorities, questions the widespread idea that automation, and more broadly, technological advances, have mainly contributed to this growing labor market problem.
He uses two main arguments to defend his point.
Indeed, automation threatens repetitive jobs but higher-end jobs are still necessary because they complement technology and manual jobs that "requires flexibility judgment and common sense" remain hard to replace with machines.
Technology is often considered too narrowly; according to Hughes, "Technology is a creative process involving human ingenuity".
They have often supposed that technology is easily controllable and this assumption has to be thoroughly questioned.
Solutionism is the ideology that every social issue can be solved thanks to technology and especially thanks to the internet.
Benjamin R. Cohen and Gwen Ottinger also discussed the multivalent effects of technology.
The use of basic technology is also a feature of other animal species apart from humans.
The ability to make and use tools was once considered a defining characteristic of the genus Homo.
In 2005, futurist Ray Kurzweil predicted that the future of technology would mainly consist of an overlapping "GNR Revolution" of genetics, nanotechnology and robotics, with robotics being the most important of the three.
Humans have already made some of the first steps toward achieving the GNR revolution.
Some believe that the future of robotics will involve a 'greater than human non-biological intelligence.'
This future shares many similarities with the concept of planned obsolescence, however, planned obsolescence is seen as a "sinister business strategy.'
Genetics have also been explored, with humans understanding genetic engineering to a certain degree.
Others think that genetic engineering will be used to make humans more resistant or completely immune to some diseases.
It is believed by futurists that nanobot technology will allow humans to 'manipulate matter at the molecular and atomic scale.'
In this context, now obsolete, an "engine" referred to a military machine, i.e., a mechanical contraption used in war (for example, a catapult).
The six classic simple machines were known in the ancient Near East.
The lever mechanism first appeared around 5,000 years ago in the Near East, where it was used in a simple balance scale, and to move large objects in ancient Egyptian technology.
The screw, the last of the simple machines to be invented, first appeared in Mesopotamia during the Neo-Assyrian period (911-609) BC.
As one of the officials of the Pharaoh, Djosèr, he probably designed and supervised the construction of the Pyramid of Djoser (the Step Pyramid) at Saqqara in Egypt around 2630–2611 BC.
Kushite ancestors built speos during the Bronze Age between 3700 and 3250 BC.Bloomeries and blast furnaces were also created during the 7th centuries BC in Kush.
Some of Archimedes' inventions as well as the Antikythera mechanism required sophisticated knowledge of differential gearing or epicyclic gearing, two key principles in machine theory that helped design the gear trains of the Industrial Revolution, and are still widely used today in diverse fields such as robotics and automotive engineering.
The spinning wheel was also a precursor to the spinning jenny, which was a key development during the early Industrial Revolution in the 18th century.
He described four automaton musicians, including drummers operated by a programmable drum machine, where they could be made to play different rhythms and different drum patterns.
Aside from these professions, universities were not believed to have had much practical significance to technology.
Canal building was an important engineering work during the early phases of the Industrial Revolution.
He was also a capable mechanical engineer and an eminent physicist.
Smeaton also made mechanical improvements to the Newcomen steam engine.
Samuel Morland, a mathematician and inventor who worked on pumps, left notes at the Vauxhall Ordinance Office on a steam pump design that Thomas Savery read.
Iron merchant Thomas Newcomen, who built the first commercial piston steam engine in 1712, was not known to have any scientific training.
These innovations lowered the cost of iron, making horse railways and iron bridges practical.
With the development of the high pressure steam engine, the power to weight ratio of steam engines made practical steamboats and locomotives possible.
The Industrial Revolution created a demand for machinery with metal parts, which led to the development of several machine tools.
Precision machining techniques were developed in the first half of the 19th century.
The United States census of 1850 listed the occupation of "engineer" for the first time with a count of 2,000.
In 1890, there were 6,000 engineers in civil, mining, mechanical and electrical.
The foundations of electrical engineering in the 1800s included the experiments of Alessandro Volta, Michael Faraday, Georg Ohm and others and the invention of the electric telegraph in 1816 and the electric motor in 1872.
Aeronautical engineering deals with aircraft design process design while aerospace engineering is a more modern term that expands the reach of the discipline by including spacecraft design.
Historically, naval engineering and mining engineering were major branches.
As a result, many engineers continue to learn new material throughout their careers.
It is generally insufficient to build a technically successful product, rather, it must also meet further requirements.
Genrich Altshuller, after gathering statistics on a large number of patents, suggested that compromises are at the heart of "low-level" engineering designs, while at a higher level the best design is one which eliminates the core contradiction causing the problem.
Testing ensures that products will perform as expected.
As well as the typical business application software there are a number of computer aided applications (computer-aided technologies) specifically for engineering.
It enables engineers to create 3D models, 2D drawings, and schematics of their designs.
Access and distribution of all this information is generally organized with the use of product data management software.
By its very nature engineering has interconnections with society, culture and human behavior.
Engineering projects can be subject to controversy.
Engineering is a key driver of innovation and human development.
There are many negative economic and political issues that this can cause, as well as ethical issues.
Scientists may also have to complete engineering tasks, such as designing experimental apparatus or building prototypes.
First, it often deals with areas in which the basic physics or chemistry are well understood, but the problems themselves are too complex to solve in an exact manner.
The former equates an understanding into a mathematical principle while the latter measures variables involved and creates technology.
A physicist would typically require additional and relevant training.
An example of this is the use of numerical approximations to the Navier–Stokes equations to describe aerodynamic flow over an aircraft, or the use of the Finite element method to calculate the stresses in complex components.
Engineers stress innovation and invention.
Since a design has to be realistic and functional, it must have its geometry, dimensions, and characteristics data defined.
Thus they studied mathematics, physics, chemistry, biology and mechanics.
Modern medicine can replace several of the body's functions through the use of artificial organs and can significantly alter the function of the human body through artificial devices such as, for example, brain implants and pacemakers.
Both fields provide solutions to real world problems.
Engineering management or "Management engineering" is a specialized field of management concerned with engineering practice or the engineering industry sector.
Engineers specializing in change management must have in-depth knowledge of the application of industrial and organizational psychology principles and methods.
Artificial intelligence (AI) is intelligence demonstrated by machines, as opposed to the natural intelligence displayed by humans or animals.
AI research has tried and discarded many different approaches during its lifetime, including simulating the brain, modeling human problem solving, formal logic, large databases of knowledge and imitating animal behavior.
The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception and the ability to move and manipulate objects.
AI also draws upon computer science, psychology, linguistics, philosophy, and many other fields.
The study of mechanical or "formal" reasoning began with philosophers and mathematicians in antiquity.
The Church-Turing thesis, along with concurrent discoveries in neurobiology, information theory and cybernetics, this led researchers to consider the possibility of building an electronic brain.
Attendees Allen Newell (CMU), Herbert Simon (CMU), John McCarthy (MIT), Marvin Minsky (MIT) and Arthur Samuel (IBM) became the founders and leaders of AI research.
AI's founders were optimistic about the future: Herbert Simon predicted, "machines will be capable, within twenty years, of doing any work a man can do".
Progress slowed and in 1974, in response to the criticism of Sir James Lighthill and ongoing pressure from the US Congress to fund more productive projects, both the U.S. and British governments cut off exploratory research in AI.
By 1985, the market for AI had reached over a billion dollars.
Faster computers, algorithmic improvements, and access to large amounts of data enabled advances in machine learning and perception; data-hungry deep learning methods started to dominate accuracy benchmarks around 2012.
AI research divided into competing sub-fields that often failed to communicate with each other.
The research was centered in three institutions: Carnegie Mellon University, Stanford, and MIT, and as described below, each one developed its own style of research.
They called their work by several names: e.g. embodied, situated, behavior-based or developmental.
The shared mathematical language permitted a high level of collaboration with more established fields (like mathematics, economics or operations research).
Nowadays results of experiments are often rigorously measurable, and are sometimes (with difficulty) reproducible.
These algorithms proved to be insufficient for solving large reasoning problems because they experienced a "combinatorial explosion": they became exponentially slower as the problems grew larger.
Among the things a comprehensive commonsense knowledge base would contain are: objects, properties, categories and relations between objects; situations, events, states and time; causes and effects; knowledge about knowledge (what we know about what other people know); and many other, less well researched domains.
For example, if a bird comes up in conversation, people typically picture a fist-sized animal that sings and flies.
Almost nothing is simply true or false in the way that abstract logic requires.
Research projects that attempt to build a complete knowledge base of commonsense knowledge (e.g., Cyc) require enormous amounts of laborious ontological engineering—they must be built, by hand, one complicated concept at a time.
They need a way to visualize the future—a representation of the state of the world and be able to make predictions about how their actions will change it—and be able to make choices that maximize the utility (or "value") of available choices.
This calls for an agent that can not only assess its environment and make predictions but also evaluate its predictions and adapt based on its assessment.
Classification is used to determine what category something belongs in, and occurs after a program sees a number of examples of things from several categories.
Computational learning theory can assess learners by computational complexity, by sample complexity (how much data is required), or by other notions of optimization.
Many current approaches use word co-occurrence frequencies to construct syntactic representations of text. "
Modern statistical NLP approaches can combine all these strategies as well as others, and often achieve acceptable accuracy at the page or paragraph level.
A modern mobile robot, when given a small, static, and visible environment, can easily determine its location and map its environment; however, dynamic environments, such as (in endoscopy) the interior of a patient's breathing body, pose a greater challenge.
For example, some virtual assistants are programmed to speak conversationally or even to banter humorously; it makes them appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitate human–computer interaction.
Can intelligent behavior be described using simple, elegant principles (such as logic or optimization)?
Or do we use algorithms that can only give us a "reasonable" solution (e.g., probabilistic methods) but may fall prey to the same kind of inscrutable mistakes that human intuition makes?
Stuart Russell and Peter Norvig observe that most AI researchers "don't care about the strong AI hypothesis—as long as the program works, they don't care whether you call it a simulation of intelligence or real intelligence."
The new intelligence could thus increase exponentially and dramatically surpass humans.
The relationship between automation and employment is complicated.
Subjective estimates of the risk vary widely; for example, Michael Osborne and Carl Benedikt Frey estimate 47% of U.S. jobs are at "high risk" of potential automation, while an OECD report classifies only 9% of U.S. jobs as "high risk".
In the long-term, the scientists have proposed to continue optimizing function while minimizing possible security risks that come along with new technologies.
In his book Superintelligence, philosopher Nick Bostrom provides an argument that artificial intelligence will pose a threat to humankind.
Bostrom also emphasizes the difficulty of fully conveying humanity's values to an advanced AI.
In his book Human Compatible, AI researcher Stuart J. Russell echoes some of Bostrom's concerns while also proposing an approach to developing provably beneficial machines focused on uncertainty and deference to humans, possibly involving inverse reinforcement learning.
The opinion of experts within the field of artificial intelligence is mixed, with sizable fractions both concerned and unconcerned by risk from eventual superhumanly-capable AI.
Facebook CEO Mark Zuckerberg believes AI will "unlock a huge amount of positive things," such as curing disease and increasing the safety of autonomous cars.
Musk also funds companies developing artificial intelligence such as DeepMind and Vicarious to "just keep an eye on what's going on with artificial intelligence.
Research in this area includes machine ethics, artificial moral agents, friendly AI and discussion towards building a human rights framework is also in talks.
The time has come for adding an ethical dimension to at least some machines.
Research in machine ethics is key to alleviating concerns with autonomous systems—it could be argued that the notion of autonomous machines without such a dimension is at the root of all fear concerning machine intelligence.
Humans should not assume machines or robots would treat us favorably because there is no a priori reason to believe that they would be sympathetic to our system of morality, which has evolved along with our particular biology (which AIs would not share).
One proposal to deal with this is to ensure that the first generally intelligent AI is 'Friendly AI' and will be able to control subsequently developed AIs.
I think the worry stems from a fundamental error in not distinguishing the difference between the very real recent advances in a particular aspect of AI and the enormity and complexity of building sentient volitional intelligence."
Regulation is considered necessary to both encourage AI and manage associated risks.
A common trope in these works began with Mary Shelley's Frankenstein, where a human creation becomes a threat to its masters.
Isaac Asimov introduced the Three Laws of Robotics in many books and stories, most notably the "Multivac" series about a super-intelligent computer of the same name.
In the 1980s, artist Hajime Sorayama's Sexy Robots series were painted and published in Japan depicting the actual organic human form with lifelike muscular metallic skins and later "the Gynoids" book followed that was used by or influenced movie makers including George Lucas and other creatives.
Biotechnology is a broad area of biology, involving the use of living systems and organisms to develop or make products.
The American Chemical Society defines biotechnology as the application of biological organisms, systems, or processes by various industries to learning about the science of life and the improvement of the value of materials and organisms such as pharmaceuticals, crops, and livestock.
Bioengineering is the application of the principles of engineering and natural sciences to tissues, cells and molecules.
Through early biotechnology, the earliest farmers selected and bred the best-suited crops, having the highest yields, to produce enough food to support a growing population.
These processes also were included in early fermentation of beer.
In this process, carbohydrates in the grains broke down into alcohols, such as ethanol.
Although the process of fermentation was not fully understood until Louis Pasteur's work in 1857, it is still the first use of biotechnology to convert a food source into another form.
These accounts contributed to Darwin's theory of natural selection.
In 1928, Alexander Fleming discovered the mold Penicillium.
The MOSFET (metal-oxide-semiconductor field-effect transistor) was invented by Mohamed M. Atalla and Dawon Kahng in 1959.
The first BioFET was the ion-sensitive field-effect transistor (ISFET), invented by Piet Bergveld in 1970.
By the mid-1980s, other BioFETs had been developed, including the gas sensor FET (GASFET), pressure sensor FET (PRESSFET), chemical field-effect transistor (ChemFET), reference ISFET (REFET), enzyme-modified FET (ENFET) and immunologically modified FET (IMFET).
Rising demand for biofuels is expected to be good news for the biotechnology sector, with the Department of Energy estimating ethanol usage could reduce U.S. petroleum-derived fuel consumption by up to 30% by 2030.
TCE: The Chemical Engineer, (816), 26–31.
Another example is the designing of transgenic plants to grow under specific environments in the presence (or absence) of chemicals.
On the other hand, some of the uses of green biotechnology involve microorganisms to clean and reduce waste.
As well as the development of hormones, stem cells, antibodies, siRNA and diagnostic tests.
One application is the creation of enhanced seeds that resist extreme environmental conditions of arid regions, which is related to the innovation, creation of agriculture techniques and management of resources.
The purpose of pharmacogenomics is to develop rational means to optimize drug therapy, with respect to the patients' genotype, to ensure maximum efficacy with minimal adverse effects.
Modern biotechnology can be used to manufacture existing medicines relatively easily and cheaply.
Genetic testing allows the genetic diagnosis of vulnerabilities to inherited diseases, and can also be used to determine a child's parentage (genetic mother and father) or in general a person's ancestry.
Most of the time, testing is used to find changes that are associated with inherited disorders.
Biotechnology firms can contribute to future food security by improving the nutrition and viability of urban agriculture.
10% of the world's crop lands were planted with GM crops in 2010.
These techniques have allowed for the introduction of new crop traits as well as a far greater control over a food's genetic structure than previously afforded by methods such as selective breeding and mutation breeding.
These have been engineered for resistance to pathogens and herbicides and better nutrient profiles.
Nonetheless, members of the public are much less likely than scientists to perceive GM foods as safe.
However, opponents have objected to GM crops per se on several grounds, including environmental concerns, whether food produced from GM crops is safe, whether GM crops are needed to address the world's food needs, and economic concerns raised by the fact these organisms are subject to intellectual property law.
There are differences in the regulation of GMOs between countries, with some of the most marked differences occurring between the US and Europe.
The European Union differentiates between approval for cultivation within the EU and approval for import and processing.
Each successful application is generally funded for five years then must be competitively renewed.
Cloning is the process of producing individual organisms with either identical or virtually identical DNA, either by natural or artificial means.
It is used in a wide array of biological experiments and practical applications ranging from genetic fingerprinting to large scale protein production.
Initially, the DNA of interest needs to be isolated to provide a DNA segment of suitable size.
Following ligation the vector with the insert of interest is transfected into cells.
A useful tissue culture technique used to clone distinct lineages of cell lines involves the use of cloning rings (cylinders).
This process is also called "research cloning" or "therapeutic cloning".
Therapeutic cloning is achieved by creating embryonic stem cells in the hopes of treating diseases such as diabetes and Alzheimer's.
The reason why SCNT is used for cloning is because somatic cells can be easily acquired and cultured in the lab.
The oocyte will react to the somatic cell nucleus, the same way it would to a sperm cell's nucleus.
The somatic cells could be used immediately or stored in the laboratory for later use.
This creates a one-cell embryo.
The successfully developed embryos are then placed in surrogate recipients, such as a cow or sheep in the case of farm animals.
Another benefit is SCNT is seen as a solution to clone endangered species that are on the verge of going extinct.
Only three of these embryos survived until birth, and only one survived to adulthood.
However, by 2014 researchers were reporting cloning success rates of seven to eight out of ten and in 2016, a Korean Company Sooam Biotech was reported to be producing 500 cloned embryos per day.
Asexual reproduction is a naturally occurring phenomenon in many species, including most plants and some insects.
As an example, some European cultivars of grapes represent clones that have been propagated for over two millennia.
Many trees, shrubs, vines, ferns and other herbaceous perennials form clonal colonies naturally.
In plants, parthenogenesis means the development of an embryo from an unfertilized egg cell, and is a component process of apomixis.
Such clones are not strictly identical since the somatic cells may contain mutations in their nuclear DNA.
Artificial embryo splitting or embryo twinning, a technique that creates monozygotic twins from a single embryo, is not considered in the same fashion as other methods of cloning.
Dolly's embryo was created by taking the cell and inserting it into a sheep ovum.
She was cloned at the Roslin Institute in Scotland by British scientists Sir Ian Wilmut and Keith Campbell and lived there from her birth in 1996 until her death in 2003 when she was six.
Dolly was publicly significant because the effort showed that genetic material from a specific adult cell, designed to express only a distinct subset of its genes, can be redesigned to grow an entirely new organism.
The first mammalian cloning (resulting in Dolly the sheep) had a success rate of 29 embryos per 277 fertilized eggs, which produced three lambs at birth, one of which lived.
Notably, although the first clones were frogs, no adult cloned frog has yet been produced from a somatic adult nucleus donor cell.
However, other researchers, including Ian Wilmut who led the team that successfully cloned Dolly, argue that Dolly's early death due to respiratory infection was unrelated to problems with the cloning process.
Soviet scientists Chaylakhyan, Veprencev, Sviridova, and Nikitin had the mouse "Masha" cloned.
More akin to artificial formation of twins.
Dog: Snuppy, a male Afghan hound was the first cloned dog (2005).
Water buffalo: Samrupa was the first cloned water buffalo.
Camel: (2009) Injaz, is the first cloned camel.
Goat: (2001) Scientists of Northwest A&F University successfully cloned the first goat which use the adult female cell.
Conducted in China in 2017, and reported in January 2018.
Black-footed ferret: (2020) In 2020, a team of scientists cloned a female named Willa, who died in the mid-1980s and left no living descendants.
It does not refer to the natural conception and delivery of identical twins.
As of right now, scientists have no intention of trying to clone people and they believe their results should spark a wider discussion about the laws and regulations the world needs to regulate cloning.
While many of these views are religious in origin, the questions raised by cloning are faced by secular perspectives as well.
Opponents of cloning have concerns that technology is not yet developed enough to be safe and that it could be prone to abuse (leading to the generation of humans from whom organs and tissues would be harvested), as well as concerns about how cloned individuals could integrate with families and with society at large.
This is also referred to as "Conservation cloning".
These successes provided hope that similar techniques (using surrogate mothers of another species) might be used to clone extinct species.
In 2002, geneticists at the Australian Museum announced that they had replicated DNA of the thylacine (Tasmanian tiger), at the time extinct for about 65 years, using polymerase chain reaction.
In 2003, for the first time, an extinct animal, the Pyrenean ibex mentioned above was cloned, at the Centre of Food Technology and Research of Aragon, using the preserved frozen cell nucleus of the skin samples from 2001 and domestic goat egg-cells.
"Когда вернутся мамонты" ("When the Mammoths Return"), 5 February 2015 (retrieved 6 September 2015) Another problem is the survival of the reconstructed mammoth: ruminants rely on a symbiosis with specific microbiota in their stomachs for digestion.
Because of this, some posited she may have aged more quickly than other naturally born animals, as she died relatively early for a sheep at the age of six.
However, early pregnancy loss and neonatal losses are still greater with cloning than natural conception or assisted reproduction (IVF).
The concept of cloning, particularly human cloning, has featured a wide variety of science fiction works.
Many works depict the artificial creation of humans by a method of growing cells from a tissue or DNA sample; the replication may be instantaneous, or take place through slow growth of human embryos in artificial wombs.
Science fiction films such as The Matrix and Star Wars: Episode II – Attack of the Clones have featured scenes of human foetuses being cultured on an industrial scale in mechanical tanks.
A Number was adapted by Caryl Churchill for television, in a co-production between the BBC and HBO Films.
She grew up always doubtful about the love from her mother, who looked nothing like her and who died nine years before.
In the 1976 Ira Levin novel The Boys from Brazil and its 1978 film adaptation, Josef Mengele uses cloning to create copies of Adolf Hitler.
In Doctor Who, an alien race of armour-clad, warlike beings called Sontarans was introduced in the 1973 serial "The Time Warrior".
The concept of cloned soldiers being bred for combat was revisited in "The Doctor's Daughter" (2008), when the Doctor's DNA is used to create a female warrior called Jenny.
The 2005 Kazuo Ishiguro novel Never Let Me Go and the 2010 film adaption are set in an alternate history in which cloned humans are created for the sole purpose of providing organ donations to naturally born humans, despite the fact that they are fully sentient and self-aware.
In the futuristic novel Cloud Atlas and subsequent film, one of the story lines focuses on a genetically-engineered fabricant clone named Sonmi~451, one of millions raised in an artificial "wombtank", destined to serve from birth.
In the film Us, at some point prior to the 1980s, the US Government creates clones of every citizen of the United States with the intention of using them to control their original counterparts, akin to voodoo dolls.
In the present day, the clones launch a surprise attack and manage to complete a mass-genocide of their unaware counterparts.
Genes have been transferred within the same species, across species (creating transgenic organisms), and even across kingdoms.
Genetic engineers must isolate the gene they wish to insert into the host organism and combine it with other genetic elements, including a promoter and terminator region and often a selectable marker.
Herbert Boyer and Stanley Cohen made the first genetically modified organism in 1973, a bacterium resistant to the antibiotic kanamycin.
The first genetically modified animal to be commercialized was the GloFish (2003) and the first genetically modified animal to be approved for food use was the AquAdvantage salmon in 2015.
Fungi have been engineered with much the same goals.
There are proposals to remove the virulent genes from viruses to create vaccines.
The majority are engineered for herbicide tolerance or insect resistance.
Animals are generally much harder to transform and the vast majority are still at the research stage.
Livestock is modified with the intention of improving economically important traits such as growth rate, quality of meat, milk composition, disease resistance, and survival.
Although human gene therapy is still relatively new, it has been used to treat genetic disorders such as severe combined immunodeficiency, and Leber's congenital amaurosis.
Other concerns are the objectivity and rigor of regulatory authorities, contamination of non-genetically modified food, control of the food supply, patenting of life and the use of intellectual property rights.
Countries have adopted regulatory measures to deal with these concerns.
A broad definition of genetic engineering also includes selective breeding and other means of artificial selection.",
For example, the grain crop triticale was fully developed in a laboratory in 1930 using various techniques to alter its genome.
Modern biotechnology is further defined as "In vitro nucleic acid techniques, including recombinant deoxyribonucleic acid (DNA) and direct injection of nucleic acid into cells or organelles, or fusion of cells beyond the taxonomic family."
The definitions focus on the process more than the product, which means there could be GMOS and non-GMOs with very similar genotypes and phenotypes.
It also poses problems as new processes are developed.
Genetic engineers must isolate the gene they wish to insert into the host organism.
The gene is then combined with other genetic elements, including a promoter and terminator region and a selectable marker.
DNA is generally inserted into animal cells using microinjection, where it can be injected through the cell's nuclear envelope directly into the nucleus, or through the use of viral vectors.
In plants this is accomplished through tissue culture.
Traditionally the new genetic material was inserted randomly within the host genome.
There are four families of engineered nucleases: meganucleases, zinc finger nucleases, transcription activator-like effector nucleases (TALENs), and the Cas9-guideRNA system (adapted from CRISPR).
In 1972 Paul Berg created the first recombinant DNA molecule when he combined DNA from a monkey virus with that of the lambda virus.
The bacteria that had successfully incorporated the plasmid was then able to survive in the presence of kanamycin.
In 1974 Rudolf Jaenisch created a transgenic mouse by introducing foreign DNA into its embryo, making it the world's first transgenic animal.
Mice with genes removed (termed a knockout mouse) were created in 1989.
In 1983 the first genetically engineered plant was developed by Michael W. Bevan, Richard B. Flavell and Mary-Dell Chilton.
In 2000, Vitamin A-enriched golden rice was the first plant developed with increased nutrient value.
The insulin produced by bacteria, branded humulin, was approved for release by the Food and Drug Administration in 1982.
In 1994 Calgene attained approval to commercially release the Flavr Savr tomato, the first genetically modified food.
In 2010, scientists at the J. Craig Venter Institute announced that they had created the first synthetic bacterial genome.
It was released to the US market in 2003.
Genes and other genetic information from a wide range of organisms can be added to a plasmid and inserted into bacteria for storage and modification.
A large number of custom plasmids make manipulating DNA extracted from bacteria relatively easy.
Scientists can easily manipulate and combine genes within the bacteria to create novel or disrupted proteins and observe the effect this has on various molecular systems.
Bacteria have been used in the production of food for a long time, and specific strains have been developed and selected for that work on an industrial scale.
Most food-producing bacteria are lactic acid bacteria, and this is where the majority of research into genetically engineering food-producing bacteria has gone.
The majority are produced in the US and even though regulations are in place to allow production in Europe, as of 2015 no food products derived from bacteria are currently available there.
The bacteria are then harvested and the desired protein purified from them.
Many of these proteins are impossible or difficult to obtain via natural methods and they are less likely to be contaminated with pathogens, making them safer.
Outside of medicine they have been used to produce biofuels.
Ideas include altering gut bacteria so they destroy harmful bacteria, or using bacteria to replace or increase deficient enzymes or proteins.
Enabling the bacteria to form a colony could provide a more long-term solution, but could also raise safety concerns as interactions between bacteria and the human body are less well understood than with traditional drugs.
For over a century bacteria have been used in agriculture.
With advances in genetic engineering, these bacteria have been manipulated for increased efficiency and expanded host range.
Pseudomonas strains of bacteria cause frost damage by nucleating water into ice crystals around themselves.
Other uses for genetically modified bacteria include bioremediation, where the bacteria are used to convert pollutants into a less toxic form.
In the 1980s artist Jon Davis and geneticist Dana Boyd converted the Germanic symbol for femininity (ᛉ) into binary code and then into a DNA sequence, which was then expressed in Escherichia coli.
Researchers can use this to control for various factors; including the target location, insert size, and duration of gene expression.
Although primarily still at trial stages, there has been some successes using gene therapy to replace defective genes.
As of 2018, there are a substantial number of clinical trials underway, including treatments for hemophilia, glioblastoma, chronic granulomatous disease, cystic fibrosis and various cancers.
Herpes simplex viruses make promising vectors, having a carrying capacity of over 30kb and providing long term expression, although they are less efficient at gene delivery than other vectors.
Other viruses that have been used as vectors include alphaviruses, flaviviruses, measles viruses, rhabdoviruses, Newcastle disease virus, poxviruses, and picornaviruses.
This does not affect the viruses infectivity, invokes a natural immune response and there is no chance that they will regain their virulence function, which can occur with some other vaccines.
The most effective vaccine against Tuberculosis, the Bacillus Calmette–Guérin (BCG) vaccine, only provides partial protection.
Other vector-based vaccines have already been approved and many more are being developed.
In 2004, researchers reported that a genetically modified virus that exploits the selfish behaviour of cancer cells might offer an alternative way of killing tumours.
The virus was injected into orange trees to combat citrus greening disease that had reduced orange production by 70% since 2005.
Genetically modified viruses that make the target animals infertile through immunocontraception have been created in the laboratory as well as others that target the developmental stage of the animal.
Genetic modification of the myxoma virus has been proposed to conserve European wild rabbits in the Iberian peninsula and to help regulate them in Australia.
It is possible to engineer bacteriophages to express modified proteins on their surface and join them up in specific patterns (a technique called phage display).
For industrial applications, yeasts combine the bacterial advantages of being a single-celled organism that is easy to manipulate and grow with the advanced protein modifications found in eukaryotes.
One has increased malolactic fermentation efficiency, while the other prevents the production of dangerous ethyl carbamate compounds during fermentation.
Unlike bacteria and viruses they have the advantage of infecting the insects by contact alone, although they are out competed in efficiency by chemical pesticides.
An attractive target for biological control are mosquitos, vectors for a range of deadly diseases, including malaria, yellow fever and dengue fever.
Another strategy is to add proteins to the fungi that block transmission of malaria or remove the Plasmodium altogether.
Many plants are pluripotent, meaning that a single cell from a mature plant can be harvested and under the right conditions can develop into a new plant.
Major advances in tissue culture and plant cellular mechanisms for a wide range of plants has originated from systems developed in tobacco.
Another major model organism relevant to genetic engineering is Arabidopsis thaliana.
In research, plants are engineered to help discover the functions of certain genes.
Unlike mutagenisis, genetic engineering allows targeted removal without disrupting other genes in the organism.
Other strategies include attaching the gene to a strong promoter and see what happens when it is overexpressed, forcing a gene to be expressed in a different location or at different developmental stages.
The first genetically modified ornamentals commercialized altered color.
Other genetically modified ornamentals include Chrysanthemum and Petunia.
The papaya ringspot virus devastated papaya trees in Hawaii in the twentieth century until transgenic papaya plants were given pathogen-derived resistance.
The second generation of crops aimed to improve the quality, often by altering the nutrient profile.
GM crops contribute by improving harvests through reducing insect pressure, increasing nutrient value and tolerating different abiotic stresses.
The majority of GM crops have been modified to be resistant to selected herbicides, usually a glyphosate or glufosinate based one.
A few use the genes that encode for vegetative insecticidal proteins.
Less than one percent of GM crops contained other traits, which include providing virus resistance, delaying senescence and altering the plants composition.
Plants and plant cells have been genetically engineered for production of biopharmaceuticals in bioreactors, a process known as pharming.
Many drugs also contain natural plant ingredients and the pathways that lead to their production have been genetically altered or transferred to other plant species to produce greater volume.
They also pose less risk of being contaminated.
Vaccines are expensive to produce, transport, and administer, so having a system that could produce them locally would allow greater access to poorer and developing areas.
Being stored in plants reduces the long-term cost as they can be disseminated without the need for cold storage, don't need to be purified, and have long term stability.
As of 2018 only three genetically modified animals have been approved, all in the USA.
Canada: Brainwaving The first transgenic mammals were produced by injecting viral DNA into embryos and then implanting the embryos in females.
The development of the CRISPR-Cas9 gene editing system as a cheap and fast way of directly modifying germ cells, effectively halving the amount of time needed to develop genetically modified mammals.
Genetically modified mice have been the most common mammals used in biomedical research, as they are cheap and easy to manipulate.
In 2009, scientists announced that they had successfully transferred a gene into a primate species (marmosets) for the first time.
Stable expression has been accomplished in sheep, pigs, rats and other animals.
Human alpha-1-antitrypsin is another protein that has been produced from goats and is used in treating humans with this deficiency.
Pig lungs from genetically modified pigs are being considered for transplantation into humans.
Animals have been engineered to grow faster, be healthier and resist diseases.
A GM pig called Enviropig was created with the capability of digesting plant phosphorus more efficiently than conventional pigs.
This could potentially benefit mothers who cannot produce breast milk but want their children to have breast milk rather than formula.
There have been suggestions that genetic engineering could be used to bring animals back from extinction.
It has been used to treat genetic disorders such as severe combined immunodeficiency, and Leber's congenital amaurosis.
Germline gene therapy results in any change being inheritable, which has raised concerns within the scientific community.
Aquaculture is a growing industry, currently providing over half the consumed fish worldwide.
Several groups have been developing zebrafish to detect pollution by attaching fluorescent proteins to genes activated by the presence of pollutants.
It was originally developed by one of the groups to detect pollution, but is now part of the ornamental fish trade, becoming the first genetically modified animal to become publicly available as a pet when in 2003 it was introduced for sale in the USA.
Zebrafish are model organisms for developmental processes, regeneration, genetics, behaviour, disease mechanisms and toxicity testing.
GM fish have been developed with promoters driving an over-production of growth hormone for use in the aquaculture industry to increase the speed of development and potentially reduce fishing pressure on wild stocks.
It obtained regulatory approval in 2015, the first non-plant GMO food to be commercialized.
Drosophila have been used to study genetics and inheritance, embryonic development, learning, behavior, and aging.
Malaria-resistant mosquitoes have been developed in the laboratory by inserting a gene that reduces the development of the malaria parasite and then use homing endonucleases to rapidly spread that gene throughout the male population (known as a gene drive).
Another approach is to use a sterile insect technique, whereby males genetically engineered to be sterile out compete viable males, to reduce population numbers.
The approach is similar to the sterile technique tested on mosquitoes, where males are transformed with a gene that prevents any females born from reaching maturity.
In this case a strain of pink bollworm that were sterilized with radiation were genetically engineered to express a red fluorescent protein making it easier for researchers to monitor them.
There is also potential to use the silk producing machinery to make other valuable proteins.
A GM chicken that produces the drug Kanuma, an enzyme that treats a rare condition, in its egg passed US regulatory approval in 2015.
There are proposals to use genetic engineering to control cane toads in Australia.
It is also relatively easy to produce stable transgenic nematodes and this along with RNAi are the major tools used in studying their genes.
Transgenic nematodes have been used to study viruses, toxicology, diseases, and to detect environmental pollutants.
Flatworms have the ability to regenerate themselves from a single cell.
The bristle worm, a marine annelid, has been modified.
The development of a regulatory framework concerning genetic engineering began in 1975, at Asilomar, California.
It is an international treaty that governs the transfer, handling, and use of genetically modified organisms.
Many experiments also need permission from a national regulatory group or legislation.
There is a near-universal system for assessing the relative risks associated with GMOs and other agents to laboratory staff and the community.
Different countries use different nomenclature to describe the levels and can have different requirements for what can be done at each level.
For example, a crop not intended for food use is generally not reviewed by authorities responsible for food safety.
Most countries that do not allow GMO cultivation do permit research using GMOs.
While only a few GMOs have been approved for cultivation in the EU a number of GMOs have been approved for import and processing.
The US policy does not focus on the process as much as other countries, looks at verifiable scientific risks and uses the concept of substantial equivalence.
One of the key issues concerning regulators is whether GM products should be labeled.
The dispute involves consumers, producers, biotechnology companies, governmental regulators, non-governmental organizations, and scientists.
Most concerns are around the health and environmental effects of GMOs.
Nonetheless, members of the public are much less likely than scientists to perceive GM foods as safe.
Gene flow between GM crops and compatible plants, along with increased use of broad-spectrum herbicides, can increase the risk of herbicide resistant weed populations.
In order to address some of these concerns some GMOs have been developed with traits to help control their spread.
Other environmental and agronomic concerns include a decrease in biodiversity, an increase in secondary pests (non-targeted pests) and evolution of resistant insect pests.
The impact of Bt crops on beneficial non-target organisms became a public issue after a 1999 paper suggested they could be toxic to monarch butterflies.
With the ability to genetically engineer humans now possible there are ethical concerns over how far this technology should go, or if it should be used at all.
October 2006 the rigor of the regulatory process, consolidation of control of the food supply in companies that make and sell GMOs, exaggeration of the benefits of genetic modification, or concerns over the use of herbicides with glyphosate.
GMOs arrived on the scene as the public confidence in food safety, attributed to recent food scares such as Bovine spongiform encephalopathy and other scandals involving government regulation of products in Europe, was low.
Genetic engineering, also called genetic modification or genetic manipulation, is the direct manipulation of an organism's genes using biotechnology.
A construct is usually created and used to insert this DNA into the host organism.
The new DNA can be inserted randomly, or targeted to a specific part of the genome.
Rudolf Jaenisch created the first GM animal when he inserted foreign DNA into a mouse in 1974.
Genetically modified food has been sold since 1994, with the release of the Flavr Savr tomato.
In 2016 salmon modified with a growth hormone were sold.
By knocking out genes responsible for certain conditions it is possible to create animal model organisms of human diseases.
The rise of commercialised genetically modified crops has provided economic benefit to farmers in many different countries, but has also been the source of most of the controversy surrounding the technology.
Gene flow, impact on non-target organisms, control of the food supply and intellectual property rights have also been raised as potential issues.
This is much faster, can be used to insert any genes from any organism (even ones from different domains) and prevents other undesirable genes from also being added.
Drugs, vaccines and other products have been harvested from organisms engineered to produce them.
Synthetic biology is an emerging discipline that takes genetic engineering a step further by introducing artificially synthesised material into an organism.
If genetic material from another species is added to the host, the resulting organism is called transgenic.
In 1973 Herbert Boyer and Stanley Cohen created the first transgenic organism by inserting antibiotic resistance genes into the plasmid of an Escherichia coli bacterium.
In 1976 Genentech, the first genetic engineering company, was founded by Herbert Boyer and Robert Swanson and a year later the company produced a human protein (somatostatin) in E.coli.
The insulin produced by bacteria was approved for release by the Food and Drug Administration (FDA) in 1982.
The People's Republic of China was the first country to commercialise transgenic plants, introducing a virus-resistant tobacco in 1992.
In 1995, Bt Potato was approved safe by the Environmental Protection Agency, after having been approved by the FDA, making it the first pesticide producing crop to be approved in the US.
Genetic screens can be carried out to determine potential genes and further tests then used to identify the best candidates.
These segments can then be extracted through gel electrophoresis.
Once isolated the gene is ligated into a plasmid that is then inserted into a bacterium.
These include a promoter and terminator region, which initiate and end transcription.
This ability can be induced in other bacteria via stress (e.g. thermal or electric shock), which increases the cell membrane's permeability to DNA; up-taken DNA can either integrate with the genome or exist as extrachromosomal DNA.
In plants the DNA is often inserted using Agrobacterium-mediated transformation, taking advantage of the Agrobacteriums T-DNA sequence that allows natural insertion of genetic material into plant cells.
In plants this is accomplished through the use of tissue culture.
Selectable markers are used to easily differentiate transformed from untransformed cells.
These tests can also confirm the chromosomal location and copy number of the inserted gene.
The new genetic material can be inserted randomly within the host genome or targeted to a specific location.
The frequency of gene targeting can be greatly enhanced through genome editing.
TALEN and CRISPR are the two most commonly used and each has its own advantages.
Most commercialised GMOs are insect resistant or herbicide tolerant crop plants.
Mouse hybridomas, cells fused together to create monoclonal antibodies, have been adapted through genetic engineering to create human monoclonal antibodies.
Genetic engineering is also used to create animal models of human diseases.
Potential cures can be tested against these mouse models.
In 2015 a virus was used to insert a healthy gene into the skin cells of a boy suffering from a rare skin disease, epidermolysis bullosa, in order to grow, and then graft healthy skin onto 80 percent of the boy's body which was affected by the illness.
There are also concerns that the technology could be used not just for treatment, but for enhancement, modification or alteration of a human beings' appearance, adaptability, intelligence, character or behavior.
He said that twin girls, Lulu and Nana, had been born a few weeks earlier.
Currently, germline modification is banned in 40 countries.
Bacteria are cheap, easy to grow, clonal, multiply quickly, relatively easy to transform and can be stored at -80 °C almost indefinitely.
This could be the effect on the phenotype of the organism, where the gene is expressed or what other genes it interacts with.
In a simple knockout a copy of the desired gene has been altered to make it non-functional.
This allows the experimenter to analyse the defects caused by this mutation and thereby determine the role of particular genes.
The simplest method, and the first to be used, is "alanine scanning", where every position in turn is mutated to the unreactive amino acid alanine.
The process is much the same as that in knockout engineering, except that the construct is designed to increase the function of the gene, usually by providing extra copies of the gene or inducing synthesis of the protein more frequently.
One way to do this is to replace the wild-type gene with a 'fusion' gene, which is a juxtaposition of the wild-type gene with a reporting element such as green fluorescent protein (GFP) that will allow easy visualisation of the products of the genetic modification.
Expression studies aim to discover where and when specific proteins are produced.
Some genes do not work well in bacteria, so yeast, insect cells or mammalians cells can also be used.
Certain genetically modified microbes can also be used in biomining and bioremediation, due to their ability to extract heavy metals from their environment and incorporate them into compounds that are more easily recoverable.
Fungal and virus resistant crops have also been developed or are in development.
In 2016 Salmon have been genetically modified with growth hormones to reach normal adult size much faster.
Soybeans and canola have been genetically modified to produce more healthy oils.
Gene transfer through viral vectors has been proposed as a means of controlling invasive species as well as vaccinating threatened fauna from disease.
Applications of genetic engineering in conservation are thus far mostly theoretical and have yet to be put into practice.
The Asilomar meeting recommended a set of voluntary guidelines regarding the use of recombinant technology.
One hundred and fifty-seven countries are members of the Protocol and many use it as a reference point for their own regulations.
Most countries that do not allow GMO cultivation do permit research.
Emily Marden, Risk and Regulation: U.S. Regulatory Policy on Genetically Modified Food and Agriculture, 44 B.C.L. Rev. 733 (2003) The European Union by contrast has possibly the most stringent GMO regulations in the world.
One of the key issues concerning regulators is whether GM products should be labeled.
These controversies have led to litigation, international trade disputes, and protests, and to restrictive regulation of commercial products in some countries.
Although doubts have been raised, economically most studies have found growing GM crops to be beneficial to farmers.
Many of the environmental impacts regarding GM crops may take many years to be understood and are also evident in conventional agriculture practices.
Few films have informed audiences about genetic engineering, with the exception of the 1978 The Boys from Brazil and the 1993 Jurassic Park, both of which made use of a lesson, a demonstration, and a clip of scientific film.
Nanotechnology, also shortened to nanotech, is the use of matter on an atomic, molecular, and supramolecular scale for industrial purposes.
This definition reflects the fact that quantum mechanical effects are important at this quantum-realm scale, and so the definition shifted from a particular technological goal to a research category inclusive of all types of research and technologies that deal with the special properties of matter which occur below the given size threshold.
The associated research and applications are equally diverse, ranging from extensions of conventional device physics to completely new approaches based upon molecular self-assembly, from developing new materials with dimensions on the nanoscale to direct control of matter on the atomic scale.
The term "nano-technology" was first used by Norio Taniguchi in 1974, though it was not widely known.
The emergence of nanotechnology as a field in the 1980s occurred through convergence of Drexler's theoretical and public work, which developed and popularized a conceptual framework for nanotechnology, and high-visibility experimental advances that drew additional wide-scale attention to the prospects of atomic control of matter.
The microscope's developers Gerd Binnig and Heinrich Rohrer at IBM Zurich Research Laboratory received a Nobel Prize in Physics in 1986.
C60 was not initially described as nanotechnology; the term was used regarding subsequent work with related carbon nanotubes (sometimes called graphene tubes or Bucky tubes) which suggested potential applications for nanoscale electronics and devices.
Decades later, advances in multi-gate technology enabled the scaling of metal–oxide–semiconductor field-effect transistor (MOSFET) devices down to nano-scale levels smaller than 20 nm gate length, starting with the FinFET (fin field-effect transistor), a three-dimensional, non-planar, double-gate MOSFET.
Controversies emerged regarding the definitions and potential implications of nanotechnologies, exemplified by the Royal Society's report on nanotechnology.
These products are limited to bulk applications of nanomaterials and do not involve atomic control of matter.
It was based on gate-all-around (GAA) FinFET technology.
This covers both current work and concepts that are more advanced.
The lower limit is set by the size of atoms (hydrogen has the smallest atoms, which are approximately a quarter of a nm kinetic diameter) since nanotechnology must build its devices from atoms and molecules.
To put that scale in another context, the comparative size of a nanometer to a meter is the same as that of a marble to the size of the earth.
In the "bottom-up" approach, materials and devices are built from molecular components which assemble themselves chemically by principles of molecular recognition.
One example is the increase in surface area to volume ratio altering mechanical, thermal and catalytic properties of materials.
The catalytic activity of nanomaterials also opens potential risks in their interaction with biomaterials.
The concept of molecular recognition is especially important: molecules can be designed so that a specific configuration or arrangement is favored due to non-covalent intermolecular forces.
Such bottom-up approaches should be capable of producing devices in parallel and be much cheaper than top-down methods, but could potentially be overwhelmed as the size and complexity of the desired assembly increases.
Manufacturing in the context of productive nanosystems is not related to, and should be clearly distinguished from, the conventional technologies used to manufacture nanomaterials such as carbon nanotubes and nanoparticles.
It is hoped that developments in nanotechnology will make possible their construction by some other means, perhaps using biomimetic principles.
In general it is very difficult to assemble devices on the atomic scale, as one has to position atoms on other atoms of comparable size and stickiness.
This led to an exchange of letters in the ACS publication Chemical & Engineering News in 2003.
They have constructed at least three distinct molecular devices whose motion is controlled from the desktop with changing voltage: a nanotube nanomotor, a molecular actuator, and a nanoelectromechanical relaxation oscillator.
Nanomaterials with fast ion transport are related also to nanoionics and nanoelectronics.
Nanoscale materials such as nanopillars are sometimes used in solar cells which combats the cost of traditional silicon solar cells.
More generally, molecular self-assembly seeks to use concepts of supramolecular chemistry, and molecular recognition in particular, to cause single-molecule components to automatically arrange themselves into some useful conformation.
Giant magnetoresistance-based hard drives already on the market fit this description, as do atomic layer deposition (ALD) techniques.
Focused ion beams can directly remove material, or even deposit material when suitable precursor gasses are applied at the same time.
These could then be used as single-molecule components in a nanoelectronic device.
Molecular nanotechnology is a proposed approach which involves manipulating single molecules in finely controlled, deterministic ways.
There are hopes for applying nanorobots in medicine.
Because of the discrete (i.e. atomic) nature of matter and the possibility of exponential growth, this stage is seen as the basis of another industrial revolution.
With the decrease in dimensionality, an increase in surface-to-volume ratio is observed.
Although conceptually similar to the scanning confocal microscope developed by Marvin Minsky in 1961 and the scanning acoustic microscope (SAM) developed by Calvin Quate and coworkers in the 1970s, newer scanning probe microscopes have much higher resolution, since they are not limited by the wavelength of sound or light.
However, this is still a slow process because of low scanning velocity of the microscope.
Another group of nanotechnological techniques include those used for fabrication of nanotubes and nanowires, those used in semiconductor fabrication such as deep ultraviolet lithography, electron beam lithography, focused ion beam machining, nanoimprint lithography, atomic layer deposition, and molecular vapor deposition, and further including molecular self-assembly techniques such as those employing di-block copolymers.
Scanning probe microscopy is an important technique both for characterization and synthesis of nanomaterials.
By using, for example, feature-oriented scanning approach, atoms or molecules can be moved around on a surface with scanning probe microscopy techniques.
These techniques include chemical synthesis, self-assembly and positional assembly.
Researchers at Bell Telephone Laboratories like John R. Arthur.
MBE allows scientists to lay down atomically precise layers of atoms and, in the process, build up complex structures.
Bandages are being infused with silver nanoparticles to heal cuts faster.
Nanotechnology may have the ability to make existing medical applications cheaper and easier to use in places like the general practitioner's office and at home.
Platinum is currently used as the diesel engine catalyst in these engines.
Next the oxidation catalyst oxidizes the hydrocarbons and carbon monoxide to form carbon dioxide and water.
Danish company InnovationsFonden invested DKK 15 million in a search for new catalyst substitutes using nanotechnology.
If the catalyst's surface area that is exposed to the exhaust fumes is maximized, efficiency of the catalyst is maximized.
Thus, creating these nanoparticles will increase the effectiveness of the resulting diesel engine catalyst—in turn leading to cleaner exhaust fumes—and will decrease cost.
When designing scaffolds, researchers attempt to mimic the nanoscale features of a cell's microenvironment to direct its differentiation down a suitable lineage.
TSMC began production of a 7 nm process in 2017, and Samsung began production of a 5 nm process in 2018.
For these reasons, some groups advocate that nanotechnology be regulated by governments.
Some nanoparticle products may have unintended consequences.
Inhaling airborne nanoparticles and nanofibers may lead to a number of pulmonary diseases, e.g. fibrosis.
A major study published more recently in Nature Nanotechnology suggests some forms of carbon nanotubes – a poster child for the "nanotechnology revolution" – could be as harmful as asbestos if inhaled in sufficient quantities.
Davies (2008) has proposed a regulatory road map describing steps to deal with these shortcomings.
As a result, some academics have called for stricter application of the precautionary principle, with delayed marketing approval, enhanced labelling and additional safety data development requirements in relation to certain forms of nanotechnology.
Nuclear technology is technology that involves the nuclear reactions of atomic nuclei.
He, Pierre Curie and Marie Curie began investigating the phenomenon.
Some of these kinds of radiation could pass through ordinary matter, and all of them could be harmful in large amounts.
Gradually it was realized that the radiation produced by radioactive decay was ionizing radiation, and that even quantities too small to burn could pose a severe long-term hazard.
As the atom came to be better understood, the nature of radioactivity became clearer.
Alpha decay is when a nucleus releases an alpha particle, which is two protons and two neutrons, equivalent to a helium nucleus.
This type of radiation is the most dangerous and most difficult to block.
The average number of neutrons released per nucleus that go on to fission another nucleus is referred to as k. Values of k larger than 1 mean that the fission reaction is releasing more neutrons than it absorbs, and therefore is referred to as a self-sustaining chain reaction.
If there are enough immediate decays to carry on the chain reaction, the mass is said to be prompt critical, and the energy release will grow rapidly and uncontrollably, usually leading to an explosion.
During the project, the first fission reactors were developed as well, though they were primarily for weapons manufacture and did not generate electricity.
However, if the mass is critical only when the delayed neutrons are included, then the reaction can be controlled, for example by the introduction or removal of neutron absorbers.
When the resulting nucleus is lighter than that of iron, energy is normally released; when the nucleus is heavier than that of iron, energy is generally absorbed.
The remaining abundance of heavy elements, from nickel to uranium and beyond, is due to supernova nucleosynthesis, the R-process.
Hydrogen bombs obtain their enormous destructive power from fusion, but their energy cannot be controlled.
However, both of these devices operate at a net energy loss.
Nuclear fusion was initially pursued only in theoretical stages during World War II, when scientists on the Manhattan Project (led by Edward Teller) investigated it as a method to build a bomb.
Even small nuclear devices can devastate a city by blast, fire and radiation.
Such a weapon must hold one or more subcritical fissile masses stable for deployment, then induce criticality (create a critical mass) for detonation.
One isotope of uranium, namely uranium-235, is naturally occurring and sufficiently unstable, but it is always found mixed with the more stable isotope uranium-238.
Alternatively, the element plutonium possesses an isotope that is sufficiently unstable for this process to be usable.
They detonated the first nuclear weapon in a test code-named "Trinity", near Alamogordo, New Mexico, on July 16, 1945.
In the wake of unprecedented devastation and casualties from a single weapon, the Japanese government soon surrendered, ending World War II.
Just over four years later, on August 29, 1949, the Soviet Union detonated its first fission weapon.
A radiological weapons is a type of nuclear weapon designed to distribute hazardous nuclear material in enemy areas.
While considered useless by a conventional military, such a weapon raises concerns over nuclear terrorism.
The treaty permitted underground nuclear testing.
After signing the Comprehensive Test Ban Treaty in 1996 (which had as of 2011 not entered into force), all of these states have pledged to discontinue all nuclear testing.
Throughout the Cold War, the opposing powers had huge nuclear arsenals, sufficient to kill hundreds of millions of people.
Currently nuclear power provides approximately 15.7% of the world's electricity (in 2004) and is used to propel aircraft carriers, icebreakers and submarines (so far economics and fears in some ports have prevented the use of nuclear power in transport ships).
Medical and dental x-ray imagers use of cobalt-60 or other x-ray sources.
Both contain a small source of 241Am that gives rise to a small constant current.
Another use in insect control is the sterile insect technique, where male insects are sterilized by radiation and released, so they have no offspring, to reduce the population.
The radiation sources used include radioisotope gamma ray sources, X-ray generators and electron accelerators.
As such it is also used on non-food items, such as medical hardware, plastics, tubes for gas-pipelines, hoses for floor-heating, shrink-foils for food packaging, automobile parts, wires and cables (isolation), tires, and even gemstones.
Microorganisms can no longer proliferate and continue their malignant or pathogenic activities.
Plants cannot continue the natural ripening or aging process.
The specialty of processing food by ionizing radiation is the fact, that the energy density per atomic transition is very high, it can cleave molecules and induce ionization (hence the name) which cannot be achieved by mere heating.
However, the use of the term, cold pasteurization, to describe irradiated foods is controversial, because pasteurization and irradiation are fundamentally different processes, although the intended end results can in some cases be similar.
Marie Curie died from aplastic anemia which resulted from her high levels of exposure.
Approximately half of the deaths from Hiroshima and Nagasaki died two to five years afterward from radiation exposure.
A nuclear meltdown refers to the more serious hazard of releasing nuclear material into the surrounding environment.
Military reactors that experienced similar accidents were Windscale in the United Kingdom and SL-1 in the United States.
Another topic of transhumanist research is how to protect humanity against existential risks, such as nuclear war or asteroid collision.
The assertion would lay the intellectual groundwork for the British philosopher Max More to begin articulating the principles of transhumanism as a futurist philosophy in 1990, and organizing in California a school of thought that has since grown into the worldwide transhumanist movement.
In the Discourse, Descartes envisioned a new kind of medicine that could grant both physical immortality and stronger minds.
St. Leon may have provided inspiration for his daughter Mary Shelley's novel Frankenstein.
In particular, he was interested in the development of the science of eugenics, ectogenesis (creating and sustaining life in an artificial environment), and the application of genetics to improve human characteristics, such as health and intelligence.
These ideas have been common transhumanist themes ever since.
In the Material and Man section of the manifesto, Noboru Kawazoe suggests that:After several decades, with the rapid progress of communication technology, every one will have a "brain wave receiver" in his ear, which conveys directly and exactly what other people think about him and vice versa.
In 1966, FM-2030 (formerly F. M. Esfandiary), a futurist who taught "new concepts of the human" at The New School, in New York City, began to identify people who adopt technologies, lifestyles and world views transitional to posthumanity as "transhuman".
FM-2030 and Vita-More soon began holding gatherings for transhumanists in Los Angeles, which included students from FM-2030's courses and audiences from Vita-More's artistic productions.
A particular concern is the equal access to human enhancement technologies across classes and borders.
This left the World Transhumanist Association as the leading international transhumanist organization.
The Mormon Transhumanist Association was founded in 2006.
Transhumanism stresses the evolutionary perspective, including sometimes the creation of a highly intelligent animal species by way of cognitive enhancement (i.e. biological uplift), but clings to a "posthuman future" as the final goal of participant evolution.
While such a "cultural posthumanism" would offer resources for rethinking the relationships between humans and increasingly sophisticated machines, transhumanism and similar posthumanisms are, in this view, not abandoning obsolete concepts of the "autonomous liberal subject", but are expanding its "prerogatives" into the realm of the posthuman.
However, other progressives have argued that posthumanism, whether it be its philosophical or activist forms, amounts to a shift away from concerns about social justice, from the reform of human institutions and from other Enlightenment preoccupations, toward narcissistic longings for a transcendence of the human body in quest of more exquisite ways of being.
Many transhumanists actively assess the potential for future technologies and innovative social systems to improve the quality of all life, while seeking to make the material reality of the human condition fulfill the promise of legal and political equality by eliminating congenital mental and physical barriers.
Some theorists such as Ray Kurzweil think that the pace of technological innovation is accelerating and that the next 50 years may yield not only radical technological advances, but possibly a technological singularity, which may fundamentally change the nature of human beings.
For example, Bostrom has written extensively on existential risks to humanity's future welfare, including ones that could be created by emerging technologies.
To counter this, Hawking emphasizes either self-design of the human genome or mechanical enhancement (e.g., brain-computer interface) to enhance human intelligence and reduce aggression, without which he implies human civilization may be too stupid collectively to survive an increasingly unstable system, resulting in societal collapse.
These thinkers argue that the ability to discuss in a falsification-based way constitutes a threshold that is not arbitrary at which it becomes possible for an individual to speak for themselves in a way that is not dependent on exterior assumptions.
In keeping with this, many prominent transhumanist advocates, such as Dan Agin, refer to transhumanism's critics, on the political right and left jointly, as "bioconservatives" or "bioluddites", the latter term alluding to the 19th century anti-industrialisation social movement that opposed the replacement of human manual labourers by machines.
The same scenario happens when people have certain neural implants that give them an advantage in the work place and in educational aspects.
Immortalism, a moral ideology based upon the belief that radical life extension and technological immortality is possible and desirable, and advocating research and development to ensure its realization.
Mathematics (from Greek: ) includes the study of such topics as quantity (number theory), structure (algebra), space (geometry), and change (analysis).
When mathematical structures are good models of real phenomena, mathematical reasoning can be used to provide insight or predictions about nature.
The research required to solve mathematical problems can take years or even centuries of sustained inquiry.
Mathematics developed at a relatively slow pace until the Renaissance, when mathematical innovations interacting with new scientific discoveries led to a rapid increase in the rate of mathematical discovery that has continued to the present day.
As evidenced by tallies found on bone, in addition to recognizing how to count physical objects, prehistoric peoples may have also recognized how to count abstract quantities, like time—days, seasons, or years.
Beginning in the 6th century BC with the Pythagoreans, with Greek mathematics the Ancient Greeks began a systematic study of mathematics as a subject in its own right.
The greatest mathematician of antiquity is often held to be Archimedes (c. 287–212 BC) of Syracuse.
The Hindu–Arabic numeral system and the rules for the use of its operations, in use throughout the world today, evolved over the course of the first millennium AD in India and were transmitted to the Western world via Islamic mathematics.
The most notable achievement of Islamic mathematics was the development of algebra.
During the early modern period, mathematics began to develop at an accelerating pace in Western Europe.
Perhaps the foremost mathematician of the 19th century was the German mathematician Carl Friedrich Gauss, who made numerous contributions to fields such as algebra, analysis, differential geometry, matrix theory, number theory, and statistics.
Mathematical discoveries continue to be made today.
In particular, mathēmatikḗ tékhnē meant "the mathematical art."
In English, the noun mathematics takes a singular verb.
However, Aristotle also noted a focus on quantity alone may not distinguish mathematics from sciences like physics; in his view, abstraction and studying quantity as a property "separable in thought" from real instances set mathematics apart.
A peculiarity of intuitionism is that it rejects some mathematical ideas considered valid according to other definitions.
Haskell Curry defined mathematics simply as "the science of formal systems".
Popper also noted that "I shall certainly admit a system as empirical or scientific only if it is capable of being tested by experience."
Intuition and experimentation also play a role in the formulation of conjectures in both mathematics and the (other) sciences.
For example, the physicist Richard Feynman invented the path integral formulation of quantum mechanics using a combination of mathematical reasoning and physical insight, and today's string theory, a still-developing scientific theory which attempts to unify the four fundamental forces of nature, continues to inspire new mathematics.
A distinction is often made between pure mathematics and applied mathematics.
As in most areas of study, the explosion of knowledge in the scientific age has led to specialization: there are now hundreds of specialized areas in mathematics and the latest Mathematics Subject Classification runs to 46 pages.
Many mathematicians talk about the elegance of mathematics, its intrinsic aesthetics and inner beauty.
G. H. Hardy in A Mathematician's Apology expressed the belief that these aesthetic considerations are, in themselves, sufficient to justify the study of pure mathematics.
A theorem expressed as a characterization of the object by these features is the prize.
Euler (1707–1783) was responsible for many of the notations in use today.
Unlike natural language, where people can often equate a word (such as cow) with the physical object it corresponds to, mathematical symbols are abstract, lacking any physical analog.
Mathematical language also includes many technical terms such as homeomorphism and integrable that have no meaning outside of mathematics.
Mathematicians refer to this precision of language and logic as "rigor".
This is to avoid mistaken "theorems", based on fallible intuitions, of which many instances have occurred in the history of the subject.
Misunderstanding the rigor is a cause for some of the common misconceptions of mathematics.
On the other hand, proof assistants allow verifying all details that cannot be given in a hand-written proof, and provide certainty of the correctness of long proofs such as that of the Feit–Thompson theorem.
In addition to these main concerns, there are also subdivisions dedicated to exploring links from the heart of mathematics to other fields: to logic, to set theory (foundations), to the empirical mathematics of the various sciences (applied mathematics), and more recently to the rigorous study of uncertainty.
Some disagreement about the foundations of mathematics continues to the present day.
As such, it is home to Gödel's incompleteness theorems which (informally) imply that any effective formal system that contains basic arithmetic, if sound (meaning that all theorems that can be proved are true), is necessarily incomplete (meaning that there are true theorems which cannot be proved in that system).
Modern logic is divided into recursion theory, model theory, and proof theory, and is closely linked to theoretical computer science, as well as to category theory.
Computability theory examines the limitations of various theoretical models of the computer, including the most well-known model—the Turing machine.
Consideration of the natural numbers also leads to the transfinite numbers, which formalize the concept of "infinity".
Thus one can study groups, rings, fields and other abstract systems; together such studies (for structures defined by algebraic operations) constitute the domain of abstract algebra.
Trigonometry is the branch of mathematics that deals with relationships between the sides and the angles of triangles and with the trigonometric functions.
Convex and discrete geometry were developed to solve problems in number theory and functional analysis but now are pursued with an eye on applications in optimization and computer science.
Lie groups are used to study space, structure, and change.
Functions arise here as a central concept describing a changing quantity.
One of many applications of functional analysis is quantum mechanics.
Statisticians (working as part of a research project) "create data that makes sense" with random sampling and with randomized experiments; the design of a statistical sample or experiment specifies the analysis of the data (before the data becomes available).
Numerical analysis studies methods for problems in analysis using functional analysis and approximation theory; numerical analysis includes the study of approximation and discretisation broadly with special concern for rounding errors.
The Chern Medal was introduced in 2010 to recognize lifetime achievement.
This list achieved great celebrity among mathematicians, and at least nine of the problems have now been solved.
The value of Pi was first calculated by him.
It was the Pythagoreans who coined the term "mathematics", and with whom the study of mathematics for its own sake begins.
Because of a political dispute, the Christian community in Alexandria punished her, presuming she was involved, by stripping her naked and scraping off her skin with clamshells (some say roofing tiles).
Funding for translation of scientific texts in other languages was ongoing throughout the reign of certain caliphs, and it turned out that certain scholars became experts in the works they translated and in turn received further support for continuing to develop certain sciences.
A notable feature of many scholars working under Muslim rule in medieval times is that they were often polymaths.
During this period of transition from a mainly feudal and ecclesiastical culture to a predominantly secular one, many notable mathematicians had other occupations: Luca Pacioli (founder of accounting); Niccolò Fontana Tartaglia (notable engineer and bookkeeper); Gerolamo Cardano (earliest founder of probability and binomial expansion); Robert Recorde (physician) and François Viète (lawyer).
British universities of this period adopted some approaches familiar to the Italian and German universities, but as they already enjoyed substantial freedoms and autonomy the changes there had begun with the Age of Enlightenment, the same influences that inspired Humboldt.
Students could conduct research in seminars or laboratories and began to produce doctoral theses with more scientific content.
Mathematicians and applied mathematicians are considered to be two of the STEM (science, technology, engineering, and mathematics) careers.
Actuaries also address financial questions, including those involving the level of pension contributions required to produce a certain retirement income and the way in which a company should invest resources to maximize its return on investments in light of potential risk.
The hieroglyphic system for Egyptian numerals, like the later Roman numerals, descended from tally marks used for counting.
Early number systems that included positional notation were not decimal, including the sexagesimal (base 60) system for Babylonian numerals, and the vigesimal (base 20) system that defined Maya numerals.
Prior to the works of Euclid around 300 BC, Greek studies in mathematics overlapped with philosophical and mystical beliefs.
The ancient Greeks lacked a symbol for zero until the Hellenistic period, and they used three separate sets of symbols as digits: one set for the units place, one for the tens place, and one for the hundreds.
Their long division algorithm was the same, and the digit-by-digit square root algorithm, popularly used as recently as the 20th century, was known to Archimedes (who may have invented it).
The ancient Chinese had advanced arithmetic studies dating from the Shang Dynasty and continuing through the Tang Dynasty, from basic numbers to advanced algebra.
For the hundreds place, they then reused the symbols for the units place, and so on.
The ancient Chinese were the first to meaningfully discover, understand, and apply negative numbers.
His contemporary, the Syriac bishop Severus Sebokht (650 AD) said, "Indians possess a method of calculation that no word can praise enough.
The Arabs also learned this new method and called it hesab.
The flourishing of algebra in the medieval Islamic world, and also in Renaissance Europe, was an outgrowth of the enormous simplification of computation through decimal notation.
Arithmetic expressions must be evaluated according to the intended sequence of operations.
For example, digital computers can reuse existing adding-circuitry and save additional circuits for implementing a subtraction, by employing the method of two's complement for representing the additive inverses, which is extremely easy to implement in hardware (negation).
Multiplication also combines two numbers into a single number, the product.
If the numbers are imagined as lying in a line, multiplication by a number greater than 1, say x, is the same as stretching everything away from 0 uniformly, in such a way that the number 1 itself is stretched to where x was.
Any dividend divided by zero is undefined.
The fundamental theorem of arithmetic was first proven by Carl Friedrich Gauss.
Positional notation (also known as "place-value notation") refers to the representation or encoding of numbers using the same symbol for the different orders of magnitude (e.g., the "ones place", "tens place", "hundreds place") and, with a radix point, using those same symbols to represent fractions (e.g., the "tenths place", "hundredths place").
The use of 0 as a placeholder and, therefore, the use of a positional notation is first attested to in the Jain text from India entitled the Lokavibhâga, dated 458 AD and it was only in the early 13th century that these concepts, transmitted via the scholarship of the Arabic world, were introduced into Europe by Fibonacci using the Hindu–Arabic numeral system.
The result is calculated by the repeated addition of single digits from each number that occupies the same position, proceeding from right to left.
The rightmost digit is the value for the current position, and the result for the subsequent addition of the digits to the left increases by the value of the second (leftmost) digit, which is always one (if not zero).
A multiplication table with ten rows and ten columns lists the results for each pair of digits.
Similar techniques exist for subtraction and division.
In mathematical terminology, this characteristic is defined as closure, and the previous list is described as .
The total in the pence column is 25.
This operation is repeated using the values in the shillings column, with the additional step of adding the value that was carried forward from the pennies column.
One typical booklet that ran to 150 pages tabulated multiples "from one to ten thousand at the various prices from one farthing to one pound".
This study is sometimes known as algorism.
Also, arithmetic was used by Islamic Scholars in order to teach application of the rulings related to Zakat and Irth.
Addition (usually signified by the plus symbol ) is one of the four basic operations of arithmetic, the other three being subtraction, multiplication and division.
In algebra, another area of mathematics, addition can also be performed on abstract objects such as vectors, matrices, subspaces and subgroups.
Using the gerundive suffix -nd results in "addend", "thing to be added".
"Sum" and "summand" derive from the Latin noun summa "the highest, the top" and associated verb summare.
The later Middle English terms "adden" and "adding" were popularized by Chaucer.
As an example, should the expression a + b + c be defined to mean (a + b) + c or a + (b + c)?
Even some nonhuman animals show a limited ability to add, particularly primates.
With additional experience, children learn to add more quickly by exploiting the commutativity of addition by counting up from the larger number, in this case, starting with three and counting "four, five."
Zero: Since zero is the additive identity, adding zero is trivial.
One aligns two decimal fractions above each other, with the decimal point in the same location.
If the addends are the rotation speeds of two shafts, they can be added with a differential.
It made use of a gravity-assisted carry mechanism.
To subtract, the operator had to use the Pascal's calculator's complement, which required as many steps as an addition.
Both XOR and AND gates are straightforward to realize in digital logic allowing the realization of full adder circuits which in turn may be combined into more complex logical operations.
Many implementations are, in fact, hybrids of these last three designs.
Unanticipated arithmetic overflow is a fairly common cause of program errors.
Taken literally, the above definition is an application of the recursion theorem on the partially ordered set N2.
If either a or b is zero, treat it as an identity.
Here, the semigroup is formed by the natural numbers and the group is the additive group of integers.
The commutativity and associativity of real addition are immediate; defining the real number 0 to be the set of negative rationals, it is easily seen to be the additive identity.
One must prove that this operation is well-defined, dealing with co-Cauchy sequences.
The set of integers modulo 2 has just two elements; the addition operation it inherits is known in Boolean logic as the "exclusive or" function.
These give two different generalizations of addition of natural numbers to the transfinite.
There are even more generalizations of multiplication than addition.
In fact, if two nonnegative numbers a and b are of different orders of magnitude, then their sum is approximately equal to their maximum.
It includes the idea of the sum of a single number, which is itself, and the empty sum, which is zero.
Integration is a kind of "summation" over a continuum, or more precisely and generally, over a differentiable manifold.
Linear combinations are especially useful in contexts where straightforward addition would violate some normalization rule, such as mixing of strategies in game theory or superposition of states in quantum mechanics.
Division is one of the four basic operations of arithmetic, the ways that numbers are combined to make new numbers.
Those in which a Euclidean division (with remainder) is defined are called Euclidean domains and include polynomial rings in one indeterminate (which define multiplication and addition over single-variabled formulas).
This division sign is also used alone to represent the division operation itself, as for instance as a label on a key of a calculator.
Distributing the objects several at a time in each round of sharing to each portion leads to the idea of 'chunking' a form of division where one repeatedly subtracts multiples of the divisor from the dividend itself.
A person can use logarithm tables to divide two numbers, by subtracting the two numbers' logarithms, then looking up the antilogarithm of the result.
Some programming languages, such as C, treat integer division as in case 5 above, so the answer is an integer.
Similarly, right division of b by a (written ) is the solution y to the equation .
Examples include matrix algebras and quaternion algebras.
Entry of such an expression into most calculators produces an error message.
Since this replacement reduces the larger of the two numbers, repeating this process gives successively smaller pairs of numbers until the two numbers become equal.
The fact that the GCD can always be expressed in this way is known as Bézout's identity.
With this improvement, the algorithm never requires more steps than five times the number of digits (base 10) of the smaller integer.
The Euclidean algorithm has many theoretical and practical applications.
The Euclidean algorithm may be used to solve Diophantine equations, such as finding numbers that satisfy multiple congruences according to the Chinese remainder theorem, to construct continued fractions, and to find accurate rational approximations to real numbers.
The greatest common divisor is often written as gcd(a, b) or, more simply, as (a, b), although the latter notation is ambiguous, also used for concepts such as an ideal in the ring of integers, which is closely related to GCD.
For example, neither 6 nor 35 is a prime number, since they both have two prime factors: 6 = 2 × 3 and 35 = 5 × 7.
Factorization of large integers is believed to be a computationally very difficult problem, and the security of many widely used cryptographic protocols is based upon its infeasibility.
The set of all integral linear combinations of a and b is actually the same as the set of all multiples of g (mg, where m is an integer).
In other words, multiples of the smaller number rk−1 are subtracted from the larger number rk−2 until the remainder rk is smaller than rk−1.
Therefore, c divides the initial remainder r0, since r0 = a − q0b = mc − q0nc = (m − q0n)c.
We first attempt to tile the rectangle using b-by-b square tiles; however, this leaves an r0-by-b residual rectangle untiled, where r0 < b. We then attempt to tile the residual rectangle with r0-by-r0 square tiles.
The theorem which underlies the definition of the Euclidean division ensures that such a quotient and remainder always exist and are unique.
At the end of the loop iteration, the variable b holds the remainder rk, whereas the variable a holds its predecessor, rk−1.
The mathematician and historian B. L. van der Waerden suggests that Book VII derives from a textbook on number theory written by mathematicians in the school of Pythagoras.
Centuries later, Euclid's algorithm was discovered independently both in India and in China, primarily to solve Diophantine equations that arose in astronomy and making accurate calendars.
The Euclidean algorithm was first described numerically and popularized in Europe in the second edition of Bachet's Problèmes plaisants et délectables (Pleasant and enjoyable problems, 1624).
In the 19th century, the Euclidean algorithm led to the development of new number systems, such as Gaussian integers and Eisenstein integers.
Peter Gustav Lejeune Dirichlet seems to have been the first to describe the Euclidean algorithm as the basis for much of number theory.
For example, Dedekind was the first to prove Fermat's two-square theorem using the unique factorization of Gaussian integers.
Other applications of Euclid's algorithm were developed in the 19th century.
Several novel integer relation algorithms have been developed, such as the algorithm of Helaman Ferguson and R.W. Forcade (1979) and the LLL algorithm.
The players take turns removing m multiples of the smaller pile from the larger.
By allowing u to vary over all possible integers, an infinite family of solutions can be generated from a single solution (x1, y1).
In this field, the results of any mathematical operation (addition, subtraction, multiplication, or division) is reduced modulo 13; that is, multiples of 13 are added or subtracted until the result is brought within the range 0–12.
Now assume that the result holds for all values of N up to M − 1.
For illustration, the probability of a quotient of 1, 2, 3, or 4 is roughly 41.5%, 17.0%, 9.3%, and 5.9%, respectively.
One inefficient approach to finding the GCD of two natural numbers a and b is to calculate all their common divisors; the GCD is then the largest common divisor.
As noted above, the GCD equals the product of the prime factors shared by the two numbers a and b. Present methods for prime factorization are also inefficient; many modern cryptography systems even rely on that inefficiency.
Lehmer's GCD algorithm uses the same general principle as the binary algorithm to speed up GCD computations in arbitrary bases.
The Euclidean algorithm can be used to solve linear Diophantine equations and Chinese remainder problems for polynomials; continued fractions of polynomials can also be defined.
Any Euclidean domain is a unique factorization domain (UFD), although the converse is not true.
A Euclidean domain is always a principal ideal domain (PID), an integral domain in which every ideal is a principal ideal.
Numerators and denominators are also used in fractions that are not common, including compound fractions, complex fractions, and mixed numerals.
The term was originally used to distinguish this type of fraction from the sexagesimal fraction used in astronomy.
This was explained in the 17th century textbook The Ground of Arts.
The product of a fraction and its reciprocal is 1, hence the reciprocal is the multiplicative inverse of a fraction.
The remainder becomes the numerator of the fractional part.
Since 5×17 (= 85) is greater than 4×18 (= 72), the result of comparing is .
Since one third of a quarter is one twelfth, two thirds of a quarter is two twelfth.
Sometimes an infinite repeating decimal is required to reach the same precision.
The Egyptians used Egyptian fractions BC.
Their methods gave the same answer as modern methods.
A modern expression of fractions known as bhinnarasi seems to have originated in India in the work of Aryabhatta, Brahmagupta, and Bhaskara.
In mathematics, modular arithmetic is a system of arithmetic for integers, where numbers "wrap around" when reaching a certain value, called the modulus.
A very practical application is to calculate checksums within serial number identifiers.
RSA and Diffie–Hellman use modular exponentiation.
It is used by the most efficient implementations of polynomial greatest common divisor, exact linear algebra and Gröbner basis algorithms over the integers and the rational numbers.
The modulo operation, as implemented in many programming languages and calculators, is an application of modular arithmetic that is often used in this context.
The method of casting out nines offers a quick check of decimal arithmetic computations performed by hand.
A linear system of congruences can be solved in polynomial time with a form of Gaussian elimination, for details see linear congruence theorem.
The multiplication of integers (including negative numbers), rational numbers (fractions) and real numbers is defined by a systematic generalization of this basic definition.
The product of two measurements is a new type of measurement.
The inverse operation of multiplication is division.
The division of a number other than 0 by itself equals 1.
This implicit usage of multiplication can cause ambiguity when the concatenated variables happen to match the name of another variable, when a variable name in front of a parenthesis can be confused with a function name, or in the correct determination of the order of operations.
The numbers to be multiplied are generally called the "factors".
Also as the result of a multiplication does not depend on the order of the factors, the distinction between "multiplicand" and "multiplier" is useful only at a very elementary level and in some multiplication algorithms, such as the long multiplication.
The result of a multiplication is called a product.
The slide rule allowed numbers to be quickly multiplied to about three places of accuracy.
The general theory is given by dimensional analysis.
The complex numbers do not have an ordering.
Here we have identity 1, as opposed to groups under addition where the identity is typically 0.
To see this, consider the set of invertible square matrices of a given dimension over a given field.
Another fact worth noticing is that the integers under multiplication is not a group—even if we exclude zero.
In mathematics, a percentage (from Latin per centum "by a hundred") is a number or ratio expressed as a fraction of 100.
Computation with these fractions was equivalent to computing percentages.
Whenever communicating about a percentage, it is important to specify what it is relative to (i.e., what is the total that corresponds to 100%).
When speaking of a "10% rise" or a "10% fall" in a quantity, the usual interpretation is that this is relative to the initial value of that quantity.
The same confusion between the different concepts of percent(age) and percentage points can potentially cause a major misunderstanding when journalists report about election results, for example, expressing both new results and differences with earlier results as percentages.
The term has been attributed to Latin per centum.
Grammar and style guides often differ as to how percentages are to be written.
When interest rates are very low, the number 0 is included if the interest rate is less than 1%, e.g. "% Treasury Stock", not "% Treasury Stock".)
Likewise, the winning percentage of a team, the fraction of matches that the club has won, is also usually expressed as a decimal proportion; a team that has a .500 winning percentage has won 50% of their matches.
Subtraction also obeys predictable rules concerning related operations, such as addition and multiplication.
Performing subtraction on natural numbers is one of the simplest numerical tasks.
Formally, the number being subtracted is known as the subtrahend, while the number it is subtracted from is the minuend.
Subtraction" is an English word derived from the Latin verb subtrahere, which in turn is a compound of sub "from under" and trahere "to pull".
From position 3, it takes no steps to the left to stay at 3, so .
To represent such an operation, the line must be extended.
The leading digit "1" of the result is then discarded.
In the ten's place, 0 is less than 1, so the 0 is increased by 10, and the difference with 1, which is 9, is written down in the ten's place.
The subtraction then proceeds in the hundreds place, where 6 is not less than 5, so the difference is written down in the result's hundred's place.
Rather it increases the subtrahend hundred's digit by one.
The answer is 1, and is written down in the result's hundred's place.
This theorem was first conjectured by Pierre de Fermat in 1637 in the margin of a copy of Arithmetica, where he claimed that he had a proof that was too large to fit in the margin.
The five color theorem, which has a short elementary proof, states that five colors suffice to color a map and was proven in the late 19th century; however, proving that four colors suffice turned out to be significantly harder.
It was the first major theorem to be proved using a computer.
Additionally, any map that could potentially be a counterexample must have a portion that looks like one of these 1,936 maps.
It was originally formulated in 1908, by Steinitz and Tietze.
A variety V over a finite field with q elements has a finite number of rational points, as well as points over every finite field with qk elements containing that field.
Originally conjectured by Henri Poincaré, the theorem concerns a space that locally looks like ordinary three-dimensional space but is connected, finite in size, and lacks any boundary (a closed 3-manifold).
After nearly a century of effort by mathematicians, Grigori Perelman presented a proof of the conjecture in three papers made available in 2002 and 2003 on arXiv.
Perelman completed this portion of the proof.
Informally, it asks whether every problem whose solution can be quickly verified by a computer can also be quickly solved by a computer; it is widely conjectured that the answer is no.
It has not been proven which one is false, but it is widely believed that the first conjecture is true and the second one is false.
For instance, the Collatz conjecture, which concerns whether or not certain sequences of integers terminate, has been tested for all integers up to 1.2 × 1012 (over a trillion).
That evidence may be of various kinds, such as verification of consequences of it or strong interconnections with known results.
One method of proof, applicable when there are only a finite number of cases that could lead to counterexamples, is known as "brute force": in this approach, all possible cases are considered and shown not to give counterexamples.
The continuum hypothesis, which tries to ascertain the relative cardinality of certain infinite sets, was eventually shown to be independent from the generally accepted set of Zermelo–Fraenkel axioms of set theory.
Few number theorists doubt that the Riemann hypothesis is true.
The logistic map is a polynomial mapping, often cited as an archetypal example of how chaotic behaviour can arise from very simple non-linear dynamical equations.
Kepler proved that it is the limit of the ratio of consecutive Fibonacci numbers.
For two reasons this representation may cause problems.
For example, the two representations 0.999... and 1 are equivalent in the sense that they represent the same number.
Using computers and supercomputers, some of the mathematical constants, including π, e, and the square root of 2, have been computed to more than one hundred billion digits.
Some constants differ so much from the usual kind that a new notation has been invented to represent them reasonably.
Sometimes, the symbol representing a constant is a whole word.
0 (zero) is a number, and the numerical digit used to represent that number in numerals.
Names for the number 0 in English include zero, nought (UK), naught (US; ), nil, or—in contexts where at least one adjacent digit distinguishes it from the letter "O"—oh or o.
For the simple notion of lacking, the words nothing and none are often used.
It is often called oh in the context of telephone numbers.
The symbol nfr, meaning beautiful, was also used to indicate the base level in drawings of tombs and pyramids, and distances were measured relative to the base line as being above or below this line.
The Babylonian placeholder was not a true zero because it was not used alone, nor was it used at the end of a number.
By AD 150, Ptolemy, influenced by Hipparchus and the Babylonians, was using a symbol for zero in his work on mathematical astronomy called the Syntaxis Mathematica, also known as the Almagest.
This use was repeated in AD525 in an equivalent table, that was translated via the Latin nulla or "none" by Dionysius Exiguus, alongside Roman numerals.
The Lokavibhāga, a Jain text on cosmology surviving in a medieval Sanskrit translation of the Prakrit original, which is internally dated to AD 458 (Saka era 380), uses a decimal place-value system, including a zero.
In 813, al-Khwarizmi used the Hindu numerals in his astronomical tables."
This book was later translated into Latin in the 12th century under the title Algoritmi de numero Indorum.
I pursued my study in depth and learned the give-and-take of disputation.
I have striven to compose this book in its entirety as understandably as I could, dividing it into fifteen chapters.
The nine Indian figures are: 9 8 7 6 5 4 3 2 1.
254–255 include 0 as a natural number, in which case it is the only natural number that is not positive.
As a value or a number, zero is not the same as the digit zero, used in numeral systems with positional notation.
The number 0 may or may not be considered a natural number, but it is an integer, and hence a rational number and a real number (as well as an algebraic number and a complex number).
It cannot be prime because it has an infinite number of factors, and cannot be composite because it cannot be expressed as a product of prime numbers (as 0 must always be one of the factors).
These rules apply for any real or complex number x, unless otherwise stated.
The cardinality function, applied to the empty set, returns the empty set as a value, thereby assigning it 0 elements.
In abstract algebra, 0 is commonly used to denote a zero element, which is a neutral element for addition (if defined on the structure under consideration) and an absorbing element for multiplication (if defined).
For some quantities, the zero level is naturally distinguished from all other levels, whereas for others it is more or less arbitrarily chosen.
It has been shown that a cluster of four neutrons may be stable enough to be considered an atom in its own right.
For example, the elements of an array are numbered starting from 0 in C, so that for an array of n items the sequence of array indices runs from 0 to .
In databases, it is possible for a field not to have a value.
For text fields this is not blank nor the empty string.
Any computation including a null value delivers a null result.
In Formula One, if the reigning World Champion no longer competes in Formula One in the year following their victory in the title race, 0 is given to one of the drivers of the team that the reigning champion won the title with.
Typewriters originally made no distinction in shape between O and 0; some models did not even have a separate key for the digit 0.
The digit 0 with a dot in the center seems to have originated as an option on IBM 3270 displays and has continued with some modern computer typefaces such as Andalé Mono, and in some airline reservation systems.
1 (one, also called unit, and unity) is a number and a numerical digit used to represent that number in numerals.
In conventions of sign where zero is considered neither positive nor negative, 1 is the first and smallest positive integer.
Most if not all properties of 1 can be deduced from this.
It is thus the integer after zero.
It was transmitted to Europe via the Maghreb and Andalusia during the Middle Ages, through scholarly works written in Arabic.
Styles that do not use the long upstroke on digit 1 usually do not use the horizontal stroke through the vertical of the digit 7 either.
By definition, 1 is the magnitude, absolute value, or norm of a unit complex number, unit vector, and a unit matrix (more usually called an identity matrix).
In category theory, 1 is sometimes used to denote the terminal object of a category.
Since the base 1 exponential function (1x) always equals 1, its inverse does not exist (which would be called the logarithm base 1 if it did exist).
Likewise, vectors are often normalized into unit vectors (i.e., vectors of magnitude one), because these often have more desirable properties.
It is also the first and second number in the Fibonacci sequence (0 being the zeroth) and is the first number in many other mathematical sequences.
Nevertheless, abstract algebra can consider the field with one element, which is not a singleton and is not a set at all.
A binary code is a sequence of 1 and 0 that is used in computers for representing any kind of data.
+1 is the electric charge of positrons and protons.
The Neopythagorean philosopher Nicomachus of Gerasa affirmed that one is not a number, but the source of number.
We Are Number One is a 2014 song from the children's TV show LazyTown, which gained popularity as a meme.
In association football (soccer) the number 1 is often given to the goalkeeper.
1 is the lowest number permitted for use by players of the National Hockey League (NHL); the league prohibited the use of 00 and 0 in the late 1990s (the highest number permitted being 98).
Any random sequence of digits contains arbitrarily long subsequences that appear non-random, by the infinite monkey theorem.
Second, since no transcendental number can be constructed with compass and straightedge, it is not possible to "square the circle".
The Indian astronomer Aryabhata used a value of 3.1416 in his Āryabhaṭīya (499 AD).
The Persian astronomer Jamshīd al-Kāshī produced 9 sexagesimal digits, roughly the equivalent of 16 decimal digits, in 1424 using a polygon with 3×228 sides, which stood as the world record for about 180 years.
These avoid reliance on infinite series.
As modified by Salamin and Brent, it is also referred to as the Brent–Salamin algorithm.
This is in contrast to infinite series or iterative algorithms, which retain and use all intermediate digits until the final result is produced.
Such memorization aids are called mnemonics.
The digits are large wooden characters attached to the dome-like ceiling.
A numerical digit is a single symbol used alone (such as "2") or in combinations (such as "25"), to represent numbers in a positional numeral system.
A positional number system has one unique digit for each integer from zero up to, but not including, the radix of the number system.
The original numerals were very similar to the modern ones, even down to the glyphs used to represent digits.
The Mayas used a shell symbol to represent zero.
The Thai numeral system is identical to the Hindu–Arabic numeral system except for the symbols used to represent digits.
They are both base 3 systems.
Several authors in the last 300 years have noted a facility of positional notation that amounts to a modified decimal representation.
For example, 1111 (one thousand, one hundred and eleven) is a repunit.
Besides counting ten fingers, some cultures have counted knuckles, the space between fingers, and toes as well as fingers.
Stone age cultures, including ancient indigenous American groups, used tallies for gambling, personal services, and trade-goods.
Beginning about 3500 BC, clay tokens were gradually replaced by number signs impressed with a round stylus at different angles in clay tablets (originally containers for tokens) which were then baked.
These cuneiform number signs resembled the round number signs they replaced and retained the additive sign-value notation of the round number signs.
Sexagesimal numerals were a mixed radix system that retained the alternating base 10 and base 6 in a sequence of cuneiform vertical wedges and chevrons.
Unique numbers of troops and measures of rice appear as unique combinations of these tallies.
Conventional tallies are quite difficult to multiply and divide.
Jews began using a similar system (Hebrew numerals), with the oldest examples known being coins from around 100 BC.
The Maya of Central America used a mixed base 18 and base 20 system, possibly inherited from the Olmec, including advanced features such as positional notation and a zero.
Knowledge of the encodings of the knots and colors was suppressed by the Spanish conquistadors in the 16th century, and has not survived although simple quipu-like recording devices are still used in the Andean region.
Zero was first used in India in the 7th century CE by Brahmagupta.
Arabic mathematicians extended the system to include decimal fractions, and Muḥammad ibn Mūsā al-Ḵwārizmī wrote an important work about it in the 9th century.
The binary system (base 2), was propagated in the 17th century by Gottfried Leibniz.
The variables for which the equation has to be solved are also called unknowns, and the values of the unknowns that satisfy the equality are called solutions of the equation.
A conditional equation is only true for particular values of the variables.
Very often the right-hand side of an equation is assumed to be zero.
An equation is analogous to a scale into which weights are placed.
This is the starting idea of algebraic geometry, an important area of mathematics.
To solve equations from either family, one uses algorithmic or geometric techniques that originate from linear algebra or mathematical analysis.
These equations are difficult in general; one often searches just to find the existence or absence of a solution, and, if they exist, to count the number of solutions.
In the illustration, x, y and z are all different quantities (in this case real numbers) represented as circular weights, and each of x, y, and z has a different weight.
Hence, the equation with R unspecified is the general equation for the circle.
The process of finding the solutions, or, in case of parameters, expressing the unknowns in terms of the parameters, is called solving the equation.
Multiplying or dividing both sides of an equation by a non-zero quantity.
An algebraic equation is univariate if it involves only one variable.
In mathematics, the theory of linear systems is the basis and a fundamental part of linear algebra, a subject which is used in most parts of modern mathematics.
This formalism allows one to determine the positions and the properties of the focuses of a conic.
This point of view, outlined by Descartes, enriches and modifies the type of geometry conceived of by the ancient Greek mathematicians.
An exponential Diophantine equation is one for which exponents of the terms of the equation can be unknowns.
Modern algebraic geometry is based on more abstract techniques of abstract algebra, especially commutative algebra, with the language and the problems of geometry.
A point of the plane belongs to an algebraic curve if its coordinates satisfy a given polynomial equation.
In pure mathematics, differential equations are studied from several different perspectives, mostly concerned with their solutions — the set of functions that satisfy the equation.
Linear differential equations, which have solutions that can be added and multiplied by coefficients, are well-defined and understood, and exact closed-form solutions are obtained.
PDEs can be used to describe a wide variety of phenomena such as sound, heat, electrostatics, electrodynamics, fluid flow, elasticity, or quantum mechanics.
A solution is an assignment of values to the unknown variables that makes the equality in the equation true.
The set of all solutions of an equation is its solution set.
Depending on the context, solving an equation may consist to find either any solution (finding a single solution is enough), all solutions, or a solution that satisfies further properties, such as belonging to a given interval.
In this case, the solutions cannot be listed.
The variety in types of equations is large, and so are the corresponding methods.
This may be due to a lack of mathematical knowledge; some problems were only solved after centuries of effort.
Polynomials appear in many areas of mathematics and science.
Many authors use these two words interchangeably.
Formally, the name of the polynomial is P, not P(x), but the use of the functional notation P(x) dates from a time when the distinction between a polynomial and the associated function was unclear.
However, one may use it over any domain where addition and multiplication are defined (that is, any ring).
Polynomials of small degree have been given specific names.
The polynomial 0, which may be considered to have no terms at all, is called the zero polynomial.
Because the degree of a non-zero polynomial is the largest degree of any one term, this polynomial has degree two.
Polynomials can be classified by the number of terms with nonzero coefficients, so that a one-term polynomial is called a monomial, a two-term polynomial is called a binomial, and a three-term polynomial is called a trinomial.
When it is used to define a function, the domain is not so restricted.
A polynomial in one indeterminate is called a univariate polynomial, a polynomial in more than one indeterminate is called a multivariate polynomial.
In the case of the field of complex numbers, the irreducible factors are linear.
If the degree is higher than one, the graph does not have any asymptote.
In elementary algebra, methods such as the quadratic formula are taught for solving all first degree and second degree polynomial equations in one variable.
However, root-finding algorithms may be used to find numerical approximations of the roots of a polynomial expression of any degree.
Since the 16th century, similar formulas (using cube roots in addition to square roots), but much more complicated are known for equations of degree three and four (see cubic equation and quartic equation).
In 1830, Évariste Galois proved that most equations of degree higher than four cannot be solved by radicals, and showed that for each equation, one may decide whether it is solvable by radicals, and, if it is, solve it.
Nevertheless, formulas for solvable equations of degrees 5 and 6 have been published (see quintic function and sextic equation).
The most efficient algorithms allow solving easily (on a computer) polynomial equations of degree higher than 1,000 (see Root-finding algorithm).
For a set of polynomial equations in several unknowns, there are algorithms to decide whether they have a finite number of complex solutions, and, if this number is finite, for computing the solutions.
A polynomial equation for which one is interested only in the solutions which are integers is called a Diophantine equation.
The coefficients may be taken as real numbers, for real-valued functions.
This equivalence explains why linear combinations are called polynomials.
In the case of coefficients in a ring, "non-constant" must be replaced by "non-constant or non-unit" (both definitions agree in the case of coefficients in a field).
When the coefficients belong to integers, rational numbers or a finite field, there are algorithms to test irreducibility and to compute the factorization into irreducible polynomials (see Factorization of polynomials).
The characteristic polynomial of a matrix or linear operator contains information about the operator's eigenvalues.
However, the elegant and practical notation we use today only developed beginning in the 15th century.
This "completes the square", converting the left side into a perfect square.
Descartes' theorem states that for every four kissing (mutually tangent) circles, their radii satisfy a particular quadratic equation.
Babylonian mathematicians from circa 400 BC and Chinese mathematicians from circa 200 BC used geometric methods of dissection to solve quadratic equations with positive roots.
Euclid, the Greek mathematician, produced a more abstract geometrical method around 300 BC.
Al-Khwarizmi goes further in providing a full solution to the general quadratic equation, accepting one or two numerical answers for every quadratic equation, while providing geometric proofs in the process.
Abū Kāmil Shujā ibn Aslam (Egypt, 10th century) in particular was the first to accept irrational numbers (often in the form of a square root, cube root or fourth root) as solutions to quadratic equations or as coefficients in an equation.
He used a prime meridian through the Canary Islands, so that all longitude values would be positive.
Hindu and Muslim astronomers continued to develop these ideas, adding many new locations and often improving on Ptolemy's data.
In the later Middle Ages, interest in geography revived in the west, as travel increased, and Arab scholarship began to be known through contact with Spain and North Africa.
Christopher Columbus made two attempts to use lunar eclipses to discover his longitude, the first in Saona Island, on 14 September 1494 (second voyage), and the second in Jamaica on 29 February 1504 (fourth voyage).
Initially an observation device, developments over the next half century transformed it into an accurate measurement tool.
On land, the period from the development of telescopes and pendulum clocks until the mid 18th-Century saw a steady increase in the number of places whose longitude had been determined with reasonable accuracy, often with errors of less than a degree, and nearly always within 2-3°.
Making accurate observations in an ocean swell is much harder than on land, and pendulum clocks do not work well in these conditions.
It offered two levels of rewards, for solutions within 1° and 0.5°.
This work was supported and rewarded with thousands of pounds from the Board of Longitude, but he fought to receive money up to the top reward of £20,000, finally receiving an additional payment in 1773 after the intervention of parliament.
Lunar distances came into general use after 1790.
It was quickly realised that the telegraph could be used to transmit a time signal for longitude determination.
The Survey established chains of mapped locations through Central and South America, and the West Indies, and as far as Japan and China in the years 1874–90.
This changed when wireless telegraphy became available in the early 20th-Century.
Radio navigation systems came into general use after World War II.
With the exception of magnetic declination, all proved practicable methods.
Longitude at a point may be determined by calculating the time difference between that at its location and Coordinated Universal Time (UTC).
The word near is used because the point might not be at the centre of the time zone; also the time zones are defined politically, so their centres and boundaries often do not lie on meridians at multiples of 15°.
The international standard convention (ISO 6709)—that East is positive—is consistent with a right-handed Cartesian coordinate system, with the North Pole up.
They have since shifted to the standard approach.
The geoid is the shape that the ocean surface would take under the influence of the gravity of Earth, including gravitational attraction and Earth's rotation, if other influences such as winds and tides were absent.
It can be known only through extensive gravitational measurements and calculations.
Although the physical Earth has excursions of +8,848 m (Mount Everest) and −10,984 (Marianas Trench), the geoid's deviation from an ellipsoid ranges from +85 m (Iceland) to −106 m (southern India), less than 200 m total.
If the continental land masses were crisscrossed by a series of tunnels or canals, the sea level in those canals would also very nearly coincide with the geoid.
That means that when traveling by ship, one does not notice the undulations of the geoid; the local vertical (plumb line) is always perpendicular to the geoid and the local horizon tangential to it.
That is because GPS satellites, orbiting about the center of gravity of the Earth, can measure heights only relative to a geocentric reference ellipsoid.
Modern GPS receivers have a grid implemented in their software by which they obtain, from the current position, the height of the geoid (e.g. the EGM-96 geoid) over the World Geodetic System (WGS) ellipsoid.
If that sphere were then covered in water, the water would not be the same height everywhere.
This is why many handheld GPS receivers have built-in undulation lookup tables to determine the height above sea level.
The first products based on GOCE satellite data became available online in June 2010, through the European Space Agency (ESA)’s Earth observation user services tools.
The geoid is a particular equipotential surface, and is somewhat involved to compute.
A globe is a spherical model of Earth, of some other celestial body, or of the celestial sphere.
A model globe of the celestial sphere is called a celestial globe.
It might show nations and major cities and the network of latitude and longitude lines.
Typically, it will also divide the celestial sphere into constellations.
The first known mention of a globe is from Strabo, describing the Globe of Crates from about 150 BC.
Many globes are made with a circumference of one metre, so they are models of the Earth at a scale of 1:40 million.
Most modern globes are also imprinted with parallels and meridians, so that one can tell the approximate coordinates of a specific location.
Early terrestrial globes depicting the entirety of the Old World were constructed in the Islamic world.
Behaim was a German mapmaker, navigator, and merchant.
Before constructing the globe, Behaim had traveled extensively.
Another early globe, the Hunt–Lenox Globe, ca.
It may be the oldest globe to show the New World.
A facsimile globe showing America was made by Martin Waldseemueller in 1507.
Globus IMP, electro-mechanical devices including five-inch globes have been used in Soviet and Russian spacecraft from 1961 to 2002 as navigation instruments.
This method of globe making was illustrated in 1802 in an engraving in The English Encyclopedia by George Kearsley .
This is placed in a machine which molds the disk into a hemispherical shape.
These globes were “enormous” and very costly.
The latter has a Soviet bullet hole through Germany.
A great circle, also known as an orthodrome, of a sphere is the intersection of the sphere and a plane that passes through the center point of the sphere.
This special case of a circle of a sphere is in opposition to a small circle, that is, the intersection of the sphere and a plane that does not pass through the center.
The exception is a pair of antipodal points, for which there are infinitely many great circles.
The length of the minor arc of a great circle is taken as the distance between two points on a surface of a sphere in Riemannian geometry where such great circles are called Riemannian circles.
Another great circle is the one that divides the land and water hemispheres.
In cartography, a map projection is a way to flatten a globe's surface into a plane in order to make a map.
Depending on the purpose of the map, some distortions are acceptable and others are not; therefore, different map projections exist in order to preserve some properties of the sphere-like body at the expense of other properties.
Projections are a subject of several pure mathematical fields, including differential geometry, projective geometry, and manifolds.
Rather, any mathematical function that transforms coordinates from the curved surface distinctly and smoothly to the plane is a projection.
The Earth and other large celestial bodies are generally better modeled as oblate spheroids, whereas small objects such as asteroids often have irregular shapes.
Because the curved Earth's surface is not isometric to a plane, preservation of shapes inevitably leads to a variable scale and, consequently, non-proportional presentation of areas.
The purpose of the map determines which projection should form the base for the map.
Data sets are geographic information; their collection depends on the chosen datum (model) of the Earth.
Like Tissot's indicatrix, the Goldberg-Gott indicatrix is based on infinitesimals, and depicts flexion and skewness (bending and lopsidedness) distortions.
Sometimes spherical triangles are used.
Another way to visualize local distortion is through grayscale or color gradations whose shade represents the magnitude of the angular deformation or areal inflation.
Because the Earth's actual shape is irregular, information is lost in this step.
To compare, one cannot flatten an orange peel without tearing and warping it.)
Tangent means the surface touches but does not slice through the globe; secant means the surface does slice through the globe.
If these lines are a parallel of latitude, as in conical projections, it is called a standard parallel.
This applies for any cylindrical or pseudocylindrical projection in normal aspect.
Scale is constant along all straight lines radiating from a particular geographic location.
Whether spherical or ellipsoidal, the principles discussed hold without loss of generality.
The ellipsoidal model is commonly used to construct topographic maps and for other large- and medium-scale maps that need to accurately depict the land surface.
Compared to the best fitting ellipsoid, a geoidal model would change the characterization of important properties such as distance, conformality and equivalence.
For irregular planetary bodies such as asteroids, however, sometimes models analogous to the geoid are used to project maps from.
The projections are described in terms of placing a gigantic surface in contact with the Earth, followed by an implied scaling operation.
Where the light source emanates along the line described in this last constraint is what yields the differences between the various "natural" cylindrical projections.
This cylinder is wrapped around the Earth, projected onto, and then unrolled.
North-south distances neither stretched nor compressed (1): equirectangular projection or "plate carrée".
Since this projection scales north-south distances by the reciprocal of east-west stretching, it preserves area at the expense of shapes.
Other meridians are longer than the central meridian and bow outward, away from the central meridian.
Therefore, meridians are equally spaced along a given parallel.
The resulting conic map has low distortion in scale, shape, and area near those standard parallels.
Can be constructed from a point of perspective an infinite distance from the tangent point; r(d) = c sin .
Near-sided perspective projection, which simulates the view from space at a finite distance and therefore shows less than a full hemisphere, such as used in The Blue Marble 2012).
The special point or points may get stretched into a line or curve segment when projected.
Azimuthal equidistant: Distances from the center and edge are preserved.
Thus, many projections exist to serve the many uses of maps and their vast range of scales.
Reference maps of the world often appear on compromise projections.
The Mercator projection is a cylindrical map projection presented by Flemish geographer and cartographer Gerardus Mercator in 1569.
As a side effect, the Mercator projection inflates the size of objects away from the equator.
However, given the geometry of a sundial, these maps may well have been based on the similar central cylindrical projection, a limiting case of the gnomonic projection, which is the basis for a sundial.
However, this was a simple, and common, case of misidentification.
Mercator titled the map : "A new and augmented description of Earth corrected for the use of sailors".
Various hypotheses have been tendered over the years, but in any case Mercator's friendship with Pedro Nunes and his access to the loxodromic tables Nunes created likely aided his efforts.
However, the mathematics involved were developed but never published by mathematician Thomas Harriot starting around 1589.
Two main problems prevented its immediate application: the impossibility of determining the longitude at sea with adequate accuracy and the fact that magnetic directions, instead of geographical directions, were used in navigation.
However, it did not begin to dominate world maps until the 19th century, when the problem of position determination had been largely solved.
Due to these pressures, publishers gradually reduced their use of the projection over the course of the 20th century.
In accomplishing this, the unavoidable east–west stretching of the map, which increases as distance away from the equator increases, is accompanied in the Mercator projection by a corresponding north–south stretching, so that at every point location the east–west scale is the same as the north–south scale, making it a conformal map projection.
At latitudes greater than 70° north or south the Mercator projection is practically unusable, because the linear scale becomes infinitely large at the poles.
Ellesmere Island on the north of Canada's Arctic archipelago looks about the same size as Australia, although Australia is over 39 times as large.
Greenland's real area is comparable to the Democratic Republic of the Congo's alone.
Alaska appears to be the same size as Australia, although Australia is actually 4½ times as large.
Sweden appears much larger than Madagascar.
A World Map on a Regular Icosahedron by Gnomonic Projection."
As a result of these criticisms, modern atlases no longer use the Mercator projection for world maps or for areas distant from the equator, preferring other cylindrical projections, or forms of equal-area projection.
Arno Peters stirred controversy beginning in 1972 when he proposed what is now usually called the Gall–Peters projection to remedy the problems of the Mercator, claiming it to be his own original work without referencing prior work by cartographers such as Gall's work from 1855.
The range for a amongst the possible choices is about 35 km, but for small scale (large region) applications this variation may be ignored, and mean values of 6,371 km and 40,030 km may be taken for the radius and circumference respectively.
A cylindrical map projection is specified by formulae linking the geographic coordinates of latitude φ and longitude λ to Cartesian coordinates on the map with origin on the equator and x-axis along the equator.
Since the cylinder is tangential to the globe at the equator, the scale factor between globe and cylinder is unity on the equator but nowhere else.
The difference (λ − λ0) is in radians.
Even more extreme truncations have been used: a Finnish school atlas was truncated at approximately 76°N and 56°S, an aspect ratio of 1.97.
Narrower strips are better: sec 8° = 1.01, so a strip of width 16° (centred on the equator) is accurate to within 1% or 1 part in 100.
The value of e2 is about 0.006 for all reference ellipsoids.)
For the above model 1 cm corresponds to 1,500 km at a latitude of 60°.
This chord subtends an angle at the centre equal to 2arcsin(cos φ sin ) and the great circle distance between A and B is 2a arcsin(cos φ sin ).)
For other bodies a fixed surface feature is usually referenced, which for Mars is the meridian passing through the crater Airy-0.
By convention for the Earth, Moon, and Sun it is expressed in degrees ranging from −180° to +180° For other bodies a range of 0° to 360° is used.
The scale of a map is the ratio of a distance on the map to the corresponding distance on the ground.
The first way is the ratio of the size of the generating globe to the size of the Earth.
Many maps state the nominal scale and may even display a bar scale (sometimes merely called a 'scale') to represent it.
In this case 'scale' means the scale factor (= point scale = particular scale).
The map projection becomes critical in understanding how scale varies throughout the map.
This is a survey of virtually all known projections from antiquity to 1993.
Small scale refers to world maps or maps of large regions such as continents or large nations.
Large-scale maps show smaller areas in more detail, such as county maps or town plans might.
However, as explained above, cartographers use the term "large scale" to refer to less extensive maps – those that show a smaller area.
This is commonly illustrated by the impossibility of smoothing an orange peel onto a flat surface without tearing and deforming it.
Conversely isotropic scale factors across the map imply a conformal projection.
The qualification 'small' means that at some given accuracy of measurement no change can be detected in the scale factor over the element.
We say that these coordinates define the projection map which must be distinguished logically from the actual printed (or viewed) maps.
Since the point scale varies with position and direction the projection of the circle on the projection will be distorted.
Superimposing these distortion ellipses on the map projection conveys the way in which the point scale is changing over the map.
The ratio of the major axis to the minor axis is .
The scale is true (k=1) on the equator so that multiplying its length on a printed map by the inverse of the RF (or principal scale) gives the actual circumference of the Earth.
The top plot shows the isotropic Mercator scale function: the scale on the parallel is the same as the scale on the meridian.
Therefore, the tangent Mercator projection is highly accurate within a strip of width 3.24 degrees centred on the equator.
These observations prompted the development of the transverse Mercator projections in which a meridian is treated 'like an equator' of the projection so that we obtain an accurate map within a narrow distance of that meridian.
The four cardinal directions, or cardinal points, are the four main compass directions: north, east, south, and west, commonly denoted by their initials N, E, S, and W respectively.
When travelling East or West, it is only on the Equator that one can keep East or West and be going straight (without the need to steer).
The north pole of the magnetic needle points towards the geographic north pole of the earth and vice versa.
In the middle of the day, it is to the south for viewers in the Northern Hemisphere, who live north of the Tropic of Cancer, and the north for those in the Southern Hemisphere, who live south of the Tropic of Capricorn.
In these locations, one needs first to determine whether the sun is moving from east to west through north or south by watching its movements—left to right means it is going through south while the right to left means it is going through north; or one can watch the sun's shadows.
Because of the Earth's axial tilt, no matter what the location of the viewer, there are only two days each year when the sun rises precisely due east.
For this method to work in the southern hemisphere, the 12 is pointed toward the Sun and the point halfway between the hour hand and 12 o'clock will indicate north.
This axis intersects the Celestial Sphere at the North and South Celestial poles, which appear to the observer to lie directly above due North and South respectively on the horizon.
The resulting photograph reveals a multitude of concentric arcs (portions of perfect circles) from which the exact center can be readily derived, and which corresponds to the Celestial pole, which lies directly above the position of the true pole (North or South) on the horizon.
The exact position of the pole changes over thousands of years because of the precession of the equinoxes.
The asterism "Big Dipper" may be used to find Polaris.
Since it finds true, rather than magnetic, north, it is immune to interference by local or shipboard magnetic fields.
Most maps in medieval Europe, for example, placed east (E) at the top.
Topographic maps include elevation, typically via contour lines.
The North point will then be the point on the limb that is closest to the North celestial pole.
Going around the disk clockwise from the North point, one encounters in order the West point, the South point, and then the East point.
In pre-modern Europe more generally, between eight and 32 points of the compass – cardinal and intercardinal directions – were given names.
Systems with five cardinal points (four directions and the center) include those from pre-modern China, as well as traditional Turkic, Tibetan and Ainu cultures.
Some may also include "above" and "below" as directions, and therefore focus on a cosmology of seven directions.
North is associated with the Himalayas and heaven while the south is associated with the underworld or land of the fathers (Pitr loka).
North is one of the four compass points or cardinal directions.
Septentrionalis is from septentriones, "the seven plow oxen", a name of Ursa Major.
For example, in Lezgian, kefer can mean both "disbelief" and "north", since to the north of the Muslim Lezgian homeland there are areas formerly inhabited by non-Muslim Caucasian and Turkic peoples.
On any rotating astronomical object, north often denotes the side appearing to rotate counter-clockwise when viewed from afar along the axis of rotation.
But simple generalizations on the subject should be treated as unsound, and as likely to reflect popular misconceptions about terrestrial magnetism.
This convention has developed from the use of a compass, which places north at the top.
95% of the Global North has enough food and shelter, and a functioning education system.
Use of the term "South" may also be country-relative, particularly in cases of noticeable economic or cultural divide.
Rarely does the meaning broaden to Bolivia, and in the most restricted sense it only covers Chile, Argentina and Uruguay.
West is the direction opposite that of the Earth's rotation on its axis, and is therefore the general direction towards which the Sun appears to constantly progress and eventually set.
In Ancient Egypt, the West was considered to be the portal to the netherworld, and is the cardinal direction regarded in connection with death, though not always with a negative connotation.
In Judaism, west is seen to be toward the Shekinah (presence) of God, as in Jewish history the Tabernacle and subsequent Jerusalem Temple faced east, with God's Presence in the Holy of Holies up the steps to the west.
The Arctic Circle is one of the two polar circles and the most northerly of the five major circles of latitude as shown on maps of Earth.
A circle of latitude or line of latitude on Earth is an abstract east–west small circle connecting all locations around Earth (ignoring elevation) at a given latitude coordinate line.
Circles of latitude are unlike circles of longitude, which are all great circles with the centre of Earth in the middle, as the circles of latitude get smaller as the distance from the Equator increases.
A circle of latitude is perpendicular to all meridians.
The Equator is the longest circle of latitude and is the only circle of latitude which also is a great circle.
On a map, the circles of latitude may or may not be parallel, and their spacing may vary, depending on which projection is used to map the surface of the Earth onto a plane.
For instance, on a Mercator projection the circles of latitude are more widely spaced near the poles to preserve local scales and shapes, while on a Gall–Peters projection the circles of latitude are spaced more closely near the poles so that comparisons of area will be accurate.
There are many smaller terms, resulting in varying daily shifts of some metres in any direction.
54°40'N The border between 19th century Russian territories to the north and conflicting American and British land claims in western North America.
43°30'N In the US, the border between Minnesota and Iowa.
42°N Originally the northward limit of New Spain.
41°N In the US, part of the border between Wyoming and Utah, the border between Wyoming and Colorado, and part of the border between Nebraska and Colorado.
38°N The boundary between the Soviet and American occupation zones in Korea, and later between North Korea and South Korea, from 1945 until the Korean War (1950–1953).
Geographically it is a Westward extension of the border between Virginia and North Carolina and part of the border between Kentucky and Tennessee.
Also, part of the border between North Carolina and Georgia.
32°N In the US, part of the border between New Mexico and Texas.
25°N Part of the border between Mauritania and Mali.
17°N The division between Republic of Vietnam (South Vietnam) and Democratic Republic of Vietnam (North Vietnam) during the Vietnam War.
8°N Part of the border between Somalia and Ethiopia.
7°S A short section of the border between Democratic Republic of the Congo and Angola.
The arts are a very wide range of human practices of creative expression, storytelling and cultural participation.
They can employ skill and imagination to produce objects, performances, convey insights and experiences, and construct new environments and spaces.
They can also develop or contribute to some particular aspect of a more complex art form, as in cinematography.
The first meaning of the word art is « way of doing ».
In its most basic abstract definition, art is a documented expression of a sentient being through or on an accessible medium so that anyone can view, hear or experience it.
Such public rating is dependent on various subjective factors.
In Ancient Greece, all art and craft was referred to by the same word, techne.
Ancient Roman art depicted gods as idealized humans, shown with characteristic distinguishing features (e.g. Zeus' thunderbolt).
A characteristic of this style is that the local colour is often defined by an outline (a contemporary equivalent is the cartoon).
In modern academia, the arts are usually grouped with or as a subset of the humanities.
The word architecture comes from the Greek arkhitekton, "master builder, director of works," from αρχι- (arkhi) "chief" + τεκτων (tekton) "builder, carpenter".
In modern usage, architecture is the art and discipline of creating, or inferring an implied or apparent plan of, a complex object or system.
Planned architecture manipulates space, volume, texture, light, shadow, or abstract elements in order to achieve pleasing aesthetics.
While some ceramic products are considered fine art, some are considered to be decorative, industrial, or applied art objects.
In a pottery or ceramic factory, a group of people design, manufacture, and decorate the pottery.
It generally involves making marks on a surface by applying pressure from a tool, or moving a tool across a surface.
The main techniques used in drawing are line drawing, hatching, crosshatching, random hatching, scribbling, stippling, and blending.
Paintings can be naturalistic and representational (as in a still life or landscape painting), photographic, abstract, narrative, symbolistic (as in Symbolist art), emotive (as in Expressionism), or political in nature (as in Artivism).
The noun "literature" comes from the Latin word littera meaning "an individual written character (letter)."
Each discipline in the performing arts is temporal in nature, meaning the product is performed over a period of time.
Dance is also used to describe methods of non-verbal communication (see body language) between humans or animals (e.g. bee dance, mating dance), motion in inanimate objects (e.g. the leaves danced in the wind), and certain musical forms or genres.
The creation, performance, significance, and even the definition of music vary according to culture and social context.
The composer Richard Wagner recognized the fusion of so many disciplines into a single work of opera, exemplified by his cycle Der Ring des Nibelungen ("The Ring of the Nibelung").
Other works in the late 19th, 20th and 21st centuries have fused other disciplines in unique and creative ways, such as performance art.
John Cage is regarded by many as a performance artist rather than a composer, although he preferred the latter term.
The applied arts includes fields such as industrial design, illustration, and commercial art.
Within social sciences, cultural economists show how video games playing is conducive to the involvement in more traditional art forms and cultural practices, which suggests the complementarity between video games and the arts.
Architecture (Latin architectura, from the Greek ἀρχιτέκτων arkhitekton "architect", from ἀρχι- "chief" and τέκτων "creator") is both the process and the product of planning, designing, and constructing buildings or other structures.
The practice, which began in the prehistoric era, has been used as a way of expressing culture for civilizations on all seven continents.
In the 19th century, Louis Sullivan declared that "form follows function". "
Architecture began as rural, oral vernacular architecture that developed from trial and error to successful replication.
During the European Middle Ages, pan-European styles of Romanesque and Gothic cathedrals and abbeys emerged while the Renaissance favored Classical forms implemented by architects known by name.
Emphasis was put on modern techniques, materials, and simplified geometric forms, paving the way for high-rise superstructures.
A unifying or coherent form or structure.
The most important aspect of beauty was, therefore, an inherent part of an object, rather than something applied superficially, and was based on universal, recognisable truths.
In the 16th century, Italian Mannerist architect, painter and theorist Sebastiano Serlio wrote Tutte L’Opere D’Architettura et Prospetiva (Complete Works on Architecture and Perspective).
Gothic architecture, Pugin believed, was the only "true Christian form of architecture."
Among the philosophies that have influenced modern architects and their approach to building design are Rationalism, Empiricism, Structuralism, Poststructuralism, Deconstruction and Phenomenology.
The architecture and urbanism of the Classical civilizations such as the Greek and the Roman evolved from civic ideals rather than religious or empirical ones and new building types emerged.
Texts on architecture have been written since ancient time.
Buddhist architecture, in particular, showed great regional diversity.
The role of architect was usually one with that of master mason, or Magister lathomorum as they are sometimes described in contemporary documents.
Buildings were ascribed to specific architects – Brunelleschi, Alberti, Michelangelo, Palladio – and the cult of the individual had begun.
Formal architectural training in the 19th century, for example at École des Beaux-Arts in France, gave much emphasis to the production of beautiful drawings and little to context and feasibility.
Notable among these is the Deutscher Werkbund, formed in 1907 to produce better quality machine-made objects.
When modern architecture was first practised, it was an avant-garde movement with moral, philosophical, and aesthetic underpinnings.
The approach of the Modernist architects was to reduce buildings to pure forms, removing historical references and ornament in favor of functional details.
Architects such as Mies van der Rohe, Philip Johnson and Marcel Breuer worked to create beauty based on the inherent qualities of building materials and modern construction techniques, trading traditional historic forms for simplified geometric forms, celebrating the new means and methods made possible by the Industrial Revolution, including steel-frame construction, which gave birth to high-rise superstructures.
The preparatory processes for the design of any large building have become increasingly complicated, and require preliminary studies of such matters as durability, sustainability, quality, money, and compliance with local laws.
Environmental sustainability has become a mainstream issue, with a profound effect on the architectural profession.
This major shift in architecture has also changed architecture schools to focus more on the environment.
The U.S. Green Building Council's LEED (Leadership in Energy and Environmental Design) rating system has been instrumental in this.
It can also be the initial design and plan for use, then later redesigned to accommodate a changed purpose, or a significantly revised design for adaptive reuse of the building shell.
Preliminary design of the vessel, its detailed design, construction, trials, operation and maintenance, launching and dry-docking are the main activities involved.
Conversely, sacred architecture as a locale for meta-intimacy may also be non-monolithic, ephemeral and intensely private, personal and non-public.
With the rise of Christianity and Islam, religious buildings increasingly became centres of worship, prayer and meditation.
India was crisscrossed by trading routes of merchants from as far away as Siraf and China as well as weathering invasions by foreigners, resulting in multiple influences of foreign elements on native styles.
An existing example is at Nalanda (Bihar).
In accordance with changes in religious practice, stupas were gradually incorporated into chaitya-grihas (stupa halls).
Buddhist temples were developed rather later and outside South Asia, where Buddhism gradually declined from the early centuries CE onwards, though an early example is that of the Mahabodhi Temple at Bodh Gaya in Bihar.
In Hindu belief, the temple represents the macrocosm of the universe as well as the microcosm of inner space.
It evolved over a period of more than 2000 years.
In addition, brick replaced stone, classical order was less strictly observed, mosaics replaced carved decoration, and complex domes were erected.
The earliest styles in Islamic architecture produced 'Arab-plan' or hypostyle mosques during the Umayyad Dynasty.
In iwan mosques, one or more iwans face a central courtyard that serves as the prayer hall.
The top of the minaret is always the highest point in mosques that have one, and often the highest point in the immediate area.
Consequently, mosque architects borrowed the shape of the bell tower for their minarets, which were used for essentially the same purpose – calling the faithful to prayer.
Although domes normally took on the shape of a hemisphere, the Mughals in India popularized onion-shaped domes in South Asia and Persia.
Usually opposite the entrance to the prayer hall is the qibla wall, which is the visually emphasized area inside the prayer hall.
In the qibla wall, usually at its center, is the mihrab, a niche or depression indicating the'qibla wall.
The mihrab serves as the location where the imam leads the five daily prayers on a regular basis.
It consists of a nave, transepts, and the altar stands at the east end (see cathedral diagram).
Most architectural historians regard Michelangelo's design of St. Peter's Basilica in Rome as a precursor to the Baroque style; this can be recognized by broader interior spaces (replacing long narrow naves), more playful attention to light and shadow, extensive ornamentation, large frescoes, focus on interior art, and frequently, a dramatic central exterior projection.
While secular structures clearly had the greater influence on the development of modern architecture, several excellent examples of modern architecture can be found in religious buildings of the 20th century.
It has been described as a "phalanx of fighters" turned on their tails and pointing heavenward.
The Temple at Independence, Missouri was conceived by Japanese architect Gyo Obata after the concept of the chambered nautilus.
The Basilica of Our Lady of Licheń on the other hand is a much more traditional edifice.
An architectural style is a set of characteristics and features that make a building or other structure notable or historically identifiable.
Most architecture can be classified within a chronology of styles which changes over time reflecting changing fashions, beliefs and religions, or the emergence of new ideas, technology, or materials which make new styles possible.
At any time several styles may be fashionable, and when a style changes it usually does so gradually, as architects learn and adapt to new ideas.
For instance, Renaissance ideas emerged in Italy around 1425 and spread to all of Europe over the next 200 years, with the French, German, English, and Spanish Renaissances showing recognisably the same style, but with unique characteristics.
After an architectural style has gone out of fashion, revivals and re-interpretations may occur.
The Spanish mission style was revived 100 years later as the Mission Revival, and that soon evolved into the Spanish Colonial Revival.
An example of Mannerist architecture is the Villa Farnese at Caprarola in the rugged country side outside of Rome.
Through Antwerp, Renaissance and Mannerist styles were widely introduced in England, Germany, and northern and eastern Europe in general.
The Renaissance ideal of harmony gave way to freer and more imaginative rhythms.
Architectural theory is the act of thinking, discussing, and writing about architecture.
Architectural theory is often didactic, and theorists tend to stay close to or work from within schools.
This does not mean, however, that such works did not exist, given that many works never survived antiquity.
Probably written between 27 and 23 BC, it is the only major contemporary source on classical architecture to have survived.
It also proposes the three fundamental laws that architecture must obey, in order to be so considered: firmitas, utilitas, venustas, translated in the 17th century by Sir Henry Wotton into the English slogan firmness, commodity and delight (meaning structural adequacy, functional adequacy, and beauty).
Since the architectural theories were on structures, fewer of them were transcribed.
These theories anticipated the development of Functionalism in modern architecture.
This in turn formed the basis for Art Nouveau in the UK, exemplified by the work of Charles Rennie Mackintosh, and influenced the Vienna Secession.
The generation born during the middle-third of the 19th century was largely enthralled with the opportunities presented by Semper's combination of a breathtaking historical scope and a methodological granularity.
The Modern Movement rejected these thoughts and Le Corbusier energetically dismissed the work.
Another influential planning theorist of this time was Ebenezer Howard, who founded the garden city movement.
An early use of the term modern architecture in print occurred in the title of a book by Otto Wagner, who gave examples of his own work representative of the Vienna Secession with art nouveau illustrations, and didactic teachings to his students.
Frank Lloyd Wright, while modern in rejecting historic revivalism, was idiosyncratic in his theory, which he conveyed in copious writing.
Wright was more poetic and firmly maintained the 19th-century view of the creative artist as unique genius.
This has also been the case with educators in academia like Dalibor Vesely or Alberto-Perez Gomez, and in more recent years this philosophical orientation has been reinforced through the research of a new generation of theorists (E.G. Jeffrey Kipnis or Sanford Kwinter).
Others, like Beatriz Colomina and Mary McLeod, expand historical understandings of architecture to include lesser or minor discourses that have influenced the development of architectural ideas over time.
In their theories, architecture is compared to a language which can be invented and re-invented every time it is used.
Since 2000, architectural theory has also had to face the rapid rise of urbanism and globalization.
In the past decade, there has been the emergence of the so-called "Digital" Architecture.
Architects also design organic-looking buildings in the attempt to develop a new formal language.
Since these new architectural tendencies emerged, many theorists and architects have been working on these issues, developing theories and ideas such as Patrick Schumacher's Parametricism.
Byzantine architecture is the architecture of the Byzantine Empire, or Eastern Roman Empire.
Magnificent golden mosaics with their graphic simplicity brought light and warmth into the heart of churches.
Some of the columns were also made of marble.
Precious wood furniture, like beds, chairs, stools, tables, bookshelves and silver or golden cups with beautiful reliefs, decorated Byzantine interiors.
For Classical temples, only the exterior was important, because only the priests entered the interior, where the statue of the deity to whom the temple was dedicated was kept.
Those in the Cathedral of Saint Mark, Venice (1071) specially attracted John Ruskin's fancy.
On eastern columns the eagle, the lion and the lamb are occasionally carved, but treated conventionally.
Composite columns line the principal space of the nave.
The columns are filled with foliage in all sorts of variations.
Other structures include the ruins of the Great Palace of Constantinople, the innovative walls of Constantinople (with 192 towers) and Basilica Cistern (with hundreds of recycled classical columns).
The Paleologan period is well represented in a dozen former churches in Istanbul, notably St Saviour at Chora and St Mary Pammakaristos.
The Church of the Holy Apostles (Thessaloniki) is cited as an archetypal structure of the late period with its exterior walls intricately decorated with complex brickwork patterns or with glazed ceramics.
At Saint Sergius, Constantinople, and San Vitale, Ravenna, churches of the central type, the space under the dome was enlarged by having apsidal additions made to the octagon.
This unbroken area, about 260 ft (80 m) long, the larger part of which is over 100 ft (30 m) wide, is entirely covered by a system of domical surfaces.
At the Holy Apostles (6th century) five domes were applied to a cruciform plan; the central dome was the highest.
Sometimes the central space was square, sometimes octagonal, or at least there were eight piers supporting the dome instead of four, and the nave and transepts were narrower in proportion.
Still in front put a square court.
Directly under the center of the dome is the ambo, from which the Scriptures were proclaimed, and beneath the ambo at floor level was the place for the choir of singers.
Rows of rising seats around the curve of the apse with the patriarch's throne at the middle eastern point formed the synthronon.
The domes and vaults to the exterior were covered with lead or with tiling of the Roman variety.
There are considerable Byzantine influences which can be detected in the distinctive early Islamic monuments in Syria (709–715).
Bricks 70 cm x 35 cm x 5 cm were used, and these bricks were glued together using mortar approximately 5 cm thick.
Perhaps the most definite feature of the Hagia Irene is the strict contrast between the interior and exterior design.
This style influenced the construction of several other buildings, such as St. Peter's Basilica.
The construction of the final version of the Hagia Sophia, which still stands today, was overseen by Emperor Justinian.
Gothic architecture (or pointed architecture) is an architectural style that was particularly popular in Europe from the late 12th century to the 16th century, during the High and Late Middle Ages, surviving into the 17th and 18th centuries in some areas.
The style at the time was sometimes known as opus Francigenum (lit.
The primary engineering innovation and one of the other characteristic design components is the flying buttress.
However, there is no evidence to indicate that there was a connection between Armenian architecture and the development of the Gothic style in Western Europe.
Thus the Gothic style, being in opposition to classical architecture, from that point of view was associated with the destruction of advancement and sophistication.
The term ‘Saracen’ was still in use in the 18th century and it typically referred to all Muslim conquerors, including the Moors and Arabs.
His aversion of the style was so strong that he refused to put a Gothic roof on the new St. Paul's, despite being pressured to do so.
Several authors have taken a stance against this allegation, claiming that the Gothic style had most likely filtered into Europe in other ways, for example through Spain or Sicily.
It was also influenced by theological doctrines which called for more light and by technical improvements in vaults and buttresses that allowed much greater height and larger windows.
Rib-vaults were employed in some parts of the cathedral at Durham (1093–) and in Lessay Abbey in Normandy (1098).
The Duchy of Normandy, part of the Angevin Empire until the 13th century, developed its own version of Gothic.
One example of early Norman Gothic is Bayeux Cathedral (1060–70) where the Romanesque cathedral nave and choir were rebuilt into the Gothic style.
Coutances Cathedral was remade into Gothic beginning about 1220.
Suger reconstructed portions of the old Romanesque church with the rib vault in order to remove walls and to make more space for windows.
In addition, he installed a circular rose window over the portal on the facade.
Durham Cathedral was the first cathedral to employ a rib vault, built between 1093 and 1104.
One of the builders who is believed to have worked on Sens Cathedral, William of Sens, later travelled to England and became the architect who, between 1175 and 1180, reconstructed the choir of Canterbury Cathedral in the new Gothic style.
French Gothic churches were heavily influenced both by the ambulatory and side-chapels around the choir at Saint-Denis, and by the paired towers and triple doors on the western façade.
The builders of Notre-Dame went further by introducing the flying buttress, heavy columns of support outside the walls connected by arches to the upper walls.
His work was continued by William the Englishman who replaced his French namesake in 1178.
Tiercerons – decorative vaulting ribs – seem first to be have been used in vaulting at Lincoln Cathedral, installed c.1200.
The first building in the High Gothic was Chartres Cathedral, an important pilgrimage church south of Paris.
The walls were filled with stained glass, mainly depicting the story of the Virgin Mary but also, in a small corner of each window, illustrating the crafts of the guilds who donated those windows.
In central Europe, the High Gothic style appeared in the Holy Roman Empire, first at Toul (1220–), whose Romanesque cathedral was rebuilt in the style of Reims Cathedral; then Trier's Liebfrauenkirche parish church (1228–), and then throughout the Reich, beginning with the Elisabethkirche at Marburg (1235–) and the cathedral at Metz (c.1235–).
Lancet windows were supplanted by multiple lights separated by geometrical bar-tracery.
Other characteristics of the High Gothic were the development of rose windows of greater size, using bar-tracery, higher and longer flying buttresses, which could reach up to the highest windows, and walls of sculpture illustrating biblical stories filling the facade and the fronts of the transept.
The high and thin walls of French Rayonnant Gothic allowed by the flying buttresses enabled increasingly ambitious expanses of glass and decorated tracery, reinforced with ironwork.
Masons elaborated a series of tracery patterns for windows – from the basic geometrical to the reticulated and the curvilinear – which had superseded the lancet window.
Churches with features of this style include Westminster Abbey (1245–), the cathedrals at Lichfield (after 1257–) and Exeter (1275–), Bath Abbey (1298–), and the retro choir at Wells Cathedral (c.1320–).
Use of ogees was especially common.
Examples of French flamboyant building include the west façade of Rouen Cathedral, and especially the façades of Sainte-Chapelle de Vincennes (1370s) and choir Mont-Saint-Michel's abbey church (1448).
It first appeared in the cloisters and chapter-house (c. 1332) of Old St Paul's Cathedral in London by William de Ramsey.
Perpendicular is sometimes called Third Pointed and was employed over three centuries; the fan-vaulted staircase at Christ Church, Oxford built around 1640.
The Kings of France had first-hand knowledge of the new Italian style, because of the military campaign of Charles VIII to Naples and Milan (1494), and especially the campaigns of Louis XII and Francis I (1500–1505) to restore French control over Milan and Genoa.
The Château de Blois (1515–24) introduced the Renaissance loggia and open stairway.
Under Henry VIII and Elizabeth I, England was largely isolated from architectural developments on the continent.
Shute published the first book in English on classical architecture in 1570.
The pointed arch did not originate in Gothic architecture; they had been employed for centuries in the Near East in pre-Islamic as well as Islamic architecture for arches, arcades, and ribbed vaults.
They were also sometimes used for more practical purposes, such as to bring transverse vaults to the same height as diagonal vaults, as in the nave and aisles of Durham Cathedral, built in 1093.
Unlike the semi-circular barrel vault of Roman and Romanesque buildings, where the weight pressed directly downward, and required thick walls and small windows, the Gothic rib vault was made of diagonal crossing arched ribs.
The outward thrust against the walls was countered by the weight of buttresses and later flying buttresses.
They were very difficult to build, and could only cross a limited space.
The alternating rows of alternating columns and piers receiving the weight of the vaults was replaced by simple pillars, each receiving the same weight.
The first of these new vaults had an additional rib, called a tierceron, which ran down the median of the vault.
These vaults often copied the forms form of the elaborate tracery of the Late Gothic styles.
A second type was called a reticulated vault, which had a network of additional decorative ribs, in triangles and other geometric forms, placed between or over the traverse ribs.
An example is the cloister of Gloucester Cathedral (c. 1370).
They were used later at Sens, at Notre-Dame de Paris and at Canterbury in England.
In the High Gothic period, a new form was introduced, composed of a central core surrounded several attached slender columns, or colonettes, going up to the vaults.
In England, the clustered columns were often ornamented with stone rings, as well as columns with carved leaves.
In place of the Corinthian capital, some columns used a stiff-leaf design.
In later structures, the buttresses often had several arches, each reaching in to a different level of the structure.
The arches had an additional practical purpose; they contained lead channels which carried rainwater off the roof; it was expelled from the mouths of stone gargoyles placed in rows on the buttresses.
They also had a practical purpose; they often served as bell towers supporting belfries, whose bells told the time by announcing religious services, warned of fire or enemy attack, and celebrated special occasions like military victories and coronations.
Since cathedral construction usually took many years, and was extremely expensive, by the time the tower were to be built public enthusiasm waned, and tastes changed.
Chartres would have been even more exuberant if the second plan had been followed; it called for seven towers around the transept and sanctuary.
The early and High Gothic Laon Cathedral has a square lantern tower over the crossing of the transept; two towers on the western front; and two towers on the ends of the transepts.
In Normandy, cathedrals and major churches often had multiple towers, built over the centuries; the Abbaye aux Hommes (begun 1066), Caen has nine towers and spires, placed on the facade, the transepts, and the centre.
A variation of the spire was the flèche, a slender, spear-like spire, which was usually placed on the transept where it crossed the nave.
Amiens Cathedral has a flèche.
It was removed in 1786 during a program to modernise the cathedral, but was put back in a new form designed by Eugène Viollet-le-Duc.
In English Gothic, the major tower was often placed at the crossing of the transept and nave, and was much higher than the other.
A crossing tower was constructed at Canterbury Cathedral in 1493–1501 by John Wastell, who had previously worked on King's College at Cambridge.
An unusual double arch had to be constructed in the centre of the crossing to give the tower the extra support it needed.
Construction began again in 1724 to the design of Nicholas Hawksmoor, after first Christopher Wren had proposed a design in 1710, but stopped again in 1727.
Cologne Cathedral had been started in the 13th century, following the plan of Amiens Cathedral, but only the apse and the base of one tower were finished in the Gothic period.
The tower of Ulm Minster has a similar history, begun in 1377, stopped in 1543, and not completed until the 19th century.
Burgos Cathedral was more inspired by Northern Europe.
Plate tracery was the first type of tracery to be developed, emerging in the later phase of Early Gothic or First Pointed.
Tracery is practical as well as decorative, because the increasingly large windows of Gothic buildings needed maximum support against the wind.
Plate tracery reached the height of its sophistication with the 12th century windows of Chartres Cathedral and in the "Dean's Eye" rose window at Lincoln Cathedral.
Stone bar-tracery, an important decorative element of Gothic styles, first was used at Reims Cathedral shortly after 1211, in the chevet built by Jean D'Orbais.
Bar-tracery became common after c.1240, with increasing complexity and decreasing weight.
Rayonnant also deployed mouldings of two different types in tracery, where earlier styles had used moulding of a single size, with different sizes of mullions.
The mullions of Geometrical style typically had capitals with curved bars emerging from them.
The mullions were in consequence branched into Y-shaped designs further ornamented with cusps.
Second Pointed (14th century) saw Intersecting tracery elaborated with ogees, creating a complex reticular (net-like) design known as Reticulated tracery.
These shapes are known as daggers, fish-bladders, or mouchettes.
Perpendicular strove for verticality and dispensed with the Curvilinear style's sinuous lines in favour of unbroken straight mullions from top to bottom, transected by horizontal transoms and bars.
The transoms were often topped by miniature crenellations.
It frequently covered the facades, and the interior walls of the nave and choir were covered with blind arcades.
2 Vaults Barrel or groin Ribbed Ribbed vaults appeared in the Romanesque era and were elaborated in the Gothic era.
They have a long nave making the body of the church, where the parishioners worshipped; a transverse arm called the transept and, beyond it to the east, the choir, also known as a chancel or presbytery, that was usually reserved for the clergy.
A passage called the ambulatory circled the choir.
The early cathedrals, like Notre-Dame, had six-part rib vaults, with alternating columns and piers, while later cathedrals had the simpler and stronger four-part vaults, with identical columns.
Transepts were usually short in early French Gothic architecture, but became longer and were given large rose windows in the Rayonnant period.
In England, transepts were more important, and the floor plans were usually much more complex than in French cathedrals, with the addition of attached Lady Chapels, an octagonal Chapter House, and other structures (See plans of Salisbury Cathedral and York Minster below).
An elevation typically had four levels.
Above that was a narrower gallery, called the triforium, which also helped provide additional thickness and support.
This system was used at Noyon Cathedral, Sens Cathedral, and other early structures.
The tribune disappeared, which meant that the arcades could be higher.
A similar arrangement was adapted in England, at Salisbury Cathedral, Lincoln Cathedral, and Ely Cathedral.
This was made possible by the development of the flying buttress, which transferred the thrust of the weight of the roof to the supports outside the walls.
Beauvais Cathedral reached the limit of what was possible with Gothic technology.
Gothic facades were adapted from the model of the Romanesque facades.
The sculpture of the central tympanum was devoted to the Last Judgement, that to the left to the Virgin Mary, and that to the right to the Saints honoured at that particular cathedral.
They followed the doctrine expressed by Saint Thomas Aquinas that beauty was a "harmony of contrasts."
In England the rose window was often replaced by several lancet windows.
The portals were crowned with high arched gables, composed of concentric arches filled with sculpture.
The towers were adorned with their own arches, often crowned with pinnacles.
While French cathedrals emphasised the height of the facade, English cathedrals, particularly in earlier Gothic, often emphasised the width.
He broke away from the French emphasis on height, and eliminated the column statutes and statuary in the arched entries, and covered the facade with colourful mosaics of biblical scenes (The current mosaics are of a later date).
The sculptor Andrea Pisano made the celebrated bronze doors for Florence Baptistry (1330–1336).
There is usually a single or double ambulatory, or aisle, around the choir and east end, so parishioners and pilgrims could walk freely easily around east end.
Abbot Suger first used the novel combination rib vaults and buttresses to replace the thick walls and replace them with stained glass, opening up that portion of the church to what he considered "divine light".
There are three such chapels at Chartres Cathedral, seven at Notre Dame de Paris, Amiens Cathedral, Prague Cathedral and Cologne Cathedral, and nine at Basilica of Saint Anthony of Padua in Italy.
An edict of the Second Council of Nicaea in 787 had declared: "The composition of religious images is not to be left to the inspiration of artists; it is derived from the principles put in place by the Catholic Church and religious tradition.
Gradually, as the style evolved, the sculpture became more and more prominent, taking over the columns of the portal, and gradually climbing above the portals, until statues in niches covered the entire facade, as in Wells Cathedral, to the transepts, and, as at Amiens Cathedral, even on the interior of the facade.
This set a pattern of complex iconography which was followed at other churches.
The tympanum over the central portal on the west façade of Notre-Dame de Paris vividly illustrates the Last Judgement, with figures of sinners being led off to hell, and good Christians taken to heaven.
The torments of hell were even more vividly depicted.
They were part of the visual message for the illiterate worshippers, symbols of the evil and danger that threatened those who did not follow the teachings of the church.
They were replaced with figures in the Gothic style, designed by Eugène Viollet-le-Duc during the 19th-century restoration.
Religious teachings in the Middle Ages, particularly the writings of Pseudo-Dionysius the Areopagite, a 6th-century mystic whose book, De Coelesti Hierarchia, was popular among monks in France, taught that all light was divine.
The windows on the north side, frequently in the shade, had windows depicting the Old Testament.
The details were painted onto the glass in vitreous enamel, then baked in a kiln to fuse the enamel on the glass.
Sainte-Chapelle became the model for other chapels across Europe.
Clear glass was dipped into coloured glass, then portions of the coloured glass were ground away to give exactly the right shade.
One of the most celebrated Flamboyant buildings was the Sainte-Chapelle de Vincennes (1370s), with walls of glass from floor to ceiling.
The stained glass windows were extremely complex and expensive to create.
The rose was a symbol of the Virgin Mary, and they were particularly used in churches dedicated to her, including Notre-Dame de Paris.
The Palais de la Cité in Paris, close to Notre-Dame de Paris, begun in 1119, which was the principal residence of the French kings until 1417.
However, it was soon made obsolete by the development of artillery, and in the 15th century it was remodelled into a comfortable residential palace.
The oldest existing example in England is probably the Mob Quad of Merton College at Oxford University, constructed between 1288 and 1378.
A similar kind of academic cloister was created at Queen's College, Oxford in the 1140s, likely designed by Reginald Ely.
Some colleges, like Balliol College, Oxford, borrowed a military style from Gothic castles, with battlements and crenolated walls.
He wrote in 1447 that he wanted his chapel "to proceed in large form, clean and substantial, setting apart superfluity of too great curious works of entail and busy moulding."
The walls had two levels of walkways on the inside, a crennellated parapet with merlons, and projecting machicolations from which missiles could be dropped on besiegers.
Castles were surrounded by a deep moat, spanned by a single drawbridge.
One good surviving example is the Château de Dourdan, near Nemours.
The conversion implied compromises since Latin churches are oriented towards the East and mosques are oriented towards Mecca.
Lala Mustafa Pasha Mosque, in Famagusta, Northern Cyprus.
The Gothic style began to be described as outdated, ugly and even barbaric.
Ireland was an island of Gothic architecture in the 17th and 18th centuries, with the construction of Derry Cathedral (completed 1633), Sligo Cathedral (c. 1730), and Down Cathedral (1790–1818) are other examples.
The two western towers of Westminster Abbey were constructed between 1722 and 1745 by Nicholas Hawksmoor, opening a new period of Gothic Revival.
This period of more universal appeal, spanning 1855–1885, is known in Britain as High Victorian Gothic.
From the second half of the 19th century onwards, it became more common in Britain for neo-Gothic to be used in the design of non-ecclesiastical and non-governmental buildings types.
Landscape architects work on structures and external spaces in the landscape aspect of the design – large or small, urban, suburban and rural, and with "hard" (built) and "soft" (planted) materials, while integrating ecological sustainability.
They can also review proposals to authorize and supervise contracts for the construction work.
The first person to write of making a landscape was Joseph Addison in 1712.
During the latter 19th century, the term landscape architect began to be used by professional landscapes designers, and was firmly established after Frederick Law Olmsted, Jr. and Beatrix Jones (later Farrand) with others founded the American Society of Landscape Architects (ASLA) in 1899.
Their projects can range from site surveys to the ecological assessment of broad areas for planning or management purposes.
Their work is embodied in written statements of policy and strategy, and their remit includes master planning for new developments, landscape evaluations and assessments, and preparing countryside management or policy plans.
In recent years the need and interest of therapeutic gardens have been increasingly rising.
Among these were Central Park in New York City, Prospect Park in Brooklyn, New York and Boston's Emerald Necklace park system.
She was design consultant for over a dozen universities including: Princeton in Princeton, New Jersey; Yale in New Haven, Connecticut; and the Arnold Arboretum for Harvard in Boston, Massachusetts.
Urban Planners are qualified to perform tasks independent of landscape architects, and in general, the curriculum of landscape architecture programs do not prepare students to become urban planners.
Roberto Burle Marx in Brazil combined the International style and native Brazilian plants and culture for a new aesthetic.
He popularized a system of analyzing the layers of a site in order to compile a complete understanding of the qualitative attributes of a place.
Once recognized by AILA, landscape architects use the title 'Registered Landscape Architect' across the six states and territories within Australia.
Within NZ, Members of NZILA when they achieve their professional standing, can use the title Registered Landscape Architect NZILA.
ILASA's mission is to advance the profession of landscape architecture and uphold high standards of professional service to its members, and to represent the profession of landscape architecture in any matter which may affect the interests of the members of the institute.
At present there are fifteen accredited programmes in the UK.
In 2008, the LI launched a major recruitment drive entitled "I want to be a Landscape Architect" to encourage the study of Landscape Architecture.
Several states require passage of a state exam as well.
By the 6th century BC, the sand already covered the statues of the main temple up to their knees.
One scheme to save the temples was based on an idea by William MacQuitty to build a clear freshwater dam around the temples, with the water inside kept at the same height as the Nile.
They considered that raising the temples ignored the effect of erosion of the sandstone by desert winds.
Between 1964 and 1968, the entire site was carefully cut into large blocks (up to 30 tons, averaging 20 tons), dismantled, lifted and reassembled in a new location 65 metres higher and 200 metres back from the river, in one of the greatest challenges of archaeological engineering in history.
Many visitors also arrive by plane at an airfield that was specially constructed for the temple complex, or by road from Aswan, the nearest city.
The colossal statues along the left-hand wall bear the white crown of Upper Egypt, while those on the opposite side are wearing the double crown of Upper and Lower Egypt (pschent).
The most famous relief shows the king on his chariot shooting arrows against his fleeing enemies, who are being taken prisoner.
There are depictions of Ramesses and Nefertari with the sacred boats of Amun and Ra-Horakhty.
These dates are allegedly the king's birthday and coronation day, respectively.
In fact, according to calculations made on the basis of the heliacal rising of the star Sirius (Sothis) and inscriptions found by archaeologists, this date must have been October 22.
This was in fact the second time in ancient Egyptian history that a temple was dedicated to a queen.
Traditionally, the statues of the queens stood next to those of the pharaoh, but were never taller than his knees.
The capitals of the pillars bear the face of the goddess Hathor; this type of column is known as Hathoric.
On the south and the north walls of this chamber there are two graceful and poetic bas-reliefs of the king and his consort presenting papyrus plants to Hathor, who is depicted as a cow on a boat sailing in a thicket of papyri.
None of the current buildings are believed to date from before the 17th century, but they were likely built with the same construction methods and designs as had been used for centuries before.
Other kasbahs and ksour were located all along this route, such as the nearby Tamdaght to the north.
The village's buildings are grouped together within a defensive wall that includes corner towers and a gate.
The village also has a number of public or community buildings such as a mosque, a caravanserai, a kasbah (castle-like fortification) and the Marabout of Sidi Ali or Amer.
It was made of compressed earth and mud, usually mixed with other materials to aid adhesion.
The Aswan Dam, or more specifically since the 1960s, the Aswan High Dam, is the world's largest embankment dam, which was built across the Nile in Aswan, Egypt, between 1960 and 1970.
Like the earlier implementation, the High Dam has had a significant effect on the economy and culture of Egypt.
However, this natural flooding varied, since high-water years could destroy the whole crop, while low-water years could create widespread drought and consequently famine.
Instead the Nile Valley Plan by the British hydrologist Harold Edwin Hurst was favored, which proposed to store water in Sudan and Ethiopia, where evaporation is much lower.
Initially, both the United States and the USSR were interested in helping development of the dam.
At that time the U.S. feared that communism would spread to the Middle East, and it saw Nasser as a natural leader of an anticommunist procapitalist Arab League.
After the UN criticized a raid by Israel against Egyptian forces in Gaza in 1955, Nasser realized that he could not portray himself as the leader of pan-Arab nationalism if he could not defend his country militarily against Israel.
Nasser did not accept these conditions, and consulted the USSR for support.
Dulles was angered more by Nasser's diplomatic recognition of China, which was in direct conflict with Dulles's policy of containment of communism.
He was also irritated by Nasser's neutrality and attempts to play both sides of the Cold War.
The enormous rock and clay dam was designed by the Soviet Hydroproject Institute along with some Egyptian engineers.
Conversely, the dam flooded a large area, causing the relocation of over 100,000 people.
The assessment of the costs and benefits of the dam remains controversial decades after its completion.
Not taking into account the negative environmental and social effects of the dam, its costs are thus estimated to have been recovered within only two years.
Another observer disagreed and he recommended that the dam should be torn down.
The dam mitigated the effects of floods, such as those in 1964, 1973, and 1988.
A new fishing industry has been created around Lake Nasser, though it is struggling due to its distance from any significant markets.
About half a million families were settled on these new lands.
On other previously irrigated land, yields increased because water could be made available at critical low-flow periods.
In Sudan, 50,000 to 70,000 Sudanese Nubians were moved from the old town of Wadi Halfa and its surrounding villages.
The government developed an irrigation project, called the New Halfa Agricultural Development Scheme to grow cotton, grains, sugar cane and other crops.
Housing and facilities were built for 47 village units whose relationship to each other approximated that in Old Nubia.
The nutrient value added to the land by the sediment was only 6,000 tons of potash, 7,000 tons of phosphorus pentoxide and 17,000 tons of nitrogen.
Soil salinity also increased because the distance between the surface and the groundwater table was small enough (1–2 m depending on soil conditions and temperature) to allow water to be pulled up by evaporation so that the relatively small concentrations of salt in the groundwater accumulated on the soil surface over the years.
By the 1950s only a small proportion of Upper Egypt had not been converted from basin (low transmission) to perennial (high transmission) irrigation.
S. haematobium has since disappeared altogether.
This means that the dead storage volume would be filled up after 300–500 years if the sediment accumulated at the same rate throughout the area of the lake.
After construction of the dam, aquatic weeds grew much faster in the clearer water, helped by fertilizer residues.
Mediterranean fishing and brackish water lake fishery declined after the dam was finished because nutrients that flowed down the Nile to the Mediterranean were trapped behind the dam.
A concern before the construction of the High Dam had been the potential drop in river-bed level downstream of the Dam as the result of erosion caused by the flow of sediment-free water.
The red-brick construction industry, which consisted of hundreds of factories that used Nile sediment deposits along the river, has also been negatively affected.
Because of the lower turbidity of the water sunlight penetrates deeper in the Nile water.
Construction work began in 1995 and, after some US$220 million had been spent, the complex was officially inaugurated on 16 October 2002.
The recreation of the ancient library was not only adopted by other individuals and agencies, it garnered support from Egyptian politicians.
UNESCO's involvement beginning in 1986 created a great opportunity for the project to truly be international in focus.
This architectural team consisted of ten members representing six countries.
The first pledges were made for funding the project at a conference held in 1990 in Aswan: USD $65 million, mostly from the MENA states.
In 2010, the library received a donation of 500,000 books from the National Library of France, Bibliothèque nationale de France (BnF).
The main reading room stands beneath a 32-meter-high glass-panelled roof, tilted out toward the sea like a sundial, and measuring some 160 m in diameter.
Holding approximately 1,316 artifacts, the Antiquities Museum collection provides a glimpse into Egyptian history from the Pharaonic era to the conquest of Alexander the Great to the Roman civilizations before the advent of Islam across Egypt.
Microfilm: This section includes microfilms of around 30,000 rare manuscripts and 50,000 documents, as well as a collection from The British Library of around 14,000 Arabic, Persian, and Turkish manuscripts, which is considered the largest collection in Europe.
However, in 2010 the library received an additional 500,000 books from the Bibliothèque nationale de France.)
The Great Mosque of Djenné is a large banco or adobe building that is considered by many architects to be one of the greatest achievements of the Sudano-Sahelian architectural style.
The earliest document mentioning the mosque is Abd al-Sadi's Tarikh al-Sudan which gives the early history, presumably from the oral tradition as it existed in the mid-seventeenth century.
His immediate successor built the towers of the mosque while the following Sultan built the surrounding wall.
This would have been the building that Caillié saw.
The new mosque was a large, low building lacking any towers or ornamentation.
The rebuilding was completed in 1907 using forced labour under the direction of Ismaila Traoré, head of Djenné's guild of masons.
There has been debate as to what extent the design of the rebuilt mosque was subject to French influence.
He thought that the cones made the building resemble a baroque temple dedicated to the god of suppositories.
He also says that local people were so unhappy with the new building that they refused to clean it, only doing so when threatened with prison.
The larger tomb to the south contains the remains of Almany Ismaïla, an important imam of the 18th century.
In some cases, the original surfaces of a mosque have even been tiled over, destroying its historical appearance and in some cases compromising the building's structural integrity.
In 1996, Vogue magazine held a fashion shoot inside the mosque.
It is accessed by six sets of stairs, each decorated with pinnacles.
The prayer wall or qibla of the Great Mosque faces east towards Mecca and overlooks the city marketplace.
The cone shaped spires or pinnacles at the top of each minaret are topped with ostrich eggs.
The small, irregularly-positioned windows on the north and south walls allow little natural light to reach the interior of the hall.
The imam conducts the prayers from the mihrab in the larger central tower.
To the right of the mihrab in the central tower is a second niche, the pulpit or minbar, from which the imam preaches his Friday sermon.
The walls of the galleries facing the courtyard are punctuated by arched openings.
Rather than a single central niche, the mihrab tower originally had a pair of large recesses echoing the form of the entrance arches in the north wall.
It requires several days to cure but needs to be periodically stirred, a task usually falling to young boys who play in the mixture, thus stirring up the contents.
A race is held at the beginning of the festival to see who will be the first to deliver the plaster to the mosque.
In 1930, an inexact replica of the Djenné Mosque was built in the town of Fréjus in southern France.
The original mosque presided over one of the most important Islamic learning centers in Africa during the Middle Ages, with thousands of students coming to study the Quran in Djenné's madrassas.
On 20 January 2006 the sight of a team of men hacking at the roof of the mosque sparked a riot in the town.
In the mosque the mob ripped out the ventilation fans that had been presented by the US Embassy at the time of the Iraq War and then went on a rampage through the town.
The Great Sphinx of Giza, commonly referred to as the Sphinx of Giza or just the Sphinx, is a limestone statue of a reclining sphinx, a mythical creature.
Furthermore, the angle and location of the south wall of the enclosure suggests the causeway connecting Khafre's Pyramid and Valley Temple already existed before the Sphinx was planned.
When the Stele was re-excavated in 1925, the lines of text referring to Khaf flaked off and were destroyed.
The cult of the Sphinx continued into medieval times.
Alexandria, Rosetta, Damietta, Cairo and the Giza Pyramids are described repeatedly, but not necessarily comprehensively.
Seven years after visiting Giza, André Thévet (Cosmographie de Levant, 1556) described the Sphinx as "the head of a colossus, caused to be made by Isis, daughter of Inachus, then so beloved of Jupiter".
Johannes Helferich's (1579) Sphinx is a pinched-face, round-breasted woman with a straight haired wig; the only edge over Thévet is that the hair suggests the flaring lappets of the headdress.
Although certain tracts on the Stela are likely accurate, this passage is contradicted by archaeological evidence, thus considered to be Late Period historical revisionism, a purposeful fake, created by the local priests as an attempt to imbue the contemporary Isis temple with an ancient history it never had.
Recent discoveries, however, strongly show that it was really not built before the reign of Khafre, in the fourth dynasty."
Maspero believed the Sphinx to be "the most ancient monument in Egypt".
Part of its headdress had fallen off in 1926 due to erosion, which had also cut deeply into its neck.
The layer in which the head was sculpted is much harder.
Other tales ascribe it to being the work of Mamluks.
According to al-Maqrīzī, many people living in the area believed that the increased sand covering the Giza Plateau was retribution for al-Dahr's act of defacement.
Al-Minufi stated that the Alexandrian Crusade in 1365 was divine punishment for a Sufi sheikh of the khanqah of Sa'id breaking off the nose.
The idea is considered pseudoarchaeology by academia, because no textual or archaeological evidence supports this to be the reason for the orientation of the Sphinx.
There is a long history of speculation about hidden chambers beneath the Sphinx, by esoteric figures such as H. Spencer Lewis.
It is believed to be the second most visited historical site in Egypt; only the Giza pyramid complex near Cairo receives more visits.
The three other parts, the Precinct of Mut, the Precinct of Montu, and the dismantled Temple of Amenhotep IV, are closed to the public.
The original temple was destroyed and partially restored by Hatshepsut, although another pharaoh built around it in order to change the focus or orientation of the sacred area.
Construction of temples started in the Middle Kingdom and continued into Ptolemaic times.
The deities represented range from some of the earliest worshiped to those worshiped much later in the history of the Ancient Egyptian culture.
These architraves may have been lifted to these heights using levers.
If stone had been used for the ramps, they would have been able to use much less material.
Final carving was executed after the drums were put in place so that it was not damaged while being placed.
The city of Thebes does not appear to have been of great significance before the Eleventh Dynasty and previous temple building there would have been relatively small, with shrines being dedicated to the early deities of Thebes, the Earth goddess Mut and Montu.
Amun (sometimes called Amen) was long the local tutelary deity of Thebes.
Major construction work in the Precinct of Amun-Re took place during the Eighteenth Dynasty, when Thebes became the capital of the unified Ancient Egypt.
Another of her projects at the site, Karnak's Red Chapel or Chapelle Rouge, was intended as a barque shrine and originally may have stood between her two obelisks.
Known as the unfinished obelisk, it provides evidence of how obelisks were quarried.
The last major change to the Precinct of Amun-Re's layout was the addition of the First Pylon and the massive enclosure walls that surround the whole precinct, both constructed by Nectanebo I of the Thirtieth Dynasty.
The Karnak temple complex is first described by an unknown Venetian in 1589, although his account gives no name for the complex.
Protais' writing about their travel was published by Melchisédech Thévenot (Relations de divers voyages curieux, 1670s–1696 editions) and Johann Michael Vansleb (The Present State of Egypt, 1678).
Following excavation and restoration works by the Johns Hopkins University team, led by Betsy Bryan (see below) the Precinct of Mut has been opened to the public.
In 2006, Betsy Bryan presented her findings of one festival that included apparent intentional overindulgence in alcohol.
These findings were made in the temple of Mut because when Thebes rose to greater prominence, Mut absorbed the warrior goddesses, Sekhmet and Bast, as some of her aspects.
In a later myth developed around the annual drunken Sekhmet festival, Ra, by then the sun god of Upper Egypt, created her from a fiery eye gained from his mother, to destroy mortals who conspired against him (Lower Egypt).
The Luxor Temple is a large Ancient Egyptian temple complex located on the east bank of the Nile River in the city today known as Luxor (ancient Thebes) and was constructed approximately 1400 BCE.
Four of the major mortuary temples visited by early travelers include the Temple of Seti I at Gurnah, the Temple of Hatshepsut at Deir el Bahri, the Temple of Ramesses II (i.e., Ramesseum), and the Temple of Ramesses III at Medinet Habu.
To the rear of the temple are chapels built by Amenhotep III of the 18th Dynasty, and Alexander.
This sandstone is referred to as Nubian sandstone.
Alexander Badawy, "Illusionism in Egyptian Architecture," Studies in the Ancient Oriental Civilization, 35 (1969): 23.
Along the avenue the stations were set up for ceremonies such as the Feast of Opet which held significance to temple.
Lalibela is a town in Lasta district of North Wollo Zone in Amhara Region, Ethiopia.
To Christians, Lalibela is one of Ethiopia's holiest cities, second only to Axum, and a center of pilgrimage.
The names of several places in the modern town and the general layout of the rock-cut churches themselves are said to mimic names and patterns observed by Lalibela during the time he spent as a youth in Jerusalem and the Holy Land.
Christian faith inspires many features with Biblical names – even Lalibela's river is known as the River Jordan.
Portuguese priest Francisco Álvares (1465–1540), accompanied the Portuguese Ambassador on his visit to Dawit II in the 1520s.
The next reported European visitor to Lalibela was Miguel de Castanhoso, who served as a soldier under Cristóvão da Gama and left Ethiopia in 1544.
Its pillars were likewise cut from the mountain."),
There is some controversy as to when some of the churches were constructed.
His report described two types of vernacular housing found in the area.
Saint Catherine's Monastery, officially Sacred Monastery of the God-Trodden Mount Sinai, is an Eastern Orthodox monastery located on the Sinai Peninsula, at the mouth of a gorge at the foot of Mount Sinai, near the town of Saint Catherine, Egypt.
The Saint Catherine monastery is located in the shadow of a group of three mountains; Ras Sufsafeh (possibly "Mount Horeb" c.1 km west), Jebel Arrenziyeb and Jebel Musa, the "Biblical Mount Sinai" (peak c.2 km south).
Catherine herself ordered the execution to commence.
The monastery was built by order of Emperor Justinian I (reigned 527–565), enclosing the Chapel of the Burning Bush (also known as "Saint Helen's Chapel") ordered to be built by Empress Consort Helena, mother of Constantine the Great, at the site where Moses is supposed to have seen the burning bush.
The site is sacred to Christianity, Islam, and Judaism.
During the seventh century, the isolated Christian anchorites of the Sinai were eliminated: only the fortified monastery remained.
From the time of the First Crusade, the presence of Crusaders in the Sinai until 1270 spurred the interest of European Christians and increased the number of intrepid pilgrims who visited the monastery.
The exact administrative status of the church within the Eastern Orthodox Church is ambiguous: by some, including the church itself, it is considered autocephalous, by others an autonomous church under the jurisdiction of the Greek Orthodox Church of Jerusalem.
But in 2003 Russian scholars discovered the donation act for the manuscript signed by the Council of Cairo Metochion and Archbishop Callistratus on 13 November 1869.
Palimpsests are notable for having been reused one or more times over the centuries.
Each page took approximately eight minutes to scan completely.
The large icon collection begins with a few dating to the 5th (possibly) and 6th centuries, which are unique survivals; the monastery having been untouched by Byzantine iconoclasm, and never sacked.
The conservation of its architectural structures, paintings, and books comprise much of the Foundation's purpose.
Its size reflects the relative prosperity of the time.
It was built on the site of an earlier, smaller temple also dedicated to Horus, although the previous structure was oriented east-west rather than north-south as in the present site.
The temple of Edfu fell into disuse as a religious monument following Theodosius I's persecution of pagans and edict banning non-Christian worship within the Roman Empire in 391.
Over the centuries, the temple became buried to a depth of 12 metres (39 ft) beneath drifting desert sand and layers of river silt deposited by the Nile.
In 1860 Auguste Mariette, a French Egyptologist, began the work of freeing Edfu temple from the sands.
Great Zimbabwe is a medieval city in the south-eastern hills of Zimbabwe near Lake Mutirikwe and the town of Masvingo.
Great Zimbabwe is believed to have served as a royal palace for the local monarch.
They were constructed without mortar (dry stone).
The first confirmed visits by Europeans were in the late 19th century, with investigations of the site starting in 1871.
The Great Zimbabwe area was settled by the 4th century AD.
David Beach believes that the city and its state, the Kingdom of Zimbabwe, flourished from 1200 to 1500, although a somewhat earlier date for its demise is implied by a description transmitted in the early 1500s to João de Barros.
They are known as the Hill Complex, the Valley Complex and the Great Enclosure.
The Valley Complex is divided into the Upper and Lower Valley Ruins, with different periods of occupation.
The focus of power moved from the Hill Complex in the 12th century, to the Great Enclosure, the Upper Valley and finally the Lower Valley in the early 16th century.
Other artefacts include soapstone figurines (one of which is in the British Museum), pottery, iron gongs, elaborately worked ivory, iron and copper wire, iron hoes, bronze spearheads, copper ingots and crucibles, and gold beads, bracelets, pendants and sheaths.
That international commerce was in addition to the local agricultural trade, in which cattle were especially important.
Portuguese traders heard about the remains of the medieval city in the early 16th century, and records survive of interviews and notes made by some of them, linking Great Zimbabwe to gold production and long-distance trade.
He asserted that the figurine instead appeared to date to the subsequent Ptolemaic era (c. 323–30 BC), when Alexandria-based Greek merchants would export Egyptian antiquities and pseudo-antiquities to southern Africa.
Bent had no formal archaeological training, but had travelled very widely in Arabia, Greece and Asia Minor.
They have a tradition of ancient Jewish or South Arabian descent through their male line.
The Lemba claim was also reported by a William Bolts (in 1777, to the Austrian Habsburg authorities), and by an A.A. Anderson (writing about his travels north of the Limpopo River in the 19th century).
She had first sunk three test pits into what had been refuse heaps on the upper terraces of the hill complex, producing a mix of unremarkable pottery and ironwork.
Caton Thompson immediately announced her Bantu origin theory to a meeting of the British Association in Johannesburg.
The radiocarbon evidence is a suite of 28 measurements, for which all but the first four, from the early days of the use of that method and now viewed as inaccurate, support the 12th-to-15th-centuries chronology.
The removal of gold and artefacts in amateurist diggings by early colonial antiquarians caused widespread damage, notably diggings by Richard Nicklin Hall.
Preben Kaarsholm writes that both colonial and black nationalist groups invoked Great Zimbabwe's past to support their vision of the country's present, through the media of popular history and of fiction.
Pikirayi and Kaarsholm suggest that this presentation of Great Zimbabwe was partly intended to encourage settlement and investment in the area.
In 1980 the new internationally recognised independent country was renamed for the site, and its famous soapstone bird carvings were retained from the Rhodesian flag and Coat of Arms as a national symbol and depicted in the new Zimbabwean flag.
An example of the former is Ken Mufuka's booklet, although the work has been heavily criticised.
It was created to preserve the rich history of this country which was facing a dark future due to globalisation.
The site exhibits a multitude of architectural styles, reminiscent of styles seen in central Mexico and of the Puuc and Chenes styles of the Northern Maya lowlands.
The city may have had the most diverse population in the Maya world, a factor that could have contributed to the variety of architectural styles at the site.
One possible translation for Itza is "enchanter (or enchantment) of the water," from its (itz), "sorcerer", and ha, "water".
This form preserves the phonemic distinction between chʼ and ch, since the base word chʼeʼen (which, however, is not stressed in Maya) begins with a postalveolar ejective affricate consonant.
Of these cenotes, the "Cenote Sagrado" or Sacred Cenote (also variously known as the Sacred Well or Well of Sacrifice), is the most famous.
Instead, the city's political organization could have been structured by a "multepal" system, which is characterized as rulership through council composed of members of elite ruling lineages.
It was, however, toward the end of the Late Classic and into the early part of the Terminal Classic that the site became a major regional capital, centralizing and dominating political, sociocultural, economic, and ideological life in the northern Maya lowlands.
Hunac Ceel supposedly prophesied his own rise to power.
While there is some archeological evidence that indicates Chichén Itzá was at one time looted and sacked, there appears to be greater evidence that it could not have been by Mayapan, at least not when Chichén Itzá was an active urban center.
After Chichén Itzá elite activities ceased, the city may not have been abandoned.
Montejo returned to Yucatán in 1531 with reinforcements and established his main base at Campeche on the west coast.
Montejo the Younger eventually arrived at Chichen Itza, which he renamed Ciudad Real.
Months passed, but no reinforcements arrived.
By 1535, all Spanish had been driven from the Yucatán Peninsula.
In 1860, Désiré Charnay surveyed Chichén Itzá and took numerous photographs that he published in Cités et ruines américaines (1863).
Augustus Le Plongeon called it "Chaacmol" (later renamed "Chac Mool", which has been the term to describe all types of this statuary found in Mesoamerica).
In 1894 the United States Consul to Yucatán, Edward Herbert Thompson, purchased the Hacienda Chichén, which included the ruins of Chichen Itza.
Thompson is most famous for dredging the Cenote Sagrado (Sacred Cenote) from 1904 to 1910, where he recovered artifacts of gold, copper and carved jade, as well as the first-ever examples of what were believed to be pre-Columbian Maya cloth and wooden weapons.
The Mexican Revolution and the following government instability, as well as World War I, delayed the project by a decade.
At the same time, the Mexican government excavated and restored El Castillo (Temple of Kukulcán) and the Great Ball Court.
Thompson, who was in the United States at the time, never returned to Yucatán.
In 1944 the Mexican Supreme Court ruled that Thompson had broken no laws and returned Chichen Itza to his heirs.
The first was sponsored by the National Geographic, and the second by private interests.
The city was built upon broken terrain, which was artificially levelled in order to build the major architectural groups, with the greatest effort being expended in the levelling of the areas for the Castillo pyramid, and the Las Monjas, Osario and Main Southwest groups.
Many of these stone buildings were originally painted in red, green, blue and purple colors.
Just like gothic cathedrals in Europe, colors provided a greater sense of completeness and contributed greatly to the symbolic impact of the buildings.
The Puuc-style building feature the usual mosaic-decorated upper façades characteristic of the style but differ from the architecture of the Puuc heartland in their block masonry walls, as opposed to the fine veneers of the Puuc region proper.
At the base of the balustrades of the northeastern staircase are carved heads of a serpent.
After several false starts, they discovered a staircase under the north side of the pyramid.
The Mexican government excavated a tunnel from the base of the north staircase, up the earlier pyramid's stairway to the hidden temple, and opened it to tourists.
In one panel, one of the players has been decapitated; the wound emits streams of blood in the form of wriggling snakes.
At the south end is another, much bigger temple, but in ruins.
Inside there is a large mural, much destroyed, which depicts a battle scene.
It is built in a combination Maya and Toltec styles, with a staircase ascending each of its four sides.
In its interior archeologists discovered a collection of large cones carved out of stone, the purpose of which is unknown.
Its name comes from a series of altars at the top of the structure that are supported by small carved figures of men with upraised arms, called "atlantes."
This complex is analogous to Temple B at the Toltec capital of Tula, and indicates some form of cultural contact between the two regions.
This temple encases or entombs a former structure called The Temple of the Chac Mool.
To the south of the Group of a Thousand Columns is a group of three, smaller, interconnected buildings.
A section of the upper façade with a motif of x's and o's is displayed in front of the structure.
The Temple of Xtoloc is a recently restored temple outside the Osario Platform is.
Between the Xtoloc temple and the Osario are several aligned structures: The Platform of Venus, which is similar in design to the structure of the same name next to Kukulkan (El Castillo), the Platform of the Tombs, and a small, round structure that is unnamed.
The Casa Colorada (Spanish for "Red House") is one of the best preserved buildings at Chichen Itza.
In 2009, INAH restored a small ball court that adjoined the back wall of the Casa Colorada.
This building's name has been long used by the local Maya, and some authors mention that it was named after a deer painting over stucco that doesn't exist anymore.
The Spanish named this complex Las Monjas ("The Nuns" or "The Nunnery"), but it was a governmental palace.
These texts frequently mention a ruler by the name of Kʼakʼupakal.
It gets its name from the stone spiral staircase inside.
The long, western-facing façade has seven doorways.
The southern end of the building has one entrance.
Inside one of the chambers, near the ceiling, is a painted hand print.
The location of the cave has been well known in modern times.
E. Wyllys Andrews IV also explored the cave in the 1930s.
On 15 September 1959, José Humberto Gómez, a local guide, discovered a false wall in the cave.
Even before the book was published, Benjamin Norman and Baron Emanuel von Friedrichsthal traveled to Chichen after meeting Stephens, and both published the results of what they found.
In 1923, Governor Carrillo Puerto officially opened the highway to Chichen Itza.
In 1930, the Mayaland Hotel opened, just north of the Hacienda Chichén, which had been taken over by the Carnegie Institution.
In 1972, Mexico enacted the Ley Federal Sobre Monumentos y Zonas Arqueológicas, Artísticas e Históricas (Federal Law over Monuments and Archeological, Artistic and Historic Sites) that put all the nation's pre-Columbian monuments, including those at Chichen Itza, under federal ownership.
Tour guides will also demonstrate a unique the acoustical effect at Chichen Itza: a handclap before the in front of the staircase the El Castillo pyramid will produce by an echo that resembles the chirp of a bird, similar to that of the quetzal as investigated by Declercq.
INAH, which manages the site, has closed a number of monuments to public access.
Originally a project of real estate developer and former New York State Senator William H. Reynolds, the building was constructed by Walter Chrysler, the head of the Chrysler Corporation.
An annex was completed in 1952, and the building was sold by the Chrysler family the next year, with numerous subsequent owners.
The era was characterized by profound social and technological changes.
The following year, Chrysler was named Time magazine's "Person of the Year".
Following the end of World War I, European and American architects came to see simplified design as the epitome of the modern era and Art Deco skyscrapers as symbolizing progress, innovation, and modernity.
Prior to his involvement in planning the building, Reynolds was best known for developing Coney Island's Dreamland amusement park.
In 1927, after several years of delays, Reynolds hired the architect William Van Alen to design a forty-story building there.
Van Alen and Severance complemented each other, with Van Alen being an original, imaginative architect and Severance being a shrewd businessperson who handled the firm's finances.
The proposal was changed again two weeks later, with official plans for a 63-story building.
The adjacent 56-story Chanin Building was also under construction.
These plans were approved in June 1928.
He instead devised an alternate design for the Reynolds Building, which was published in August 1928.
A contract was awarded on October 28, and demolition was completed on November 9.
From late 1928 to early 1929, modifications to the design of the dome continued.
Lower down, the design was affected by Walter Chrysler's intention to make the building the Chrysler Corporation's headquarters, and as such, various architectural details were modeled after Chrysler automobile products, such as the hood ornaments of the Plymouth (see ).
Construction of the building proper began on January 21, 1929.
Despite a frantic steelwork construction pace of about four floors per week, no workers died during the construction of the skyscraper's steelwork.
40 Wall Street and the Chrysler Building started competing for the distinction of "world's tallest building".
On October 23, 1929, one week after surpassing the Woolworth Building's height and one day before the catastrophic Wall Street Crash of 1929 started, the spire was assembled.
Even the New York Herald Tribune, which had virtually continuous coverage of the tower's construction, did not report on the spire's installation until days after the spire had been raised.
In the lobby of the building, a bronze plaque that read "in recognition of Mr. Chrysler's contribution to civic advancement" was unveiled.
The Chrysler Building was appraised at $14 million, but was exempt from city taxes per an 1859 law that gave tax exemptions to sites owned by the Cooper Union.
Van Alen's satisfaction at these accomplishments was likely muted by Walter Chrysler's later refusal to pay the balance of his architectural fee.
However, the lawsuit against Chrysler markedly diminished Van Alen's reputation as an architect, which, along with the effects of the Great Depression and negative criticism, ended up ruining his career.
In 1944, the corporation filed plans to build a 38-story annex to the east of the building, at 666 Third Avenue.
The stone for the original building was no longer manufactured, and had to be specially replicated.
The family sold the building in 1953 to William Zeckendorf for its assessed price of $18 million.
At the time, it was reported to be the largest real estate sale in New York City's history.
In 1961, the building's stainless steel elements, including the needle, crown, gargoyles, and entrance doors, were polished for the first time.
The company purchased the building for $35 million.
The spire underwent a restoration that was completed in 1995.
The cleaning received the New York Landmarks Conservancy's Lucy G. Moses Preservation Award for 1997.
In June 2008, it was reported that the Abu Dhabi Investment Council was in negotiations to buy TMW's 75% economic interest, a 15% interest from Tishman Speyer Properties in the building, and a share of the Trylons retail structure next door for US$800 million.
This resulted in a 21% decrease in the building's total energy consumption, a 64% decrease in water consumption, and an 81% rate of waste being recycled.
The Ethics of Philosophical Practice."
Philosophy is rationally critical thinking, of a more or less systematic kind about the general nature of the world (metaphysics or theory of existence), the justification of belief (epistemology or theory of knowledge), and the conduct of life (ethics or theory of value).
Metaphysics replaces the unargued assumptions embodied in such a conception with a rational and organized body of beliefs about the world as a whole.
In the 19th century, the growth of modern research universities led academic philosophy and other disciplines to professionalize and specialize.
In Against the Logicians the Pyrrhonist philosopher Sextus Empiricus detailed the variety of ways in which the ancient Greek philosophers had divided philosophy, noting that this three-part division was agreed to by Plato, Aristotle, Xenocrates, and the Stoics.
Other ancient philosophical traditions influenced by Socrates included Cynicism, Cyrenaicism, Stoicism, and Academic Skepticism.
Some key Medieval thinkers include St. Augustine, Thomas Aquinas, Boethius, Anselm and Roger Bacon.
Major modern philosophers include Spinoza, Leibniz, Locke, Berkeley, Hume, and Kant.
Babylonian astronomy also included much philosophical speculations about cosmology which may have influenced the Ancient Greeks.
Later Jewish philosophy came under strong Western intellectual influences and includes the works of Moses Mendelssohn who ushered in the Haskalah (the Jewish Enlightenment), Jewish existentialism, and Reform Judaism.
Islamic philosophy is the philosophical work originating in the Islamic tradition and is mostly done in Arabic.
Early Islamic philosophy developed the Greek philosophical traditions in new innovative directions.
The work of Aristotle was very influential among philosophers such as Al-Kindi (9th century), Avicenna (980 – June 1037) and Averroes (12th century).
Ibn Khaldun was an influential thinker in philosophy of history.
Indian philosophical traditions share various key concepts and ideas, which are defined in different ways and accepted or rejected by the different traditions.
Indian philosophy is commonly grouped based on their relationship to the Vedas and the ideas contained in them.
The schools which align themselves with the thought of the Upanishads, the so-called "orthodox" or "Hindu" traditions, are often classified into six darśanas or philosophies:Sānkhya, Yoga, Nyāya, Vaisheshika, Mimāmsā and Vedānta.
They also reflect a tolerance for a diversity of philosophical interpretations within Hinduism while sharing the same foundation.
There are also other schools of thought which are often seen as "Hindu", though not necessarily orthodox (since they may accept different scriptures as normative, such as the Shaiva Agamas and Tantras), these include different schools of Shavism such as Pashupata, Shaiva Siddhanta, non-dual tantric Shavism (i.e. Trika, Kaula, etc.).
The denial that a human being possesses a "self" or "soul" is probably the most famous Buddhist teaching.
Jain philosophy is one of the only two surviving "unorthodox" traditions (along with Buddhism).
Jain thought holds that all existence is cyclic, eternal and uncreated.
In these regions, Buddhist thought developed into different philosophical traditions which used various languages (like Tibetan, Chinese and Pali).
The philosophy of the Theravada school is dominant in Southeast Asian countries like Sri Lanka, Burma and Thailand.
After the death of the Buddha, various groups began to systematize his main teachings, eventually developing comprehensive philosophical systems termed Abhidharma.
There were numerous schools, sub-schools, and traditions of Buddhist philosophy in ancient and medieval India.
These philosophical traditions developed metaphysical, political and ethical theories such Tao, Yin and yang, Ren and Li.
Neo-Confucianism came to dominate the education system during the Song dynasty (960–1297), and its ideas served as the philosophical basis of the imperial exams for the scholar official class.
During later Chinese dynasties like the Ming Dynasty (1368–1644) as well as in the Korean Joseon dynasty (1392–1897) a resurgent Neo-Confucianism led by thinkers such as Wang Yangming (1472–1529) became the dominant school of thought, and was promoted by the imperial state.
In the Modern era, Chinese thinkers incorporated ideas from Western philosophy.
For example, New Confucianism, led by figures such as Xiong Shili, has become quite influential.
Another trend in modern Japanese philosophy was the "National Studies" (Kokugaku) tradition.
During the 17th century, Ethiopian philosophy developed a robust literary tradition as exemplified by Zera Yacob.
Another feature of the indigenous American worldviews was their extension of ethics to non-human animals and plants.
The theory of Teotl can be seen as a form of Pantheism.
Nevertheless, U.S. Department of Education reports from the 1990s indicate that few women ended up in philosophy, and that philosophy is one of the least gender-proportionate fields in the humanities, with women making up somewhere between 17% and 30% of philosophy faculty according to some studies.
See also "Characteristics and Attitudes of Instructional Faculty and Staff in the Humanities."
Its primary investigations include how to live a good life and identifying standards of morality.
Epistemologists examine putative sources of knowledge, including perceptual experience, reason, memory, and testimony.
It arose early in Pre-Socratic philosophy and became formalized with Pyrrho, the founder of the earliest Western school of philosophical skepticism.
Empiricism places emphasis on observational evidence via sensory experience as the source of knowledge.
Rationalism is associated with a priori knowledge, which is independent of experience (such as logic and mathematics).
Metaphysics includes cosmology, the study of the world in its entirety and ontology, the study of being.
Essence is the set of attributes that make an object what it fundamentally is and without which it loses its identity while accident is a property that the object has, without which the object can still retain its identity.
Because sound reasoning is an essential element of all sciences, social sciences and humanities disciplines, logic became a formal science.
New York: Oxford University Press.
However, most students of academic philosophy later contribute to law, journalism, religion, sciences, politics, business, or various arts.
In analytic philosophy, philosophy of language investigates the nature of language, the relations between language, language users, and the world.
These writers were followed by Ludwig Wittgenstein (Tractatus Logico-Philosophicus), the Vienna Circle as well as the logical positivists, and Willard Van Orman Quine.
He criticized conventionalism because it led to the bizarre consequence that anything can be conventionally denominated by any name.
To do this, he pointed out that compound words and phrases have a range of correctness.
However, by the end of the Cratylus, he had admitted that some social conventions were also involved, and that there were faults in the idea that phonemes had individual meanings.
He separated all things into categories of species and genus.
However, since Aristotle took these similarities to be constituted by a real commonality of form, he is more often considered a proponent of "moderate realism".
This lektón was the meaning (or sense) of every term.
There were several noteworthy philosophers of language in the medieval period.
The scholastics of the high medieval period, such as Ockham and John Duns Scotus, considered logic to be a scientia sermocinalis (science of language).
The phenomena of vagueness and ambiguity were analyzed intensely, and this led to an increasing interest in problems related to the use of syncategorematic words such as and, or, not, if, and every.
The suppositio of a term is the interpretation that is given of it in a specific context.
Such a classification scheme is the precursor of modern distinctions between use and mention, and between language and metalanguage.
One part of the common sentence is the lexical word, which is composed of nouns, verbs, and adjectives.
Philosophical semantics tends to focus on the principle of compositionality to explain the relationship between meaningful parts and whole sentences.
It is possible to use the concept of functions to describe more than just how lexical meanings work: they can also be used to describe the meaning of a sentence.
A propositional function is an operation of language that takes an entity (in this case, the horse) as an input and outputs a semantic fact (i.e., the proposition that is represented by "The horse is red").
Is language acquisition a special faculty in the mind?
The first is the behaviorist perspective, which dictates that not only is the solid bulk of language learned, but it is learned via conditioning.
Nativist models assert that there are specialized devices in the brain that are dedicated to language acquisition.
Linguists Sapir and Whorf suggested that language limited the extent to which members of a "linguistic community" can think about certain subjects (a hypothesis paralleled in George Orwell's novel Nineteen Eighty-Four).
The stark opposite to the Sapir–Whorf position is the notion that thought (or, more broadly, mental content) has priority over language.
Another argument is that it is difficult to explain how signs and symbols on paper can represent anything meaningful unless some sort of meaning is infused into them by the contents of the mind.
Another tradition of philosophers has attempted to show that language and thought are coextensive – that there is no way of explaining one without the other.
To an extent, the theoretical underpinnings to cognitive semantics (including the notion of semantic framing) suggest the influence of language upon thought.
There are studies that prove that languages shape how people understand causality.
However, Spanish or Japanese speakers would be more likely to say "the vase broke itself".
Spanish and Japanese speakers did not remember the agents of accidental events as well as did English speakers.
In one study German and Spanish speakers were asked to describe objects having opposite gender assignment in those two languages.
To describe a "bridge", which is feminine in German and masculine in Spanish, the German speakers said "beautiful", "elegant", "fragile", "peaceful", "pretty" and "slender", and the Spanish speakers said "big", "dangerous", "long", "strong", "sturdy" and "towering".
Whether each alien was friendly or hostile was determined by certain subtle features but participants were not told what these were.
For the rest, the aliens remained nameless.
It was concluded that naming objects helps us categorize and memorize them.
Within this area, issues include: the nature of synonymy, the origins of meaning itself, our apprehension of meaning, and the nature of composition (the question of how meaningful units of language are composed of smaller meaningful parts, and how the meaning of the whole is derived from the meaning of its parts).
The ideational theory of meaning, most commonly associated with the British empiricist John Locke, claims that meanings are mental representations provoked by signs.
(See also Wittgenstein's picture theory of language.)
Cambridge, Massachusetts: Harvard University Press.
The reference theory of meaning, also known collectively as semantic externalism, views meaning to be equivalent to those things in the world that are actually connected to signs.
The traditional formulation of such a theory is that the meaning of a sentence is its method of verification or falsification.
In this version, the comprehension (and hence meaning) of a sentence consists in the hearer's ability to recognize the demonstration (mathematical, empirical or other) of the truth of the sentence.
A pragmatic theory of meaning is any theory in which the meaning (or understanding) of a sentence is determined by the consequences of its application.
Gottlob Frege was an advocate of a mediated reference theory.
Such a thought is abstract, universal and objective.
Referents are the objects in the world that words pick out.
He viewed proper names of the sort described above as "abbreviated definite descriptions" (see Theory of descriptions).
Such phrases denote in the sense that there is an object that satisfies the description.
On Frege's account, any referring expression has a sense as well as a referent.
Despite the differences between the views of Frege and Russell, they are generally lumped together as descriptivists about proper names.
Consider the name Aristotle and the descriptions "the greatest student of Plato", "the founder of logic" and "the teacher of Alexander".
He may have existed and not have become known to posterity at all or he may have died in infancy.
But this is deeply counterintuitive.
Questions inevitably arise on surrounding topics.
David Kellogg Lewis proposed a worthy reply to the first question by expounding the view that a convention is a rationally self-perpetuating regularity in behavior.
Noam Chomsky proposed that the study of language could be done in terms of the I-Language, or internal language of persons.
One fruitful source of research involves investigation into the social conditions that give rise to, or are associated with, meanings and languages.
The presumptions that prop up each theoretical view are of interest to the philosopher of language.
Rhetoric is the study of the particular words that people use to achieve the proper emotional and rational effect in the listener, be it to persuade, provoke, endear, or teach.
It also has applications to the study and interpretation of law, and helps give insight to the logical concept of the domain of discourse.
The idea of language is often related to that of logic in its Greek sense as "logos", meaning discourse or dialectic.
Heidegger combines phenomenology with the hermeneutics of Wilhelm Dilthey.
For example, Sein (being), the word itself, is saturated with multiple meanings.
Heidegger claims writing is only a supplement to speech, because even readers construct or contribute their own "talk" while reading.
In Truth and Method, Gadamer describes language as "the medium in which substantive understanding and agreement take place between two people.
Paul Ricœur, on the other hand, proposed a hermeneutics which, reconnecting with the original Greek sense of the term, emphasized the discovery of hidden meanings in the equivocal terms (or "symbols") of ordinary language.
It allows them to take advantage of and effectively manipulate the external world in order to create meaning for themselves and transmit this meaning to others.
Some important figures in the history of semiotics, are Charles Sanders Peirce, Roland Barthes, and Roman Jakobson.
19th century romanticism emphasised human agency and free will in meaning construction.
Humanistic views are challenged by biological theories of language which consider languages as natural phenomena.
In Neo-Darwinism, Richard Dawkins and other proponents of cultural replicator theories consider languages as populations of mind viruses.
Some have said that the expression stands for some real, abstract universal out in the world called "rocks".
The issue here can be explicated if we examine the proposition "Socrates is a Man".
These two things connect in some way or overlap.
Another perspective is to consider "man" to be a property of the entity, "Socrates".
Some of the most prominent members of this tradition of formal semantics include Tarski, Carnap, Richard Montague and Donald Davidson.
They did not believe that the social and practical dimensions of linguistic meaning could be captured by any attempts at formalization using the tools of logic.
Many of its ideas have been absorbed by theorists such as Kent Bach, Robert Brandom, Paul Horwich and Stephen Neale.
In Word and Object, Quine asks readers to imagine a situation in which they are confronted with a previously undocumented, group of indigenous people where they must attempt to make sense of the utterances and gestures that its members make.
All that can be done is to examine the utterance as a part of the overall linguistic behaviour of the individual, and then use these observations to interpret the meaning of all other utterances.
For Quine, as for Wittgenstein and Austin, meaning is not something that is associated with a single word or sentence, but is rather something that, if it can be attributed at all, can only be attributed to a whole language.
The specific instances of vagueness that most interest philosophers of language are those where the existence of "borderline cases" makes it seemingly impossible to say whether a predicate is true or false.
The philosophy of mathematics is the branch of philosophy that studies the assumptions, foundations, and implications of mathematics.
Today, some philosophers of mathematics aim to give accounts of this form of inquiry and its products as they stand, while others emphasize a role for themselves that goes beyond simple interpretation to critical analysis.
Greek philosophy on mathematics was strongly influenced by their study of geometry.
Therefore, 3, for example, represented a certain multitude of units, and was thus not "truly" a number.
These earlier Greek ideas of numbers were later upended by the discovery of the irrationality of the square root of two.
According to legend, fellow Pythagoreans were so traumatized by this discovery that they murdered Hippasus to stop him from spreading his heretical idea.
It is a profound puzzle that on the one hand mathematical truths seem to have a compelling inevitability, but on the other hand the source of their "truthfulness" remains elusive.
Three schools, formalism, intuitionism, and logicism, emerged at this time, partly in response to the increasingly widespread worry that mathematics as it stood, and analysis in particular, did not live up to the standards of certainty and rigor that had been taken for granted.
As the century unfolded, the initial focus of concern expanded to an open exploration of the fundamental axioms of mathematics, the axiomatic approach having been taken for granted since the time of Euclid around 300 BCE as the natural basis for mathematics.
In mathematics, as in physics, new and unexpected ideas had arisen and significant changes were coming.
I do not think that the difficulties that philosophy finds with classical mathematics today are genuine difficulties; and I think that the philosophical interpretations of mathematics that we are being offered on every hand are wrong, and that "philosophical interpretation" is just what mathematics doesn't need.
Many working mathematicians have been mathematical realists; they see themselves as discoverers of naturally occurring objects.
Certain principles (e.g., for any two objects, there is a collection of objects consisting of precisely those two objects) could be directly seen to be true, but the continuum hypothesis conjecture might prove undecidable just on the basis of such principles.
Both Plato's cave and Platonism have meaningful, not just superficial connections, because Plato's ideas were preceded and probably influenced by the hugely popular Pythagoreans of ancient Greece, who believed that the world was, quite literally, generated by numbers.
This view bears resemblances to many things Husserl said about mathematics, and supports Kant's idea that mathematics is synthetic a priori.)
Full-blooded Platonism is a modern variation of Platonism, which is in reaction to the fact that different sets of mathematical entities can be proven to exist depending on the axioms and inference rules employed (for instance, the law of the excluded middle, and the axiom of choice).
Set-theoretic realism (also set-theoretic Platonism) a position defended by Penelope Maddy, is the view that set theory is about a single universe of sets.
They attributed the paradox to "vicious circularity" and built up what they called ramified type theory to deal with it.
Even Russell said that this axiom did not really belong to logic.
Frege required Basic Law V to be able to give an explicit definition of the numbers, but all the properties of numbers can be derived from Hume's principle.
But it does allow the working mathematician to continue in his or her work and leave such problems to the philosopher or scientist.
Hilbert aimed to show the consistency of mathematical systems from the assumption that the "finitary arithmetic" (a subsystem of the usual arithmetic of the positive integers, chosen to be philosophically uncontroversial) was consistent.
Thus, in order to show that any axiomatic system of mathematics is in fact consistent, one needs to first assume the consistency of a system of mathematics that is in a sense stronger than the system to be proven consistent.
Other formalists, such as Rudolf Carnap, Alfred Tarski, and Haskell Curry, considered mathematics to be the investigation of formal axiom systems.
The more games we study, the better.
The main critique of formalism is that the actual mathematical ideas that occupy mathematicians are far removed from the string manipulation games mentioned above.
Brouwer, the founder of the movement, held that mathematical objects arise from the a priori forms of the volitions that inform the perception of empirical objects.
The axiom of choice is also rejected in most intuitionistic set theories, though in some versions it is accepted.
In this view, mathematics is an exercise of the human intuition, not a game played with meaningless symbols.
Likewise all the other whole numbers are defined by their places in a structure, the number line.
However, its central claim only relates to what kind of entity a mathematical object is, not to what kind of existence mathematical objects or structures have (not, in other words, to their ontology).
Structures are held to have a real but abstract and immaterial existence.
Structures are held to exist inasmuch as some concrete system exemplifies them.
Like nominalism, the post rem approach denies the existence of abstract mathematical objects with properties other than their place in a relational structure.
It is held that mathematics is not universal and does not exist in any real sense, other than in human brains.
However, the human mind has no special claim on reality or approaches to it built out of math.
The most accessible, famous, and infamous treatment of this perspective is Where Mathematics Comes From, by George Lakoff and Rafael E. Núñez.
Franklin, James (2014), "An Aristotelian Realist Philosophy of Mathematics", Palgrave Macmillan, Basingstoke; Franklin, James (2021), "Mathematics as a science of non-abstract reality: Aristotelian realist philosophies of mathematics," Foundations of Science 25.
The Euclidean arithmetic developed by John Penn Mayberry in his book The Foundations of Mathematics in the Theory of Sets also falls into the Aristotelian realist tradition.
Edmund Husserl, in the first volume of his Logical Investigations, called "The Prolegomena of Pure Logic", criticized psychologism thoroughly and sought to distance himself from it.
That is, since physics needs to talk about electrons to say why light bulbs behave as they do, then electrons must exist.
It argues for the existence of mathematical entities as the best explanation for experience, thus stripping mathematics of being distinct from the other sciences.
This grew from the increasingly popular assertion in the late 20th century that no one foundation of mathematics could be ever proven to exist.
A mathematical argument can transmit falsity from the conclusion to the premises just as well as it can transmit truth from the premises to the conclusion.
He gave a detailed argument for this in New Directions.
If mathematics is just as empirical as the other sciences, then this suggests that its results are just as fallible as theirs, and just as contingent.
For a philosophy of mathematics that attempts to overcome some of the shortcomings of Quine and Gödel's approaches by taking aspects of each see Penelope Maddy's Realism in Mathematics.
He started with the "betweenness" of Hilbert's axioms to characterize space without coordinatizing it, and then added extra relations between points to do the work formerly done by vector fields.
By this account, there are no metaphysical or epistemological problems special to mathematics.
However, while on an empiricist view the evaluation is some sort of comparison with "reality", social constructivists emphasize that the direction of mathematical research is dictated by the fashions of the social group performing it or by the needs of the society financing it.
But social constructivists argue that mathematics is in fact grounded by much uncertainty: as mathematical practice evolves, the status of previous mathematics is cast into doubt, and is corrected to the degree it is required or desired by the current mathematical community.
The social nature of mathematics is highlighted in its subcultures.
Social constructivists see the process of "doing mathematics" as actually creating the meaning, while social realists see a deficiency either of human capacity to abstractify, or of human's cognitive bias, or of mathematicians' collective intelligence as preventing the comprehension of a real universe of mathematical objects.
More recently Paul Ernest has explicitly formulated a social constructivist philosophy of mathematics.
For example, the tools of linguistics are not generally applied to the symbol systems of mathematics, that is, mathematics is studied in a markedly different way from other languages.
However, the methods developed by Frege and Tarski for the study of mathematical language have been extended greatly by Tarski's student Richard Montague and other linguists working in formal semantics to show that the distinction between mathematical language and natural language may not be as great as it seems.
The assertion that "all" entities postulated in scientific theories, including numbers, should be accepted as real is justified by confirmation holism.
Field developed his views into fictionalism.
The argument hinges on the idea that a satisfactory naturalistic account of thought processes in terms of brain processes can be given for mathematical reasoning along with everything else.
Another line of defense is to maintain that abstract objects are relevant to mathematical reasoning in a way that is non-causal, and not analogous to perception.
By way of example, they provide two proofs of the irrationality of .
Paul Erdős was well known for his notion of a hypothetical "Book" containing the most elegant or beautiful mathematical proofs.
By the same token, however, philosophers of mathematics have sought to characterize what makes one proof more desirable than another when both are logically sound.
Philosophy of mind is a branch of philosophy that studies the ontology and nature of the mind and its relationship with the body.
Dualism and monism are the two central schools of thought on the mind–body problem, although nuanced views have arisen that do not fit one or the other category neatly.
Hart, W.D. (1996) "Dualism", in Samuel Guttenplan (org) A Companion to the Philosophy of Mind, Blackwell, Oxford, 265-7.
Pinel, J. Psychobiology, (1990) Prentice Hall, Inc. LeDoux, J. (2002) The Synaptic Self: How Our Brains Become Who We Are, New York:Viking Penguin.
Psychological Predicates", in W. H. Capitan and D. D. Merrill, eds.,
Secondly, intentional states of consciousness do not make sense on non-reductive physicalism.
Someone's desire for a slice of pizza, for example, will tend to cause that person to move his or her body in a specific manner and in a specific direction to obtain what he or she wants.
Robinson, H. (1983): "Aristotelian dualism", Oxford Studies in Ancient Philosophy 1, 123–44.
They would almost certainly deny that the mind simply is the brain, or vice versa, finding the idea that there is just one ontological entity at play to be too mechanistic or unintelligible.
So, for example, one can reasonably ask what a burnt finger feels like, or what a blue sky looks like, or what nice music sounds like to a person.
There are qualia involved in these mental events that seem particularly difficult to reduce to anything physical.
Dualism must therefore explain how consciousness affects physical reality.
Knowledge, however, is apprehended by reasoning from ground to consequent.
The basic idea is that one can imagine one's body, and therefore conceive the existence of one's body, without any conscious states being associated with this body.
Others such as Dennett have argued that the notion of a philosophical zombie is an incoherent, or unlikely, concept.
It is the view that mental states, such as beliefs and desires, causally interact with physical states.
Descartes' argument depends on the premise that what Seth believes to be "clear and distinct" ideas in his mind are necessarily true.
Cambridge, MA: MIT Press (Bradford) For example, Joseph Agassi suggests that several scientific discoveries made since the early 20th century have undermined the idea of privileged access to one's own ideas.
This view was most prominently defended by Gottfried Leibniz.
These emergent properties have an independent ontological status and cannot be reduced to, or explained in terms of, the physical substrate from which they emerge.
Epiphenomenalism is a doctrine first formulated by Thomas Henry Huxley.
This view has been defended by Frank Jackson.
Panpsychism is the view that all matter has a mental aspect, or, alternatively, all objects have a unified center of experience or point of view.
An example of these disparate degrees of freedom is given by Allan Wallace who notes that it is "experientially apparent that one may be physically uncomfortable—for instance, while engaging in a strenuous physical workout—while mentally cheerful; conversely, one may be mentally distraught while experiencing physical comfort".
Mental states can cause changes in physical states and vice versa.
Experiential dualism is accepted as the conceptual framework of Madhyamaka Buddhism.
In denying the independent self-existence of all the phenomena that make up the world of our experience, the Madhyamaka view departs from both the substance dualism of Descartes and the substance monism—namely, physicalism—that is characteristic of modern science.
Indeed, physicalism, or the idea that matter is the only fundamental substance of reality, is explicitly rejected by Buddhism.
While the former commonly have mass, location, velocity, shape, size, and numerous other physical attributes, these are not generally characteristic of mental phenomena.
The fundamentally disparate nature of reality has been central to forms of eastern philosophies for over two millennia.
Physicalistic monism asserts that the only existing substance is physical, in some sense of that term to be clarified by our best science.
Although pure idealism, such as that of George Berkeley, is uncommon in contemporary Western philosophy, a more sophisticated variant called panpsychism, according to which mental experience and properties may be at the foundation of physical experience and properties, has been espoused by some philosophers such as Alfred North Whitehead and David Ray Griffin.
A third possibility is to accept the existence of a basic substance that is neither physical nor mental.
Introspective reports on one's own interior mental life are not subject to careful examination for accuracy and cannot be used to form predictive generalizations.
Parallel to these developments in psychology, a philosophical behaviorism (sometimes called logical behaviorism) was developed.
These philosophers reasoned that, if mental states are something material, but not behavioral, then mental states are probably identical to internal states of the brain.
According to token identity theories, the fact that a certain brain state is connected with only one mental state of a person does not have to mean that there is an absolute correlation between types of mental state and types of brain state.
Finally, Wittgenstein's idea of meaning as use led to a version of functionalism as a theory of meaning, further developed by Wilfrid Sellars and Gilbert Harman.
Hence, the question arises whether there can still be a non-reductive physicalism.
Davidson uses the thesis of supervenience: mental states supervene on physical states, but are not reducible to them. "
The brain goes on from one moment of time to another; the brain thus has identity through time.
An analogy of the self or the “I” would be the flame of a candle.
The flame displays a type of continuity in that the candle does not go out while it is burning, but there is not really any identity of the flame from one moment to another over time.
Similarly, it is an illusion that one is the same individual who walked into class this morning.
This is analogous to physical properties of the brain giving rise to a mental state.
The Churchlands often invoke the fate of other, erroneous popular theories and ontologies that have arisen in the course of history.
Some philosophers argue that this is because there is an underlying conceptual confusion.
Rather it should simply be accepted that human experience can be described in different ways—for instance, in a mental and in a biological vocabulary.
The brain is simply the wrong context for the use of mental vocabulary—the search for mental states of the brain is therefore a category error or a sort of fallacy of reasoning.
And it is characteristic of a mental state that it has some experiential quality, e.g. of pain, that it hurts.
The existence of cerebral events, in and of themselves, cannot explain why they are accompanied by these corresponding qualitative experiences.
This follows from an assumption about the possibility of reductive explanations.
The 20th-century German philosopher Martin Heidegger criticized the ontological assumptions underpinning such a reductive model, and claimed that it was impossible to make sense of experience in these terms.
This problem of explaining introspective first-person aspects of mental states and consciousness in general in terms of third-person quantitative neuroscience is called the explanatory gap.
There are two separate categories involved and one cannot be reduced to the other.
For Nagel, science is not yet able to explain subjective experience because it has not yet arrived at the level or kind of knowledge that is required.
This property of mental states entails that they have contents and semantic referents and can therefore be assigned truth values.
But mental ideas or judgments are true or false, so how then can mental states (ideas or judgments) be natural processes?
If the fact is true, then the idea is true; otherwise, it is false.
Since mental processes are intimately related to bodily processes, the descriptions that the natural sciences furnish of human beings play an important role in the philosophy of mind.
Within the field of neurobiology, there are many subdisciplines that are concerned with the relations between mental and physical states and processes: Sensory neurophysiology investigates the relation between the processes of perception and stimulation.
Lastly, evolutionary biology studies the origins and development of the human nervous system and, in as much as this is the basis of the mind, also describes the ontogenetic and phylogenetic development of mental phenomena beginning from their most primitive stages.
A simple example is multiplication.
This question has been propelled into the forefront of much philosophical debate because of investigations in the field of artificial intelligence (AI).
The objective of strong AI, on the contrary, is a computer with consciousness similar to that of human beings.
The Turing test has received many criticisms, among which the most famous is probably the Chinese room thought experiment formulated by Searle.
Psychology investigates the laws that bind these mental states to each other or with inputs and outputs to the human organism.
A law of the psychology of forms says that objects that move in the same direction are perceived as related to each other.
It includes research on intelligence and behavior, especially focusing on how information is represented, processed, and transformed (in faculties such as perception, language, memory, reasoning, and emotion) within nervous systems (human or other animal) and machines (e.g. computers).
Nonetheless, Hegel's work differs radically from the style of Anglo-American philosophy of mind.
Phenomenology, founded by Edmund Husserl, focuses on the contents of the human mind (see noema) and how processes shape our experiences.
This is the case for materialistic determinists.
Some take this reasoning a step further: people cannot determine by themselves what they want and what they do.
Those who adopt this position suggest that the question "Are we free?"
It is not appropriate to identify freedom with indetermination.
The most important compatibilist in the history of the philosophy was David Hume.
These philosophers affirm the course of the world is either a) not completely determined by natural law where natural law is intercepted by physically independent agency, b) determined by indeterministic natural law only, or c) determined by indeterministic natural law in line with the subjective effort of physically non-reducible agency.
They argue as follows: if our will is not determined by anything, then we desire what we desire by pure chance.
The idea of a self as an immutable essential nucleus derives from the idea of an immaterial soul.
Mantranga, the principal governing body of these states, consisted of the King, Prime Minister, Commander in chief of army, Chief Priest of the King.
The Arthashastra provides an account of the science of politics for a wise ruler, policies for foreign affairs and wars, the system of a spy state and surveillance and economic stability of the state.
The major philosophies during the period, Confucianism, Legalism, Mohism, Agrarianism and Taoism, each had a political aspect to their philosophical schools.
Legalism advocated a highly authoritarian government based on draconian punishments and laws.
By the late ancient period, however, the "traditionalist" Asharite view of Islam had in general triumphed.
However, in Western thought, it is generally supposed that it was a specific area peculiar merely to the great philosophers of Islam: al-Kindi (Alkindus), al-Farabi (Abunaser), İbn Sina (Avicenna), Ibn Bajjah (Avempace) and Ibn Rushd (Averroes).
For example, the ideas of the Khawarij in the very early years of Islamic history on Khilafa and Ummah, or that of Shia Islam on the concept of Imamah are considered proofs of political thought.
Aristotleanism flourished as the Islamic Golden Age saw rise to a continuation of the peripatetic philosophers who implemented the ideas of Aristotle in the context of the Islamic world.
Other notable political philosophers of the time include Nizam al-Mulk, a Persian scholar and vizier of the Seljuq Empire who composed the Siyasatnama, or the "Book of Government" in English.
Perhaps the most influential political philosopher of medieval Europe was St. Thomas Aquinas who helped reintroduce Aristotle's works, which had only been transmitted to Catholic Europe through Muslim Spain, along with the commentaries of Averroes.
Others, like Nicole Oresme in his Livre de Politiques, categorically denied this right to overthrow an unjust ruler.
That work, as well as The Discourses, a rigorous analysis of classical antiquity, did much to influence modern political thought in the West.
At any rate, Machiavelli presents a pragmatic and somewhat consequentialist view of politics, whereby good and evil are mere means used to bring about an end—i.e., the acquisition and maintenance of absolute power.
These theorists were driven by two basic questions: one, by what right or need do people form states; and two, what the best form for a state could be.
The term "government" would refer to a specific group of people who occupied the institutions of the state, and create the laws and ordinances by which the people, themselves included, would be bound.
It can also be understood as the free market idea applied to international trade.
The most outspoken critic of the church in France was François Marie Arouet de Voltaire, a representative figure of the enlightenment.
My one regret in dying is that I cannot aid you in this noble enterprise, the finest and most respectable which the human mind can point out."
Locke stood to refute Sir Robert Filmer's paternally founded political theory in favor of a natural system based on nature in a particular given system.
Unlike Aquinas's preponderant view on the salvation of the soul from original sin, Locke believes man's mind comes into this world as tabula rasa.
Though one could be worried about restrictions on liberty by benevolent monarchs or aristocrats, the traditional worry is that when rulers are politically unaccountable to the governed they will rule in their own interests, rather than the interests of the governed.
Justice involves duties that are perfect duties—that is, duties that are correlated with rights.
He uses, On Liberty to discuss gender equality in society.
The Liberty of the Ancients was participatory republican liberty, which gave the citizens the right to directly influence politics through debates and votes in the public assembly.
Ancient Liberty was also limited to relatively small and homogenous societies, in which the people could be conveniently gathered together in one place to transact public affairs.
Instead, the voters would elect representatives, who would deliberate in Parliament on behalf of the people and would save citizens from the necessity of daily political involvement.
In Leviathan, Hobbes set out his doctrine of the foundation of states and legitimate governments and creating an objective science of morality.
In that state, each person would have a right, or license, to everything in the world.
Published in 1762, it became one of the most influential works of political philosophy in the Western tradition.
Those who think themselves the masters of others are indeed greater slaves than they."
The industrial revolution produced a parallel revolution in political thought.
In the mid-19th century, Marxism was developed, and socialism in general gained increasing popular support, mostly from the urban working class.
Unlike Marx who believed in historical materialism, Hegel believed in the Phenomenology of Spirit.
In the Anglo-American world, anti-imperialism and pluralism began gaining currency at the turn of the 20th century.
This was the time of Jean-Paul Sartre and Louis Althusser, and the victories of Mao Zedong in China and Fidel Castro in Cuba, as well as the events of May 1968, led to increased interest in revolutionary ideology, especially by the New Left.
Colonialism and racism were important issues that arose.
The rise of feminism, LGBT social movements and the end of colonial rule and of the political exclusion of such minorities as African Americans and sexual minorities in the developed world has led to feminist, postcolonial, and multicultural thought becoming significant.
Rawls used a thought experiment, the original position, in which representative parties choose principles of justice for the basic structure of society from behind a veil of ignorance.
Contemporaneously with the rise of analytic ethics in Anglo-American thought, in Europe, several new lines of philosophy directed at the critique of existing societies arose between the 1950s and 1980s.
Along somewhat different lines, a number of other continental thinkers—still largely influenced by Marxism—put new emphases on structuralism and on a "return to Hegel".
Another debate developed around the (distinct) criticisms of liberal political theory made by Michael Walzer, Michael Sandel and Charles Taylor.
Communitarians tend to support greater local control as well as economic and social policies which encourage the growth of social capital.
A pair of overlapping political perspectives arising toward the end of the 20th century are republicanism (or neo- or civic-republicanism) and the capability approach.
To a republican the mere status as a slave, regardless of how that slave is treated, is objectionable.
Both the capability approach and republicanism treat choice as something which must be resourced.
Notable for the theories that humans are social animals, and that the polis (Ancient Greek city state) existed to bring about the good life appropriate to such animals.
Burke was one of the biggest supporters of the American Revolution.
Chomsky is a leading critic of U.S. foreign policy, neoliberalism and contemporary state capitalism, the Israeli–Palestinian conflict, and mainstream news media.
William E. Connolly: Helped introduce postmodern philosophy into political theory, and promoted new theories of Pluralism and agonistic democracy.
Thomas Hill Green: Modern liberal thinker and early supporter of positive freedom.
His early work was heavily influenced by the Frankfurt School.
He advocated free-market capitalism in which the main role of the state is to maintain the rule of law and let spontaneous order develop.
David Hume: Hume criticized the social contract theory of John Locke and others as resting on a myth of some actual agreement.
Most famous for the United States Declaration of Independence.
Argued that an international organization was needed to preserve world peace.
He departed from Hobbes in that, based on the assumption of a society in which moral values are independent of governmental authority and widely shared, he argued for a government with power limited to the protection of personal property.
One of the founders of Western Marxism.
Gave an account of statecraft in a realistic point of view instead of relying on idealism.
As a political theorist, he believed in separation of powers and proposed a comprehensive set of checks and balances that are necessary to protect the rights of an individual from the tyranny of the majority.
Introduced the concept of "repressive desublimation", in which social control can operate not only by direct control, but also by manipulation of desire.
Created the concept of ideology in the sense of (true or false) beliefs that shape and control social actions.
Mencius: One of the most important thinkers in the Confucian school, he is the first theorist to make a coherent argument for an obligation of rulers to the ruled.
Montesquieu: Analyzed protection of the people by a "balance of powers" in the divisions of a state.
His interpreters have debated the content of his political philosophy.
Plato: Wrote a lengthy dialog The Republic in which he laid out his political philosophy: citizens should be divided into three categories.
Ayn Rand: Founder of Objectivism and prime mover of the Objectivist and Libertarian movements in mid-twentieth-century America.
The government was to be separated from economics the same way and for the same reasons it was separated from religion.
Adam Smith: Often said to have founded modern economics; explained emergence of economic benefits from the self-interested behavior ("the invisible hand") of artisans and traders.
Socrates: Widely considered the founder of Western political philosophy, via his spoken influence on Athenian contemporaries; since Socrates never wrote anything, much of what we know about him and his teachings comes through his most famous student, Plato.
Max Stirner: Important thinker within anarchism and the main representative of the anarchist current known as individualist anarchism.
Other forms of social philosophy include political philosophy and jurisprudence, which are largely concerned with the societies of state and government and their functioning.
Pre-Socratic philosophy, also known as early Greek philosophy, is ancient Greek philosophy before Socrates.
Their work and writing has been almost entirely lost.
Pre-Socratic philosophy began in the 6th century BCE with the three Milesians: Thales, Anaximander, and Anaximenes.
Xenophanes is known for his critique of the anthropomorphism of gods.
The Eleatic school (Parmenides, Zeno of Elea, and Melissus) followed in the 5th century BCE.
Anaxagoras and Empedocles offered a pluralistic account of how the universe was created.
It was first used by the German philosopher J.A. Eberhard as "vorsokratische Philosophie''' in the late 18th century.
The term comes with drawbacks, as several of the pre-Socratics were highly interested in ethics and how to live the best life.
According to James Warren, the distinction between the pre-Socratic philosophers and philosophers of the classical era is demarcated not so much by Socrates, but by geography and what texts survived.
Scholar André Laks distinguishes two traditions of separating pre-Socratics from Socratics, dating back to the classical era and running through current times.
Many of the works are titled Peri Physeos, or On Nature, a title probably attributed later by other authors.
Adding more difficulty to their interpretation is the obscure language they used.
Theophrastus, Aristotle's successor, wrote an encyclopedic book Opinion of the Physicists that was the standard work about the pre-Socratics in ancient times.
Scholars now use this book to reference the fragments using a coding scheme called Diels–Kranz numbering.
After that is a code regarding whether the fragment is a testimonia, coded as "A", or "B" if is a direct quote from the philosopher.
The pre-Socratic era lasted about two centuries, during which the expanding Persian Achaemenid Empire was stretching to the west, while the Greeks were advancing in trade and sea routes, reaching Cyprus and Syria.
The Greeks revolted in 499 BCE, but ultimately were defeated in 494 BCE.
Several factors contributed to the birth of pre-Socratic philosophy in Ancient Greece.
Another factor was the ease and frequency of intra-Greek travel, which led to the blending and comparison of ideas.
The democratic political system of independent poleis also contributed to the rise of philosophy.
The philosophers' ideas, were, to a certain extent, answers to questions that were subtly present in the work of Homer and Hesiod.
They are considered predecessors of the pre-Socratics since they seek to address the origin of the world and to organize traditional folklore and legends systematically.
The first pre-Socratic philosophers also traveled extensively to other lands, meaning that pre-Socratic thought had roots abroad as well as domestically.
The pre-Socratic philosophers shared the intuition that there was a single explanation that could explain both the plurality and the singularity of the whole – and that explanation would not be direct actions of the gods.
Many sought the material principle (arche) of things, and the method of their origin and disappearance.
In their effort to make sense of the cosmos they coined new terms and concepts such as rhythm, symmetry, analogy, deductionism, reductionism, mathematicazion of nature and others.
It could mean the beginning or origin with the undertone that there is an effect on the things to follow.
This may have been because of a lack of instruments, or because of a tendency to view the world as a unity, undeconstructable, so it would be impossible for an external eye to observe tiny fractions of nature under experimental control.
Systematic because they tried to universalize their findings.
The pre-Socratics were not atheists; however, they minimized the extent of the gods' involvement in natural phenomena such as thunder or totally eliminated the gods from the natural world.
The first phase of pre-Socratic philosophy, mainly the Milesians, Xenophanes, and Heraclitus, consisted of rejecting traditional cosmogony and attempting to explain nature based on empirical observations and interpretations.
The Eleatics were also monists (believing that only one thing exists and everything else is just a transformation of it).
He is considered the first western philosopher since he was the first to use reason, to use proof, and to generalize.
Thales may have been of Phoenician ancestry.
Thales, though, advanced geometry with his abstract deductive reasoning reaching universal generalizations.
Thales visited Sardis, as many Greeks then, where astronomical records were kept and used astronomical observations for practical matters (oil harvesting).
He attributed the origin of the world to an element instead of a divine being.
He was a member of the elite of Miletus, wealthy and a statesman.
In response to Thales, he postulated as the first principle an undefined, unlimited substance without qualities (apeiron), out of which the primary opposites, hot and cold, moist and dry, became differentiated.
He is also known for speculating on the origin of mankind.
He also wrote a book on nature in prose.
He was a well-traveled poet whose primary interests were theology and epistemology.
He famously said that if oxen, horses, or lions could draw, they would draw their gods as oxen, horses, or lions.
Xenophanes also offered naturalistic explanations for phenomena such as the sun, the rainbow and St. Elmo's fire.
While Xenophanes was a pessimist about the capability of humans to reach knowledge, he also believed in gradual progress through critical thinking.
Heraclitus posited that all things in nature are in a state of perpetual flux.
Fire becomes water and earth and vice versa.
There, Heraclitus claims we can not step into the same river twice, a position summarized with the slogan ta panta rhei (everything flows).
Another key concept of Heraclitus is that opposites somehow mirror each other, a doctrine called unity of opposites.
Heraclitus' doctrine on the unity of opposites suggests that unity of the world and its various parts is kept through the tension produced by the opposites.
A fundamental idea in Heraclitus is logos, an ancient Greek word with a variety of meanings; Heraclitus might have used a different meaning of the word with each usage in his book.
Some decades later he had to flee Croton and relocate to Metapontum.
They advanced his ideas, reaching the claim that everything consists of numbers, the universe is made by numbers and everything is a reflection of analogies and geometrical relations.
Their way of life was ascetic, restraining themselves from various pleasures and food.
Other pre-Socratic philosophers mocked Pythagoras for his belief in reincarnation.
Pythagoreanism influenced later Christian currents as Neoplatonism, and its pedagogical methods were adapted by Plato.
According to Aristotle and Diogenes Laertius, Xenophanes was Parmenides' teacher, and it is debated whether Xenophanes should also be considered an Eleatic.
He was the first to deduce that the earth is spherical.
Parmenides wrote a hard to interpret poem, named On Nature or On What-is, that substantially influenced later Greek philosophy.
The poem consists of three parts, the proem (i.e., preface), the Way of Truth and the Way of Opinion.
The Way of Truth was then, and is still today, considered of much more importance.
Hence, all the things that we think to be true, even ourselves, are false representations.
The goddess teaches Kouros to use his reasoning to understand whether various claims are true or false, discarding senses as fallacious.
Zeno and Melissus continued Parmenides' thought on cosmology.
He tried to explain why we think various non-existent objects exist.
Anaxagoras was born in Ionia, but was the first major philosopher to emigrate to Athens.
Anaxagoras was also a major influence on Socrates.
Interpretations differ as to what he meant.
All objects were mixtures of various elements, such as air, water, and others.
Nous was also considered a building block of the cosmos, but it exists only in living objects.
Anaxagoras advanced Milesian thought on epistemology, striving to establish an explanation that could be valid for all natural phenomena.
According to Diogenes Laertius, Empedocles wrote two books in the form of poems: Peri Physeos (On nature) and the Katharmoi (Purifications).
He also continues Anaxagoras' thought on the four "roots" (i.e., classical elements), that by intermixing, they create all things around us.
These two forces are opposite and by acting upon the material of the four roots unite in harmony or tear apart the four roots, with the resulting mixture being all things that exist.
They are most famous for their atomic cosmology even though their thought included many other fields of philosophy, such as ethics, mathematics, aesthetics, politics, and even embryology.
Democritus and Leucippus were skeptics regarding the reliability of our senses, but they were confident that motion exists.
Atoms move within the void, interact with each other, and form the plurality of the world we live in, in a purely mechanical manner.
Democritus concluded that since everything is atoms and void, several of our senses are not real but conventional.
They attacked traditional thinking, from gods to morality, paving the way for further advances of philosophy and other disciplines such as drama, social sciences, mathematics, and history.
The sophists taught rhetoric and how to address issues from multiple viewpoints.
Gorgias wrote a book named On Nature, in which he attacked the Eleatics' concepts of What-is and What-is-not.
Antiphon placed natural law against the law of the city.
He attempted to explain both the variety and unity of the cosmos.
Diogenes of Apollonia returned to Milesian monism, but with a rather more elegant thought.
While Pythagoras and Empedocles linked their self-proclaimed wisdom to their divinely inspired status, they tried to teach or urge mortals to seek the truth about the natural realm—Pythagoras by means of mathematics and geometry and Empedocles by exposure to experiences.
They attacked the traditional representations of gods that Homer and Hesiod had established and put Greek popular religion under scrutiny, initiating the schism between natural philosophy and theology.
The theological thought starts with the Milesian philosophers.
Xenophanes set three preconditions for God: he had to be all good, immortal and not resembling humans in appearance, which had a major impact on western religious thought.
Anaxagoras asserted that cosmic intelligence (nous) gives life to things.
It was Hippocrates (often hailed as the father of medicine) who separated – but not completely – the two domains.
Ever-transforming nature is summarized by Heraclitus' axiom panta rhei (everything is in a state of flux).
The pre-Socratics sought to understand the various aspects of nature by means of rationalism, observations, and offering explanations that could be deemed as scientific, giving birth to what became Western rationalism.
Anaximander offered the principle of sufficient reason, a revolutionary argument that would also yield the principle that nothing comes out of nothing.
Xenophanes also advanced a critique of anthropomorphic religion by highlighting in a rational way the inconsistency of depictions of the gods in Greek popular religion.
Other pre-Socratics also sought to answer the question of arche, offering various answers, but the first step towards scientific thought was already taken.
The philosophic thought produced by the pre-Socratics heavily influenced later philosophers, historians and playwrights.
The naturalists impressed young Socrates and he was interested in the quest for the substance of the cosmos, but his interest waned as he became steadily more focused on epistemology, virtue, and ethics rather than the natural world.
Cicero analyzed his views on the pre-Socratics in his Tusculanae Disputationes, as he distinguished the theoretical nature of pre-Socratic thought from previous "sages" who were interested in more practical issues.
Aristotle discussed the pre-Socratics in the first book of Metaphysics, as an introduction to his own philosophy and the quest for arche.
Francis Bacon, a 16th-century philosopher known for advancing the scientific method, was probably the first philosopher of the modern era to use pre-Socratic axioms extensively in his texts.
Friedrich Nietzsche admired the pre-Socratics deeply, calling them "tyrants of the spirit" to mark their antithesis and his preference against Socrates and his successors.
According to his narrative, limned in many of his books, the pre-Socratic era was the glorious era of Greece, while the so-called Golden Age that followed was an age of decay, according to Nietzsche.
Even though this period – known in its earlier part as the Spring and Autumn period and the Warring States period – in its latter part was fraught with chaos and bloody battles, it is also known as the Golden Age of Chinese philosophy because a broad range of thoughts and ideas were developed and discussed freely.
Taoism (also called Daoism), a philosophy which emphasizes the Three Jewels of the Tao: compassion, moderation, and humility, while Taoist thought generally focuses on nature, the relationship between humanity and the cosmos; health and longevity; and wu wei (action through inaction).
Agrarianism, or the School of Agrarianism, which advocated peasant utopian communalism and egalitarianism.
Scholars from this school were good orators, debaters and tacticians.
The School of "Minor-talks", which was not a unique school of thought, but a philosophy constructed of all the thoughts which were discussed by and originated from normal people on the street.
Confucianism was particularly strong during the Han Dynasty, whose greatest thinker was Dong Zhongshu, who integrated Confucianism with the thoughts of the Zhongshu School and the theory of the Five Elements.
In particular, they refuted the assumption of Confucius as a godlike figure and considered him as the greatest sage, but simply a human and mortal.
Buddhism arrived in China around the 1st century AD, but it was not until the Northern and Southern, Sui and Tang Dynasties that it gained considerable influence and acknowledgement.
This leads to the inquiry into the one being that underlies the diversity of empirical phenomena and the origin of all things.
Seven Rishis — Atri, Bharadwaja, Gautama, Jamadagni, Kasyapa, Vasishtha, Viswamitra.
Ancient Greek philosophy arose in the 6th century BC, marking the end of the Greek Dark Ages.
It dealt with a wide variety of subjects, including astronomy, epistemology, mathematics, political philosophy, ethics, metaphysics, ontology, logic, biology, rhetoric and aesthetics.
Clear, unbroken lines of influence lead from ancient Greek and Hellenistic philosophers to Roman philosophy, Early Islamic philosophy, Medieval Scholasticism, the European Renaissance and the Age of Enlightenment.
But they taught themselves to reason.
Thales inspired the Milesian school of philosophy and was followed by Anaximander, who argued that the substratum or arche could not be water or any of the classical elements but was instead something "unlimited" or "indefinite" (in Greek, the apeiron).
Contrary to the Milesian school, which posits one stable element as the arche, Heraclitus taught that panta rhei ("everything flows"), the closest element to this eternal flux being fire.
Being, he argued, by definition implies eternality, while only that which is can be thought; a thing which is, moreover, cannot be more or less, and so the rarefaction and condensation of the Milesians is impossible regarding Being; lastly, as movement requires that something exist apart from the thing moving (viz.
In support of this, Parmenides' pupil Zeno of Elea attempted to prove that the concept of motion was absurd and as such motion did not exist.
Leucippus also proposed an ontological pluralism with a cosmogony based on two main elements: the vacuum and atoms.
While philosophy was an established pursuit prior to Socrates, Cicero credits him as "the first who brought philosophy down from the heavens, placed it in cities, introduced it into families, and obliged it to examine into life and morals, and good and evil."
The fact that many conversations involving Socrates (as recounted by Plato and Xenophon) end without having reached a firm conclusion, or aporetically, has stimulated debate over the meaning of the Socratic method.
Socrates taught that no one desires what is bad, and so if anyone does something that truly is bad, it must be unwillingly or out of ignorance; consequently, all virtue is knowledge.
The great statesman Pericles was closely associated with this new learning and a friend of Anaxagoras, however, and his political opponents struck at him by taking advantage of a conservative reaction against the philosophers; it became a crime to investigate the things above the heavens or below the earth, subjects considered impious.
Socrates, however, is the only subject recorded as charged under this law, convicted, and sentenced to death in 399 BCE (see Trial of Socrates).
Plato casts Socrates as the main interlocutor in his dialogues, deriving from them the basis of Platonism (and by extension, Neoplatonism).
Zeno of Citium in turn adapted the ethics of Cynicism to articulate Stoicism.
Along with Xenophon, Plato is the primary source of information about Socrates' life and beliefs and it is not always easy to distinguish between the two.
Although rule by a wise man would be preferable to rule by law, the wise cannot help but be judged by the unwise, and so in practice, rule by law is deemed necessary.
Plato's dialogues also have metaphysical themes, the most famous of which is his theory of forms.
It likens most humans to people tied up in a cave, who look only at shadows on the walls and have no other conception of reality.
If these travelers then re-entered the cave, the people inside (who are still only familiar with the shadows) would not be equipped to believe reports of this 'outside world'.
Bertrand Russell, A History of Western Philosophy (New York: Simon & Schuster, 1972).
He criticizes the regimes described in Plato's Republic and Laws, and refers to the theory of forms as "empty words and poetic metaphors."
Antisthenes was inspired by the ascetism of Socrates, and accused Plato of pride and conceit.
It was founded by Euclides of Megara, one of the pupils of Socrates.
Pyrrhonism places the attainment of ataraxia (a state of equanimity) as the way to achieve eudaimonia.
His ethics were based on "the pursuit of pleasure and the avoidance of pain".
Their logical contributions still feature in contemporary propositional calculus.
This skeptical period of ancient Platonism, from Arcesilaus to Philo of Larissa, became known as the New Academy, although some ancient authors added further subdivisions, such as a Middle Academy.
While the objective of the Pyrrhonists was the attainment of ataraxia, after Arcesilaus the Academic skeptics did not hold up ataraxia as the central objective.
In the Byzantine Empire Greek ideas were preserved and studied, and not long after the first major expansion of Islam, however, the Abbasid caliphs authorized the gathering of Greek manuscripts and hired translators to increase their prestige.
Medieval philosophy is the philosophy that existed through the Middle Ages, the period roughly extending from the fall of the Western Roman Empire in the 5th century to the Renaissance in the 15th century.
With the possible exceptions of Avicenna and Averroes, medieval thinkers did not consider themselves philosophers at all: for them, the philosophers were the ancient pagan writers such as Plato and Aristotle.
One of the most heavily debated things of the period was that of faith versus reason.
It is generally agreed that it begins with Augustine (354–430) who strictly belongs to the classical period, and ends with the lasting revival of learning in the late eleventh century, at the beginning of the high medieval period.
In later periods, monks were used for training administrators and churchmen.
Much of the work of Aristotle was unknown in the West in this period.
Augustine is regarded as the greatest of the Church Fathers.
For over a thousand years, there was hardly a Latin work of theology or philosophy that did not quote his writing, or invoke his authority.
He became consul in 510 in the kingdom of the Ostrogoths.
He wrote commentaries on these works, and on the Isagoge by Porphyry (a commentary on the Categories).
Around this period several doctrinal controversies emerged, such as the question of whether God had predestined some for salvation and some for damnation.
Is the host the same as Christ's historical body?
This period also witnessed a revival of scholarship.
Later, under St. Abbo of Fleury (abbot 988–1004), head of the reformed abbey school, Fleury enjoyed a second golden age.
The early 13th century witnessed the culmination of the recovery of Greek philosophy.
Powerful Norman kings gathered men of knowledge from Italy and other areas into their courts as a sign of their prestige.
The universities developed in the large cities of Europe during this period, and rival clerical orders within the Church began to battle for political and intellectual control over these centers of educational life.
The great representatives of Dominican thinking in this period were Albertus Magnus and (especially) Thomas Aquinas, whose artful synthesis of Greek rationalism and Christian doctrine eventually came to define Catholic philosophy.
Aquinas showed how it was possible to incorporate much of the philosophy of Aristotle without falling into the "errors" of the Commentator Averroes.
The problem of evil: The classical philosophers had speculated on the nature of evil, but the problem of how an all-powerful, all-knowing, loving God could create a system of things in which evil exists first arose in the medieval period.
However, from the fourteenth century onward, the increasing use of mathematical reasoning in natural philosophy prepared the way for the rise of science in the early modern period.
In the earlier period, writers such as Peter Abelard wrote commentaries on the works of the Old logic (Aristotle's Categories, On interpretation, and the Isagoge of Porphyry).
(The word 'intentionality' was revived by Franz Brentano, who was intending to reflect medieval usage).
The designation "Renaissance philosophy" is used by scholars of intellectual history to refer to the thought of the period running in Europe roughly between 1355 and 1650 (the dates shift forward for central and northern Europe and for areas such as Spanish America, India, Japan, and China under European influence).
The assumption that Aristotle's works were foundational to an understanding of philosophy did not wane during the Renaissance, which saw a flourishing of new translations, commentaries, and other interpretations of his works, both in Latin and in the vernacular.
The latter, similar in some ways to modern debates, examined the pros and cons of particular philosophical positions or interpretations.
Plato, known directly only through two and a half dialogues in the Middle Ages, came to be known through numerous Latin translations in fifteenth century Italy, culminating in the hugely influential translation of his complete works by Marsilio Ficino in Florence in 1484.
Not all Renaissance humanists followed his example in all things, but Petrarch contributed to a broadening of his time's 'canon' (pagan poetry had previously been considered frivolous and dangerous), something that happened in philosophy as well.
Other movements from ancient philosophy also re-entered the mainstream.
This position came under increasing strain in the Renaissance, as various thinkers claimed that Thomas's classifications were inaccurate, and that ethics were the most important part of morality.
As we have seen, they believed that philosophy could be brought under the wing of rhetoric.
In 1416–1417, Leonardo Bruni, the pre-eminent humanist of his time and chancellor of Florence, re-translated Aristotle's Ethics into a more flowing, idiomatic and classical Latin.
The driving conviction was that philosophy should be freed of its technical jargon so that more people would be able to read it.
Desiderius Erasmus, the great Dutch humanist, even prepared a Greek edition of Aristotle, and eventually those teaching philosophy in the universities had to at least pretend that they knew Greek.
Once it had been determined, however, that Italian was a language with literary merit and that it could carry the weight of philosophical discussion, numerous efforts in this direction started to appear, particularly from the 1540s onward.
We know that debates about the freedom of the will continued to flare up (for instance, in the famous exchanges between Erasmus and Martin Luther), that Spanish thinkers were increasingly obsessed with the notion of nobility, that duelling was a practice that generated a large literature in the sixteenth century (was it permissible or not?).
We must not forget that most philosophers of the time were at least nominal, if not devout, Christians, that the sixteenth century saw both the Protestant and the Catholic reformations, and that Renaissance philosophy culminates with the period of the Thirty Years' War (1618–1648).
In conclusion, like any other moment in the history of thought Renaissance philosophy cannot be considered to have provided something entirely new nor to have continued for centuries to repeat the conclusions of its predecessors.
Modern philosophy is philosophy developed in the modern era and associated with modernity.
By the 17th and 18th centuries the major figures in philosophy of mind, epistemology, and metaphysics were roughly divided into two main groups.
The "Empiricists," by contrast, held that knowledge must begin with sensory experience.
Other important figures in political philosophy include Thomas Hobbes and Jean-Jacques Rousseau.
Kant sparked a storm of philosophical work in Germany in the early nineteenth century, beginning with German idealism.
Karl Marx appropriated both Hegel's philosophy of history and the empirical ethics dominant in Britain, transforming Hegel's ideas into a strictly materialist form, setting the grounds for the development of a science of society.
Arthur Schopenhauer took idealism to the conclusion that the world was nothing but the futile endless interplay of images and desires, and advocated atheism and pessimism.
Descartes argued that many predominant Scholastic metaphysical doctrines were meaningless or false.
He tries to set aside as much as he possibly can of all his beliefs, to determine what if anything he knows for certain.
From this basis he builds his knowledge back up again.
While historicism also acknowledges the role of experience, it differs from empiricism by assuming that sensory data cannot be understood without considering the historical and cultural circumstances in which observations are made.
As such empiricism is first and foremost characterized by the ideal to let observational data "speak for themselves", while the competing views are opposed to this ideal.
In other words: Empiricism as a concept has to be constructed along with other concepts, which together make it possible to make important discriminations between different ideals underlying contemporary science.
Epistemologically, idealism manifests as a skepticism about the possibility of knowing any mind-independent thing.
It describes a process where theory is extracted from practice, and applied back to practice to form what is called intelligent practice.
Brian Leiter (2006) webpage “Analytic” and “Continental” Philosophy.
Contemporary philosophy is the present period in the history of Western philosophy beginning at the early 20th century with the increasing professionalization of the discipline and the rise of analytic and continental philosophy.
Germany was the first country to professionalize philosophy.
Furthermore, unlike many of the sciences for which there has come to be a healthy industry of books, magazines, and television shows meant to popularize science and communicate the technical results of a scientific field to the general populace, works by professional philosophers directed at an audience outside the profession remain rare.
Each division organises a large annual conference.
Among its many other tasks, the association is responsible for administering many of the profession's top honors.
This development was roughly contemporaneous with work by Gottlob Frege and Bertrand Russell inaugurating a new philosophical method based on the analysis of language via modern logic (hence the term "analytic philosophy").
Some philosophers, such as Richard Rorty and Simon Glendinning, argue that this "analytic–continental" divide is inimical to the discipline as a whole.
Afterwards, analytic and continental philosophers differ on the importance and influence of subsequent philosophers on their respective traditions.
Although, since analytic and continental philosophy have such starkly different views of philosophy after Kant, continental philosophy is also often understood in an extended sense to include any post-Kant philosophers or movements important to continental philosophy but not analytic philosophy.
Thus continental philosophy tends toward historicism, where analytic philosophy tends to treat philosophy in terms of discrete problems, capable of being analyzed apart from their historical origins.
The major orthodox schools arose sometime between the start of the Common Era and the Gupta Empire.
These religio-philosophical traditions were later grouped under the label Hinduism.
Western scholars regard Hinduism as a fusion or synthesis of various Indian cultures and traditions, with diverse roots and no single founder.
Indian philosophers developed a system of epistemological reasoning (pramana) and logic and investigated topics such as Ontology (metaphysics, Brahman-Atman, Sunyata-Anatta), reliable means of knowledge (epistemology, Pramanas), value system (axiology) and other topics.
Later developments include the development of Tantra and Iranian-Islamic influences.
Nyāya traditionally accepts four Pramanas as reliable means of gaining knowledge – Pratyakṣa (perception), Anumāṇa (inference), Upamāṇa (comparison and analogy) and Śabda (word, testimony of past or present reliable experts).
This philosophy held that the universe was reducible to paramāṇu (atoms), which are indestructible (anitya), indivisible, and have a special kind of dimension, called “small” (aṇu).
Later Vaiśeṣikas (Śrīdhara and Udayana and Śivāditya) added one more category abhava (non-existence).
Because of their focus on textual study and interpretation, Mīmāṃsā also developed theories of philology and the philosophy of language which influenced other Indian schools.
The distinguishing features of Jain philosophy include a mind-body dualism, denial of a creative and omnipotent God, karma, an eternal and uncreated universe, non-violence, the theory of the multiple facets of truth, and morality based on liberation of the soul.
It has also been called a model of philosophical liberalism for its insistence that truth is relative and multifaceted and for its willingness to accommodate all possible view-points of the rival philosophies.
Cārvāka philosophers like Brihaspati were extremely critical of other schools of philosophy of the time.
It is the dominant philosophical tradition in Tibet and Southeast Asian countries like Sri Lanka and Burma.
Later Buddhist philosophical traditions developed complex phenomenological psychologies termed 'Abhidharma'.
This tradition contributed to what has been called an "epistemological turn" in Indian philosophy.
Important exponents of Buddhist modernism include Anagarika Dharmapala (1864–1933) and the American convert Henry Steel Olcott, the Chinese modernists Taixu (1890–1947) and Yin Shun (1906–2005), Zen scholar D.T. Suzuki, and the Tibetan Gendün Chöphel (1903–1951).
Anthropology is the scientific study of humanity, concerned with human behavior, human biology, cultures and societies, in both the present and past, including past human species.
Biological or physical anthropology studies the biological development of humans.
Various short-lived organizations of anthropologists had already been formed.
When slavery was abolished in France in 1848, the Société was abandoned.
For them, the publication of Charles Darwin's On the Origin of Species was the epiphany of everything they had begun to suspect.
There was an immediate rush to bring it into the social sciences.
His definition now became "the study of the human group, considered as a whole, in its details, and in relation to the rest of nature".
He discovered the speech center of the human brain, today called Broca's area after him.
The last two volumes were published posthumously.
He stresses that the data of comparison must be empirical, gathered by experimentation.
Waitz was influential among the British ethnologists.
Representatives from the French Société were present, though not Broca.
Previously Edward had referred to himself as an ethnologist; subsequently, an anthropologist.
One notable exception was the Berlin Society for Anthropology, Ethnology, and Prehistory (1869) founded by Rudolph Virchow, known for his vituperative attacks on the evolutionists.
The major theorists belonged to these organizations.
Practical anthropology, the use of anthropological knowledge and technique to solve specific problems, has arrived; for example, the presence of buried victims might stimulate the use of a forensic archaeologist to recreate the final scene.
This has been particularly prominent in the United States, from Boas' arguments against 19th-century racial ideology, through Margaret Mead's advocacy for gender equality and sexual liberation, to current criticisms of post-colonial oppression and promotion of multiculturalism.
In Great Britain and the Commonwealth countries, the British tradition of social anthropology tends to dominate.
Cultural anthropology is the comparative study of the manifold ways in which people make sense of the world around them, while social anthropology is the study of the relationships among individuals and groups.
There is no hard-and-fast distinction between them, and these categories overlap to a considerable degree.
This project is often accommodated in the field of ethnography.
Participant observation is one of the foundational methods of social and cultural anthropology.
The study of kinship and social organization is a central focus of sociocultural anthropology, as kinship is a human universal.
Ethnography views first-hand experience and social context as important.
Ethnomusicology can be used in a wide variety of fields, such as teaching, politics, cultural anthropology etc.
Economic Anthropology remains, for the most part, focused upon exchange.
The first of these areas was concerned with the "pre-capitalist" societies that were subject to evolutionary "tribal" stereotypes.
Why are those working in development so willing to disregard history and the lessons it might offer?
Within kinship you have two different families.
Anthropology engages often with feminists from non-Western traditions, whose perspectives and experiences can differ from those of white feminists of Europe, America, and elsewhere.
Political anthropology developed as a discipline concerned primarily with politics in stateless societies, a new development started from the 1960s, and is still unfolding: anthropologists started increasingly to study more "complex" social settings in which the presence of states, bureaucracies and markets entered both ethnographic accounts and analysis of local phenomena.
Secondly, anthropologists slowly started to develop a disciplinary concern with states and their institutions (and on the relationship between formal and informal political institutions).
It is sometimes grouped with sociocultural anthropology, and sometimes considered part of material culture.
It is also the study of the history of various ethnic groups that may or may not exist today.
Various social processes in the Western World as well as in the "Third World" (the latter being the habitual focus of attention of anthropologists) brought the attention of "specialists in 'other cultures'" closer to their homes.
It is an interdisciplinary field that overlaps with a number of other disciplines, including anthropology, ethology, medicine, psychology, veterinary medicine and zoology.
It is the study of ancient humans, as found in fossil hominid evidence such as petrifacted bones and footprints.
In 1989, a group of European and American scholars in the field of anthropology established the European Association of Social Anthropologists (EASA) which serves as a major professional organization for anthropologists working in Europe.
This is the notion that cultures should not be judged by another's values or viewpoints, but be examined dispassionately on their own terms.
Franz Boas publicly objected to US participation in World War I, and after the war he published a brief expose and condemnation of the participation of several American archaeologists in espionage in Mexico under their cover as scientists.
At the same time, David H. Price's work on American anthropology during the Cold War provides detailed accounts of the pursuit and dismissal of several anthropologists from their jobs for communist sympathies.
Numerous resolutions condemning the war in all its aspects were passed overwhelmingly at the annual meetings of the American Anthropological Association (AAA).
The Association of Social Anthropologists of the UK and Commonwealth (ASA) has called certain scholarship ethically dangerous.
One of the central characteristics is that anthropology tends to provide a comparatively more holistic account of phenomena and tends to be highly empirical.
These dynamic relationships, between what can be observed on the ground, as opposed to what can be observed by compiling many local observations remain fundamental in any kind of anthropology, whether cultural, biological, linguistic or archaeological.
On the biological or physical side, human measurements, genetic samples, nutritional data may be gathered and published as articles or monographs.
Further cultural subdivisions according to tool types, such as Olduwan or Mousterian or Levalloisian help archaeologists and other anthropologists in understanding major trends in the human past.
A cultural norm codifies acceptable conduct in society; it serves as a guideline for behavior, dress, language, and demeanor in a situation, which serves as a template for expectations in a social group.
These include expressive forms like art, music, dance, ritual, religion, and technologies like tool usage, cooking, shelter, and clothing.
The level of cultural sophistication has also sometimes been used to distinguish civilizations from less complex societies.
Mass culture refers to the mass-produced and mass mediated forms of consumer culture that emerged in the 20th century.
In the wider social sciences, the theoretical perspective of cultural materialism holds that human symbolic culture arises from the material conditions of human life, as humans create the conditions for physical survival, and that the basis of culture is found in evolved biological dispositions.
In this sense, multiculturalism values the peaceful coexistence and mutual respect between different cultures inhabiting the same planet.
In 1986, philosopher Edward S. Casey wrote, "The very word culture meant 'place tilled' in Middle English, and the same word goes back to Latin colere, 'to inhabit, care for, till, worship' and cultus, 'A cult, especially a religious one.'
Thus a contrast between "culture" and "civilization" is usually implied in these authors, even when not expressed as such.
This ability arose with the evolution of behavioral modernity in humans around 50,000 years ago and is often thought to be unique to humans.
Rein Raud, building on the work of Umberto Eco, Pierre Bourdieu and Jeffrey C. Alexander, has proposed a model of cultural change based on claims and bids, which are judged by their cognitive adequacy and endorsed or not endorsed by the symbolic authority of the cultural community in question.
Culture repositioning means the reconstruction of the cultural concept of a society.
Social conflict and the development of technologies can produce changes within a society by altering social dynamics and promoting new cultural models, and spurring or enabling generative action.
Environmental conditions may also enter as factors.
War or competition over resources may impact technological development or social dynamics.
For example, Western restaurant chains and culinary brands sparked curiosity and fascination to the Chinese as China opened its economy to international trade in the late 20th-century.
He argued that this immaturity comes not from a lack of understanding, but from a lack of courage to think independently.
Moreover, Herder proposed a collective form of Bildung: "For Herder, Bildung was the totality of experiences that provide a coherent identity, and sense of common destiny, to a people."
According to this school of thought, each ethnic group has a distinct worldview that is incommensurable with the worldviews of other groups.
He proposed that a scientific comparison of all human societies would reveal that distinct worldviews consisted of the same basic elements.
a particular way of life, whether of a people, period or a group.
In other words, the idea of "culture" that developed in Europe during the 18th and early 19th centuries reflected inequalities within European societies.
According to this way of thinking, one could classify some countries and nations as more civilized than others and some people as more cultured than others.
Other 19th-century critics, following Rousseau, have accepted this differentiation between higher and lower culture, but have seen the refinement and sophistication of high culture as corrupting and unnatural developments that obscure and distort people's essential nature.
In 1870 the anthropologist Edward Tylor (1832–1917) applied these ideas of higher versus lower culture to propose a theory of the evolution of religion.
For sociologist Georg Simmel (1858–1918), culture referred to "the cultivation of individuals through the agency of external forms which have been objectified in the course of history."
Non-material culture refers to the non-physical ideas that individuals have about their culture, including values, belief systems, rules, norms, morals, language, organizations, and institutions, while material culture is the physical evidence of a culture in the objects and architecture they make or have made.
Cultural sociology was then "reinvented" in the English-speaking world as a product of the "cultural turn" of the 1960s, which ushered in structuralist and postmodern approaches to social science.
Culture" has since become an important concept across many branches of sociology, including resolutely scientific fields like social stratification and social network analysis.
They saw patterns of consumption and leisure as determined by relations of production, which led them to focus on class relations and the organization of production.
It has since become strongly associated with Stuart Hall, who succeeded Hoggart as Director.
These practices comprise the ways people do particular things (such as watching television or eating out) in a given culture.
Watching television to view a public perspective on a historical event should not be thought of as culture unless referring to the medium of television itself, which may have been selected culturally; however, schoolchildren watching television after school with their friends to "fit in" certainly qualifies since there is no grounded reason for one's participation in this practice.
Culture" for a cultural-studies researcher not only includes traditional high culture (the culture of ruling social groups) and popular culture, but also everyday meanings and practices.
Scholars in the United Kingdom and the United States developed somewhat different versions of cultural studies after the late 1970s.
The distinction between American and British strands, however, has faded.
The main focus of an orthodox Marxist approach concentrates on the production of meaning.
Other approaches to cultural studies, such as feminist cultural studies and later American developments of the field, distance themselves from this view.
Culture psychologists began to try to explore the relationship between emotions and culture, and answer whether the human mind is independent from culture.
On the other hand, some researchers try to look for differences between people's personalities across cultures.
For example, people who are raised in a culture with an abacus are trained with distinctive reasoning style.
Basically, the Hague Convention for the Protection of Cultural Property in the Event of Armed Conflict and the UNESCO Convention for the Protection of Cultural Diversity deal with the protection of culture.
Under international law, the UN and UNESCO try to set up and enforce rules for this.
The target of the attack is the identity of the opponent, which is why symbolic cultural assets become a main target.
A festival is an event ordinarily celebrated by a community and centering on some characteristic aspect of that community and its religion or cultures.
Next to religion and folklore, a significant origin is agricultural.
Festivals often serve to fulfill specific communal purposes, especially in regard to commemoration or thanking to the gods, goddesses or saints: they're called patronal festivals.
In Ancient Greece and Rome, festivals such as the Saturnalia were closely associated with social organisation and political processes as well as religion.
In Middle English, a "festival dai" was a religious holiday.
The term "feast" is also used in common secular parlance as a synonym for any large or elaborate meal.
The most important religious festivals such as Christmas, Rosh Hashanah, Diwali, Eid al-Fitr and Eid al-Adha serve to mark out the year.
An early example is the festival established by Ancient Egyptian Pharaoh Ramesses III celebrating his victory over the Libyans.
There are numerous types of festivals in the world and most countries celebrate important events or traditions with traditional cultural events and activities.
Ancient Egyptian festivals could be either religious or political.
The Sed festival, for example, celebrated the thirtieth year of an Egyptian pharaoh's rule and then every three (or four in one case) years after that.
In the Christian liturgical calendar, there are two principal feasts, properly known as the Feast of the Nativity of our Lord (Christmas) and the Feast of the Resurrection (Easter), but minor festivals in honour of local patron saints are celebrated in almost all countries influenced by Christianity.
Buddhist religious festivals, such as Esala Perahera are held in Sri Lanka and Thailand.
Film festivals involve the screenings of several different films, and are usually held annually.
There are also specific beverage festivals, such as the famous Oktoberfest in Germany for beer.
Ancient Egyptians relied upon the seasonal inundation caused by the Nile River, a form of irrigation, which provided fertile land for crops.
Dree Festival of the Apatanis living in Lower Subansiri District of Arunachal Pradesh is celebrated every year from July 4 to 7 by praying for a bumper crop harvest.
A holiday is a day set aside by custom or by law on which normal activities, especially business or work including school, are suspended or reduced.
The degree to which normal activities are reduced by a holiday may depend on local laws, customs, the type of job held or personal choices.
In most modern societies, however, holidays serve as much of a recreational function as any other weekend days or activities.
In some cases, a holiday may only be nominally observed.
The modern use varies geographically.
For example, Monkey Day is celebrated on December 14, International Talk Like a Pirate Day is observed on September 19, and Blasphemy Day is held on September 30.
Jehovah's Witnesses annually commemorate "The Memorial of Jesus Christ's Death", but do not celebrate other holidays with any religious significance such as Easter, Christmas or New Year's.
Ahmadi Muslims additionally celebrate Promised Messiah Day, Promised Reformer Day, and Khilafat Day, but contrary to popular belief, neither are regarded as holidays.
Celtic, Norse, and Neopagan holidays follow the order of the Wheel of the Year.
Researchers in bioarchaeology combine the skill sets of human osteology, paleopathology, and archaeology, and often consider the cultural and mortuary context of the remains.
Evolutionary psychology is the study of psychological structures from a modern evolutionary perspective.
Human behavioral ecology is the study of behavioral adaptations (foraging, reproduction, ontogeny) from the evolutionary and ecologic perspectives (see behavioral ecology).
Paleoanthropology is the study of fossil evidence for human evolution, mainly using remains from extinct hominin and other primate species to determine the morphological and behavioral changes in the human lineage, as well as the environment in which human evolution occurred.
The name is even relatively new, having been 'physical anthropology' for over a century, with some practitioners still applying that term.
Some editors, see below, have rooted the field even deeper than formal science.
This became the main system through which scholars thought about nature for the next roughly 2,000 years.
He also wrote about physiognomy, an idea derived from writings in the Hippocratic Corpus.
In the 19th century, French physical anthropologists, led by Paul Broca (1824-1880), focused on craniometry while the German tradition, led by Rudolf Virchow (1821–1902), emphasized the influence of environment and disease upon the human body.
He changed the focus from racial typology to concentrate upon the study of human evolution, moving away from classification towards evolutionary process.
A race is a grouping of humans based on shared physical or social qualities into categories generally viewed as distinct by society.
Modern science regards race as a social construct, an identity which is assigned based on rules made by society.
Still others argue that, among humans, race has no taxonomic significance because all living humans belong to the same subspecies, Homo sapiens sapiens.
In South Africa, the Population Registration Act, 1950 recognized only White, Black, and Coloured, with Indians added later.
The United States Census Bureau proposed but then withdrew plans to add a new category to classify Middle Eastern and North African peoples in the U.S. Census 2020, over a dispute over whether this classification should be considered a white ethnicity or a separate race.
The establishment of racial boundaries often involves the subjugation of groups defined as racially inferior, as in the one-drop rule used in the 19th-century United States to exclude those with any amount of African ancestry from the dominant racial grouping, defined as "white".
According to geneticist David Reich, "while race may be a social construct, differences in genetic ancestry that happen to correlate to many of today's racial constructs are real."
Other dimensions of racial groupings include shared history, traditions, and language.
Socioeconomic factors, in combination with early but enduring views of race, have led to considerable suffering within disadvantaged racial groups.
Racism has led to many instances of tragedy, including slavery and genocide.
Because in some societies racial groupings correspond closely with patterns of social stratification, for social scientists studying social inequality, race can be a significant variable.
For example, in 2008, John Hartigan, Jr. argued for a view of race that focused primarily on culture, but which does not ignore the potential relevance of biology or genetics.
In this way the idea of race as we understand it today came about during the historical process of exploration and conquest which brought Europeans into contact with groups from different continents, and of the ideology of classification and typology found in the natural sciences.
A set of folk beliefs took hold that linked inherited physical differences between groups to inherited intellectual, behavioral, and moral qualities.
The 1735 classification of Carl Linnaeus, inventor of zoological taxonomy, divided the human species Homo sapiens into continental varieties of europaeus, asiaticus, americanus, and afer, each associated with a different humour: sanguine, melancholic, choleric, and phlegmatic, respectively.
Blumenbach also noted the graded transition in appearances from one group to adjacent groups and suggested that "one variety of mankind does so sensibly pass into the other, that you cannot mark out the limits between them".
It was further argued that some groups may be the result of mixture between formerly distinct populations, but that careful study could distinguish the ancestral races that had combined to produce admixed groups.
New studies of culture and the fledgling field of population genetics undermined the scientific standing of racial essentialism, leading race anthropologists to revise their conclusions about the sources of phenotypic variation.
Studies of human genetic variation show that human populations are not geographically isolated, and their genetic differences are far smaller than those among comparable subspecies.
Andreasen cited tree diagrams of relative genetic distances among populations published by Luigi Cavalli-Sforza as the basis for a phylogenetic tree of human races (p. 661).
Marks, Templeton, and Cavalli-Sforza all conclude that genetics does not provide evidence of human races.
For example, with respect to skin color in Europe and Africa, Brace writes:To this day, skin color grades by imperceptible means from Europe southward around the eastern end of the Mediterranean and up the Nile into Africa.
He further argued that one could use the term race if one distinguished between "race differences" and "the race concept".
In short, Livingstone and Dobzhansky agree that there are genetic differences among human beings; they also agree that the use of the race concept to classify people, and how the race concept is used, is a matter of social convention.
As the anthropologists Leonard Lieberman and Fatimah Linda Jackson observed, "Discordant patterns of heterogeneity falsify any description of a population as if it were genotypically or even phenotypically homogeneous".
The mid-20th-century anthropologist William C. Boyd defined race as: "A population which differs significantly from other populations in regard to the frequency of one or more of the genes it possesses.
Moreover, the anthropologist Stephen Molnar has suggested that the discordance of clines inevitably results in a multiplication of races that renders the concept itself useless.
Joanna Mountain and Neil Risch cautioned that while genetic clusters may one day be shown to correspond to phenotypic variations between groups, such assumptions were premature as the relationship between genes and complex traits remains poorly understood.
Any category you come up with is going to be imperfect, but that doesn't preclude you from using it or the fact that it has utility.
This assumed three population groups separated by large geographic ranges (European, African and East Asian).
Anthropologists such as C. Loring Brace, the philosophers Jonathan Kaplan and Rasmus Winther, and the geneticist Joseph Graves, have argued that while there it is certainly possible to find biological and genetic variation that corresponds roughly to the groupings normally defined as "continental races", this is true for almost all geographically distinct populations.
Weiss and Fullerton have noted that if one sampled only Icelanders, Mayans and Maoris, three distinct clusters would form and all other populations could be described as being clinally composed of admixtures of Maori, Icelandic and Mayan genetic materials.
Moreover, the genomic data underdetermines whether one wishes to see subdivisions (i.e., splitters) or a continuum (i.e., lumpers).
Alongside empirical and conceptual problems with "race", following the Second World War, evolutionary and social scientists were acutely aware of how beliefs about race had been used to justify discrimination, apartheid, slavery, and genocide.
Craig Venter and Francis Collins of the National Institute of Health jointly made the announcement of the mapping of the human genome in 2000.
It's not a scientific one.
Anthropologist Stephan Palmié has argued that race "is not a thing but a social relation"; or, in the words of Katya Gibel Mevorach, "a metonym", "a human invention whose criteria for differentiation are neither universal nor fixed but have always been used to manage difference."
There, racial identity was not governed by rigid descent rule, such as the one-drop rule, as it was in the United States.
These types grade into each other like the colors of the spectrum, and not one category stands significantly isolated from the rest.
New Jersey: Prentice Hall Inc, 1984.
In European context, historical resonance of "race" underscores its problematic nature.
The concept of racial origin relies on the notion that human beings can be separated into biologically distinct "races", an idea generally rejected by the scientific community.
In the United States most people who self-identify as African American have some European ancestors, while many people who identify as European American have some African or Amerindian ancestors.
The criteria for membership in these races diverged in the late 19th century.
Amerindians continue to be defined by a certain percentage of "Indian blood" (called blood quantum).
This rule meant that those that were mixed race but with some discernible African ancestry were defined as black.
The term "Hispanic" as an ethnonym emerged in the 20th century with the rise of migration of laborers from the Spanish-speaking countries of Latin America to the United States.
Three factors, country of academic education, discipline, and age, were found to be significant in differentiating the replies.
In 2007, Ann Morning interviewed over 40 American biologists and anthropologists and found significant disagreements over the nature of race, with no one viewpoint holding a majority among either group.
While he can see good arguments for both sides, the complete denial of the opposing evidence "seems to stem largely from socio-political motivation and not science at all".
In partial response to Gill's statement, Professor of Biological Anthropology C. Loring Brace argues that the reason laymen and biological anthropologists can determine the geographic ancestry of an individual can be explained by the fact that biological characteristics are clinally distributed across the planet, and that does not translate into the concept of race.
Physical anthropology texts argued that biological races exist until the 1970s, when they began to argue that races do not exist.
In February 2001, the editors of Archives of Pediatrics and Adolescent Medicine asked "authors to not use race and ethnicity when there is no biological, scientific, or sociological reason for doing so."
Morning (2008) looked at high school biology textbooks during the 1952–2002 period and initially found a similar pattern with only 35% directly discussing race in the 1983–92 period from initially 92% doing so.
In general, the material on race has moved from surface traits to genetics and evolutionary history.
She notes, "At best, one can conclude that biologists and anthropologists now appear equally divided in their beliefs about the nature of race."
33 health services researchers from differing geographic regions were interviewed in a 2008 study.
Many sociologists focused on African Americans, called Negroes at that time, and claimed that they were inferior to whites.
His solution was largely based on Al-Khwarizmi's work.
However, at some point the quadratic formula begins to lose accuracy because of round off error, while the approximate method continues to improve.
Methods of numerical approximation existed, called prosthaphaeresis, that offered shortcuts around time-consuming operations such as multiplication and taking powers and roots.
Computational algorithms for finding the solutions are an important part of numerical linear algebra, and play a prominent role in engineering, physics, chemistry, computer science, and economics.
For solutions in an integral domain like the ring of the integers, or in other algebraic structures, other theories have been developed, see Linear equation over a ring.
This allows all the language and theory of vector spaces (or more generally, modules) to be brought to bear.
Such a system is known as an underdetermined system.
The second system has a single unique solution, namely the intersection of the two lines.
Any two of these equations have a common solution.
A system of equations whose left-hand sides are linearly independent is always consistent.
This yields a system of equations with one fewer equation and one fewer unknown.
Type 3: Add to one row a scalar multiple of another.
For instance, systems with a symmetric positive definite matrix can be solved twice as fast with the Cholesky decomposition.
A completely different approach is often taken for very large systems, which would otherwise take too much time or memory.
This leads to the class of iterative methods.
In mathematics, a series is, roughly speaking, a description of the operation of adding infinitely many quantities, one after the other, to a given starting quantity.
In addition to their ubiquity in mathematics, infinite series are also widely used in other quantitative disciplines such as physics, computer science, statistics and finance.
Zeno's paradox of Achilles and the tortoise illustrates this counterintuitive property of infinite sums: Achilles runs after a tortoise, but when he reaches the position of the tortoise at the beginning of the race, the tortoise has reached a second position; when he reaches this second position, the tortoise is at a third position, and so on.
This argument does not prove that the sum is equal to 2 (although it is), but it does prove that it is at most 2.
Tests for uniform convergence include the Weierstrass' M-test, Abel's uniform convergence test, Dini's test, and the Cauchy criterion.
The convergence is uniform on closed and bounded (that is, compact) subsets of the interior of the disc of convergence: to wit, it is uniformly convergent on compact sets.
The Hilbert–Poincaré series is a formal power series used to study graded algebras.
In the 17th century, James Gregory worked in the new decimal system on infinite series and published several Maclaurin series.
Cauchy (1821) insisted on strict tests of convergence; he showed that if two series are convergent their product is not necessarily so, and with him begins the discovery of effective criteria.
A summability method is such an assignment of a limit to a subset of the set of divergent series which properly extends the classical notion of convergence.
Indian scholars have been using factorial formulas since at least the 12th century.
In functional languages, the recursive definition is often implemented directly to illustrate recursive functions.
Other implementations (such as computer software such as spreadsheet programs) can often handle larger values.
Compared to the Pickover definition of the superfactorial, the hyperfactorial grows relatively slowly.
There are, relatively speaking, no such simple solutions for factorials; no finite combination of sums, products, powers, exponential functions, or logarithms will suffice to express ; but it is possible to find a general formula for factorials using tools such as integrals and limits from calculus.
The integrals we have discussed so far involve transcendental functions, but the gamma function also arises from integrals of purely algebraic functions.
By taking limits, certain rational products with infinitely many factors can be evaluated in terms of the gamma function as well.
Its history, notably documented by Philip J. Davis in an article that won him the 1963 Chauvenet Prize, reflects many of the major developments within mathematics since the 18th century.
Instead of finding a specialized proof for each formula, it would be desirable to have a general method of identifying the gamma function.
However, the gamma function does not appear to satisfy any simple differential equation.
The Bohr–Mollerup theorem is useful because it is relatively easy to prove logarithmic convexity for any of the different formulas used to define the gamma function.
As electronic computers became available for the production of tables in the 1950s, several extensive tables for the complex gamma function were published to meet the demand, including a table accurate to 12 decimal places from the U.S. National Bureau of Standards.
In science, a formula is a concise way of expressing information symbolically, as in a mathematical formula or a chemical formula.
In mathematics, a formula generally refers to an identity which equates one mathematical expression to another, with the most important ones being mathematical theorems.
This convention, while less important in a relatively simple formula, means that mathematicians can more quickly manipulate formulas which are larger and more complex.
For example, H2O is the chemical formula for water, specifying that each molecule consists of two hydrogen (H) atoms and one oxygen (O) atom.
In empirical formulas, these proportions begin with a key element and then assign numbers of atoms of the other elements in the compound—as ratios to the key element.
Some types of ionic compounds, however, cannot be written as empirical formulas which contains only the whole numbers.
There are several types of these formulas, including molecular formulas and condensed formulas.
Functions were originally the idealization of how a varying quantity depends on another quantity.
This definition of "graph" refers to a set of pairs of objects.
When the domain and the codomain are sets of real numbers, each such pair may be thought of as the Cartesian coordinates of a point in the plane.
Occasionally, it may be identified with the function, but this hides the usual interpretation of a function as a process.
A map can have any set as its codomain, while, in some contexts, typically in older books, the codomain of a function is specifically the set of real or complex numbers.
Another common example is the error function.
Power series can be used to define functions on the domain in which they converge.
Then, the power series can be used to enlarge the domain of the function.
Parts of this may create a plot that represents (parts of) the function.
This is the canonical factorization of .
At that time, only real-valued functions of a real variable were considered, and all functions were assumed to be smooth.
Functions are now used throughout all areas of mathematics.
This is how inverse trigonometric functions are defined in terms of trigonometric functions, where the trigonometric functions are monotonic.
Usefulness of the concept of multi-valued functions is clearer when considering complex functions, typically analytic functions.
Such a function is called the principal value of the function.
Functional programming is the programming paradigm consisting of building programs by using only subroutines that behave like mathematical functions.
Except for computer-language terminology, "function" has the usual mathematical meaning in computer science.
Terms are manipulated through some rules, (the -equivalence, the -reduction, and the -conversion), which are the axioms of the theory and may be interpreted as rules of computation.
Nicolas Chuquet used a form of exponential notation in the 15th century, which was later used by Henricus Grammateus and Michael Stifel in the 16th century.
Thus they would write polynomials, for example, as .
The result is always a positive real number, and the identities and properties shown above for integer exponents remain true with these definitions for real exponents.
This function equals the usual th root for positive real radicands.
This is the starting point of the mathematical theory of semigroups.
We can again replace the set N with a cardinal number n to get Vn, although without choosing a specific standard set with cardinality n, this is defined only up to isomorphism.
Nicolas Bourbaki, Elements of Mathematics, Theory of Sets, Springer-Verlag, 2004, III.§3.5.
Iterating tetration leads to another operation, and so on, a concept named hyperoperation.
In applied settings, exponential functions model a relationship in which a constant change in the independent variable gives the same proportional change (that is, percentage increase or decrease) in the dependent variable.
This function property leads to exponential growth or exponential decay.
Similarly, the composition of onto (surjective) functions is always onto.
Then one can form chains of transformations composed together, such as .
This alternative notation is called postfix notation.
The category of sets with functions as morphisms is the prototypical category.
For example, the decibel (dB) is a unit used to express ratio as logarithms, mostly for signal power and amplitude (of which sound pressure is a common example).
They help to describe frequency ratios of musical intervals, appear in formulas counting prime numbers or approximating factorials, inform some models in psychophysics, and can aid in forensic accounting.
The next integer is 4, which is the number of digits of 1430.
Prior to Napier's invention, there had been other techniques of similar scopes, such as the prosthaphaeresis or the use of tables of progressions, extensively developed by Jost Bürgi around 1600.
Speaking of a number as requiring so many figures is a rough allusion to common logarithm, and was referred to by Archimedes as the “order of a number”.
Such methods are called prosthaphaeresis.
For example, each chamber of the shell of a nautilus is an approximate copy of the next one, scaled by a constant factor.
Logarithms are also linked to self-similarity.
It is used to quantify the loss of voltage levels in transmitting electrical signals, to describe power levels of sounds in acoustics, and the absorbance of light in the fields of spectrometry and optics.
Vinegar typically has a pH of about 3.
This "law", however, is less realistic than more recent models, such as Stevens's power law.)
When the logarithm of a random variable has a normal distribution, the variable is said to have a log-normal distribution.
For such a model, the likelihood function depends on at least one parameter that must be estimated.
Similarly, the merge sort algorithm sorts an unsorted list by dividing the list into halves and sorting these first before merging the results.
Lyapunov exponents use logarithms to gauge the degree of chaoticity of a dynamical system.
The Sierpinski triangle (pictured) can be covered by three copies of itself, each having sides half the original length.
Another example is the p-adic logarithm, the inverse function of the p-adic exponential.
Carrying out the exponentiation can be done efficiently, but the discrete logarithm is believed to be very hard to calculate in some groups.
Square roots of negative numbers can be discussed within the framework of complex numbers.
In Ancient India, the knowledge of theoretical and applied aspects of square and square root was at least as old as the Sulba Sutras, dated around 800–500 BC (possibly much earlier).
The letter jīm resembles the present square root shape.
It defines an important concept of standard deviation used in probability theory and statistics.
Most pocket calculators have a square root key.
The time complexity for computing a square root with n digits of precision is equivalent to that of multiplying two n-digit numbers.
Hilbert's problems are twenty-three problems in mathematics published by German mathematician David Hilbert in 1900.
For other problems, such as the 5th, experts have traditionally agreed on a single interpretation, and a solution to the accepted interpretation has been given, but closely related unsolved problems exist.
There are two problems that are not only unresolved but may in fact be unresolvable by modern standards.
The other twenty-one problems have all received significant attention, and late into the twentieth century work on these problems was still considered to be of the greatest importance.
Hilbert lived for 12 years after Kurt Gödel published his theorem, but does not seem to have written any formal response to Gödel's work.
In discussing his opinion that every mathematical problem should have a solution, Hilbert allows for the possibility that the solution could be a proof that the original problem is impossible.
The first of these was proved by Bernard Dwork; a completely different proof of the first two, via ℓ-adic cohomology, was given by Alexander Grothendieck.
However, the Weil conjectures were, in their scope, more like a single Hilbert problem, and Weil never intended them as a programme for all mathematics.
Erdős often offered monetary rewards; the size of the reward depended on the perceived difficulty of the problem.
At least in the mainstream media, the de facto 21st century analogue of Hilbert's problems is the list of seven Millennium Prize Problems chosen during 2000 by the Clay Mathematics Institute.
The Riemann hypothesis is noteworthy for its appearance on the list of Hilbert problems, Smale's list, the list of Millennium Prize Problems, and even the Weil conjectures, in its geometric guise.
1931, 1936 3rd Given any two polyhedra of equal volume, is it always possible to cut the first into finitely many polyhedral pieces that can be reassembled to yield the second?
— 12th Extend the Kronecker–Weber theorem on Abelian extensions of the rational numbers to any base number field.
1959 15th Rigorous foundation of Schubert's enumerative calculus.
1927 18th (a) Is there a polyhedron that admits only an anisohedral tiling in three dimensions?(b) What is the densest sphere packing?
A number is a mathematical object used to count, measure, and label.
More universally, individual numbers can be represented by symbols, called numerals; for example, "5" is a numeral that represents the number five.
Calculations with numbers are done with arithmetical operations, the most familiar being addition, subtraction, multiplication, division, and exponentiation.
Gilsdorf, Thomas E. Introduction to Cultural Mathematics: With Case Studies in the Otomies and Incas, John Wiley & Sons, Feb 24, 2012.Restivo, S. Mathematics in Society and History, Springer Science & Business Media, Nov 30, 1992.
During the 19th century, mathematicians began to develop many different abstractions which share certain properties of numbers, and may be seen as extending the concept.
A tallying system has no concept of place value (as in modern decimal notation), which limits its representation of large numbers.
Brahmagupta's Brāhmasphuṭasiddhānta is the first book that mentions zero as a number, hence Brahmagupta is usually considered the first to formulate the concept of zero.
In a similar vein, Pāṇini (5th century BC) used the null (zero) operator in the Ashtadhyayi, an early example of an algebraic grammar for the Sanskrit language (also see Pingala).
By 130 AD, Ptolemy, influenced by Hipparchus and the Babylonians, was using a symbol for 0 (a small circle with a long overbar) within a sexagesimal numeral system otherwise using alphabetic Greek numerals.
Diophantus' previous reference was discussed more explicitly by Indian mathematician Brahmagupta, in Brāhmasphuṭasiddhānta in 628, who used negative numbers to produce the general form quadratic formula that remains in use today.
At the same time, the Chinese were indicating negative numbers by drawing a diagonal stroke through the right-most non-zero digit of the corresponding positive number's numeral.
Classical Greek and Indian mathematicians made studies of the theory of rational numbers, as part of the general study of number theory.
The concept of decimal fractions is closely linked with decimal place-value notation; the two seem to have developed in tandem.
However, Pythagoras believed in the absoluteness of numbers, and could not accept the existence of irrational numbers.
By the 17th century, mathematicians generally used decimal fractions with modern notation.
In 1872, the publication of the theories of Karl Weierstrass (by his pupil E. Kossak), Eduard Heine, Georg Cantor, and Richard Dedekind was brought about.
Weierstrass, Cantor, and Heine base their theories on infinite series, while Dedekind founds his on the idea of a cut (Schnitt) in the system of real numbers, separating all rational numbers into two groups having certain characteristic properties.
Hence it was necessary to consider the wider set of algebraic numbers (all solutions to polynomial equations).
Aristotle defined the traditional Western notion of mathematical infinity.
But the next major advance in the theory was made by Georg Cantor; in 1895 he published a book about his new set theory, introducing, among other things, transfinite numbers and formulating the continuum hypothesis.
A modern geometrical version of infinity is given by projective geometry, which introduces "ideal points at infinity", one for each spatial direction.
The idea of the graphic representation of complex numbers had appeared, however, as early as 1685, in Wallis's De algebra tractatus.
In 240 BC, Eratosthenes used the Sieve of Eratosthenes to quickly isolate prime numbers.
Other results concerning the distribution of the primes include Euler's proof that the sum of the reciprocals of the primes diverges, and the Goldbach conjecture, which claims that any sufficiently large even number is the sum of two primes.
Traditionally, the sequence of natural numbers started with 1 (0 was not even considered a number for the Ancient Greeks.)
In this base 10 system, the rightmost digit of a natural number has a place value of 1, and every other digit has a place value ten times that of the place value of the digit to its right.
Negative numbers are usually written with a negative sign (a minus sign).
Here the letter Z comes .
Fractions can be greater than, less than, or equal to 1 and can also be positive, negative, or 0.
The following paragraph will focus primarily on positive real numbers.
Thus, for example, one half is 0.5, one fifth is 0.2, one-tenth is 0.1, and one fiftieth is 0.02.
Not only these prominent examples but almost all real numbers are irrational and therefore have no repeating patterns and hence no corresponding decimal numeral.
Since not even the second digit after the decimal place is preserved, the following digits are not significant.
For example, 0.999..., 1.0, 1.00, 1.000, ..., all represent the natural number 1.
Finally, if all of the digits in a numeral are 0, the number is 0, and if all of the digits in a numeral are an unending string of 9's, you can drop the nines to the right of the decimal place, and add one to the string of 9s to the left of the decimal place.
Thus the real numbers are a subset of the complex numbers.
The fundamental theorem of algebra asserts that the complex numbers form an algebraically closed field, meaning that every polynomial with complex coefficients has a root in the complex numbers.
The primes have been widely studied for more than 2000 years and have led to many questions, only some of which have been answered.
Real numbers that are not rational numbers are called irrational numbers.
The computable numbers are stable for all usual arithmetic operations, including the computation of the roots of a polynomial, and thus form a real closed field that contains the real algebraic numbers.
One reason is that there is no algorithm for testing the equality of two computable numbers.
The number system that results depends on what base is used for the digits: any base is possible, but a prime number base provides the best mathematical properties.
The former gives the ordering of the set, while the latter gives its size.
This standard basis makes the complex numbers a Cartesian plane, called the complex plane.
The complex numbers of absolute value one form the unit circle.
In domain coloring the output dimensions are represented by color and brightness, respectively.
Work on the problem of general polynomials ultimately led to the fundamental theorem of algebra, which shows that with complex numbers, a solution exists to every polynomial equation of degree one or higher.
Wessel's memoir appeared in the Proceedings of the Copenhagen Academy but went largely unnoticed.
Later classical writers on the general theory include Richard Dedekind, Otto Hölder, Felix Klein, Henri Poincaré, Hermann Schwarz, Karl Weierstrass and many others.
The use of imaginary numbers was not widely accepted until the work of Leonhard Euler (1707–1783) and Carl Friedrich Gauss (1777–1855).
The integers form the smallest group and the smallest ring containing the natural numbers.
It is the prototype of all objects of such algebraic structure.
Fixed length integer approximation data types (or subsets) are denoted int or Integer in several programming languages (such as Algol68, C, Java, Delphi, etc.).
These are provable properties of rational numbers and positional number systems, and are not used as definitions in mathematics.
Since the triangle is isosceles, a = b).
Since c is even, dividing c by 2 yields an integer.
Substituting 4y2 for c2 in the first equation (c2 = 2b2) gives us 4y2= 2b2.
Since b2 is even, b must be even.
However this contradicts the assumption that they have no common factors.
Hippasus, however, was not lauded for his efforts: according to one legend, he made his discovery while out at sea, and was subsequently thrown overboard by his fellow Pythagoreans “…for having produced an element in the universe which denied the…doctrine that all phenomena in the universe can be reduced to whole numbers and their ratios.”
For example, consider a line segment: this segment can be split in half, that half split in half, the half of the half in half, and so on.
This is just what Zeno sought to prove.
In the minds of the Greeks, disproving the validity of one view did not necessarily prove the validity of another, and therefore further investigation had to occur.
A magnitude “...was not a number but stood for entities such as line segments, angles, areas, volumes, and time which could vary, as we would say, continuously.
Because no quantitative values were assigned to magnitudes, Eudoxus was then able to account for both commensurable and incommensurable ratios by defining a ratio in terms of its magnitude, and proportion as an equality between two ratios.
This incommensurability is dealt with in Euclid's Elements, Book X, Proposition 9.
In fact, in many cases algebraic conceptions were reformulated into geometric terms.
The realization that some basic conception within the existing theory was at odds with reality necessitated a complete and thorough investigation of the axioms and assumptions that underlie that theory.
However, historian Carl Benjamin Boyer writes that "such claims are not well substantiated and unlikely to be true".
Mathematicians like Brahmagupta (in 628 AD) and Bhāskara I (in 629 AD) made contributions in this area as did other mathematicians who followed.
The year 1872 saw the publication of the theories of Karl Weierstrass (by his pupil Ernst Kossak), Eduard Heine (Crelle's Journal, 74), Georg Cantor (Annalen, 5), and Richard Dedekind.
Weierstrass, Cantor, and Heine base their theories on infinite series, while Dedekind founds his on the idea of a cut (Schnitt) in the system of all rational numbers, separating them into two groups having certain characteristic properties.
Dirichlet also added to the general theory, as have numerous contributors to the applications of the subject.
This asserts that every integer has a unique factorization into primes.
To show this, suppose we divide integers n by m (where m is nonzero).
If 0 never occurs, then the algorithm can run at most m − 1 steps without using any remainder more than once.
In mathematics, the natural numbers are those used for counting (as in "there are six coins on the table") and ordering (as in "this is the third largest city in the country").
These chains of extensions make the natural numbers canonically embedded (identified) in the other number systems.
The first major advance in abstraction was the use of numerals to represent numbers.
